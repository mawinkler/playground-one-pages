{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Playground One","text":"<p>Ultra fast and slim playground in the clouds designed for educational and demoing purposes.</p>"},{"location":"#latest-news","title":"Latest News","text":"<p>!!! Playground prepares for Vision One !!!</p> <p>In a nutshell:</p> <ul> <li>Bootstrapping directly from the clouds. It will attempt to upgrade already installed tools to the latest available version.  </li> </ul> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <ul> <li>Management of the environment with the help of an easy to use command line interface <code>pgo</code>.</li> <li>Based on Terraform &gt;1.5</li> </ul>"},{"location":"#change-log","title":"Change Log","text":"<p>08/07/2023</p> <ul> <li>Initial release</li> </ul>"},{"location":"#currently-work-in-progress","title":"Currently Work in Progress","text":"<ul> <li>Preparing the sub project <code>terraform-awsone</code> to integrate with V1ES for Server &amp; Workload Protection (Windows &amp; Linux)</li> <li>Enable ALB for Bottlerocket and Fargate cluster</li> </ul>"},{"location":"#requirements-and-support-matrix","title":"Requirements and Support Matrix","text":"<p>The Playground One is designed to work with AWS and is tested these operating systems</p> <ul> <li>Ubuntu Bionic and newer</li> <li>Cloud9 with Ubuntu</li> </ul>"},{"location":"#cli-commands-of-the-playground","title":"CLI Commands of the Playground","text":"<p>Besides the obvious cli tools like <code>kubectl</code>, <code>docker</code>, etc. the Playground offers you additional commands shown in the table below (and more):</p> Command Function pgo The command line interface for Playground One stern Tail logs from multiple pods simultaneously syft See github.com/anchore/syft grype See github.com/anchore/grype k9s See k9scli.io"},{"location":"configurations/","title":"Playground One Configurations","text":"<p>The Playground One has a modular structure as shown in the following tree:</p> <pre><code>awsone\n\u251c\u2500\u2500 vpc (2-network)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ec2 (3-instances)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 eks (4-cluster-eks)\n\u2502\u00a0\u00a0 |   \u2514\u2500\u2500 eks-deployments (8-cluster-eks-deployments)\n\u2502   \u2514\u2500\u2500 ecs (5-cluster-ecs)\n</code></pre> <p>As we can see, the configuration <code>vpc</code> is the base for the other configurations. One can choose to only create the EKS cluster, or ECS cluster, or even the full stack. Everything will reside in the same VPC.</p> <p>Architecture:</p> <p></p> <p>Security Groups:</p> <p></p> <p>The following chapters describe the different configurations on a high level, refer the the dedicated documentation for more details.</p>"},{"location":"configurations/#network","title":"Network","text":"<p>Configuration located in <code>awsone/2-network</code></p> <p>This configuration defines a VPC with the most commonly used architecture, private and public subnets accross three availability zones. It includes everything what a VPC should have, this is amongst others an internet gateway, NAT gateway, security groups, etc. Since a VPC is cheap there's no real need to destroy the networking configuration everyday, just leave it as it is and reuse it the next time. This eases the handling of other components like Vision One XDR for Containers.</p>"},{"location":"configurations/#virtual-instances","title":"Virtual Instances","text":"<p>Configuration located in <code>awsone/3-instances</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Basically, a couple of EC2 instances are created with this configuration. Currently these are two linux and one windows instances.</p> <p>If you store the agent installers for Server and Workload Security in <code>0-files</code> the instances will connect to Vision One.</p> <p>You can optionally drop any file or installer in the <code>0-files</code> directory which will then be available in the ec2 instances download folder.</p>"},{"location":"configurations/#eks-cluster","title":"EKS Cluster","text":"<p>Configuration located in <code>awsone/4-cluster-eks</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>So, this is my favorite part. This configuration creates an EKS cluster with some nice key features:</p> <ul> <li>Autoscaling from 1 to 10 nodes</li> <li>Nodes running as Spot instances to save money :-)</li> <li>ALB Load Balancer controller</li> <li>Kubernetes Autoscaler</li> <li>Optional Fargate profile</li> <li>Cluster is located in the private subnets</li> </ul>"},{"location":"configurations/#cluster-deployments","title":"Cluster Deployments","text":"<p>Configuration located in <code>awsone/8-cluster-deployments</code></p> <p>Depends on <code>awsone/4-cluster-eks</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Trivy</li> <li>Vulnerable Java-Goof</li> <li>Vulnerable Web App (openssl)</li> </ul>"},{"location":"configurations/#ecs-clusters","title":"ECS Clusters","text":"<p>Configuration located in <code>awsone/5-cluster-ecs</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Here we're building an ECS cluster using EC2 instances and/or Fargate profile. Key features:</p> <ul> <li>Two autoscaling groups (on-demand and spot) when using the EC2 variant</li> <li>Fargate profile with a mix of on-demand and spot instances</li> <li>ALB Load Balancer</li> <li>Located in the private subnets</li> <li>Automatic deployment of a vulnerable service (Java-Goof)</li> </ul>"},{"location":"life-cycle/","title":"General Life-Cycle","text":"<p>The life-cycle of Playground One is controlled by the command line interface <code>pgo</code>.</p> <p>Use it to interact with the Playground One from anywhere in your terminal by running</p> <pre><code>pgo\n</code></pre> <p>from anywhere in your terminal.</p>"},{"location":"life-cycle/#getting-help","title":"Getting Help","text":"<p>Run:</p> <pre><code>pgo --help\n</code></pre> <pre><code>Usage: pgo &lt;command&gt; &lt;configuration&gt; ...\n\nThe available commands for execution are listed below.\nThe primary workflow commands are given first, followed by\nless common or more advanced commands.\n\nMain commands:\n  -i --init     Prepare a configuration for other commands\n  -a --apply    Create of update infrastructure\n  -d --destroy  Destroy previously-created infrastructure\n  -o --output   Show output values\n  -s --state    Show the current state\n  -h --help     Show this help\nOther commands:\n  -S --show     Show advanced state\n\nAvailable configurations:\n  vpc           VPC configuration\n  ec2           EC2 configuration\n  eks           EKS configuration\n  ecs           ECS configurations\n  all           All configurations\n\nExamples:\n  pgo --apply vpc\n  pgo --state all\n</code></pre>"},{"location":"life-cycle/#create-the-environment","title":"Create the Environment","text":"<ol> <li> <p>Initialize with</p> <pre><code>pgo --init all\n</code></pre> <p>This will prepare all available configurations. No changes done in the clouds yet. You only need to init once after cloning the repository.</p> </li> <li> <p>To create the Network run</p> <pre><code>pgo --apply vpc\n</code></pre> <p>This will create your VPC in the configured region (see <code>config.yaml</code>)</p> </li> <li> <p>Create Virtual Instances and/or Kubernetes Clusters with Workload</p> <p>EC2 instances:</p> <pre><code>pgo --apply ec2\n</code></pre> <p>EKS cluster:</p> <pre><code>pgo --apply eks\n</code></pre> <p>The default workload (Container Security, Trivy, and vulnerable apps) are deployed automatically.</p> <p>ECS cluster:</p> <pre><code>pgo --apply ecs\n</code></pre> <p>A default workload is deployed automatically.</p> </li> </ol>"},{"location":"life-cycle/#query-outputs-and-state","title":"Query Outputs and State","text":"<p>The most relevant information on your configuration can be queried by running</p> <pre><code>pgo --output &lt;configuration&gt;\n</code></pre> <p>Example: <code>pgo --output ec2</code>:</p> <pre><code>public_instance_id_db1 = \"i-072abd953dedaae5d\"\npublic_instance_id_srv1 = \"i-0f2c91e08fd054510\"\npublic_instance_id_web1 = \"i-048ecedf660236f47\"\npublic_instance_ip_db1 = \"3.76.39.227\"\npublic_instance_ip_srv1 = \"3.75.219.198\"\npublic_instance_ip_web1 = \"18.197.106.33\"\npublic_instance_password_srv1 = &lt;sensitive&gt;\ns3_bucket = \"playground-awsone-cesh306v\"\nssh_instance_db1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@3.76.39.227\"\nssh_instance_srv1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no admin@3.75.219.198\"\nssh_instance_web1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@18.197.106.33\"\npublic_instance_password_srv1 = \"4h1v}Q7Hc9tbGWdM\"\n</code></pre> <p>With this you can always query how to connect to your running EC2 instances. All instances support SSH connections, the Windows Server Remote Desktop as well. For RDP Use the configured <code>admin</code> user, the ip address and password for srv1.</p>"},{"location":"life-cycle/#tear-down","title":"Tear Down","text":"<p>If you want to destroy your environment completely or only parts of it</p> <pre><code>pgo --destroy &lt;configuration&gt;\n</code></pre> <p>If you want to tear down everything run</p> <pre><code>pgo --destroy all\n</code></pre>"},{"location":"life-cycle/#optional-adapt-terraformtfvars-in-configurations","title":"Optional: Adapt <code>terraform.tfvars</code> in Configurations","text":"<p>The <code>terraform.tfvars</code>-files located within the configurations allow you to configure the AWS One playground in some aspects. Normally there's nothing to do for you, but if you only need Linux servers you could disable windows instance(s) in <code>3-instances/terraform.tfvars</code>.</p>"},{"location":"orchestration/","title":"Orchestration","text":""},{"location":"orchestration/#how-it-works","title":"How it works","text":"<p>The Playground One utilizes Terraform to maintain the environment. For best flexibility and cost optimization it is structured into several Terraform configurations. You can also view these configurations as modules that can be linked together as needed.</p> <p>Note: Currently, the only cloud provides supported is AWS, when required other public cloud providers might follow.</p>"},{"location":"orchestration/#what-is-terraform","title":"What is Terraform?","text":"<p>Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-prem resources safely and efficiently. It is maintained by HashiCorp.</p> <p>HashiCorp Terraform is an infrastructure as code tool that lets you define both cloud and on-prem resources in human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle. Terraform can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.</p>"},{"location":"orchestration/#how-does-terraform-work","title":"How does Terraform work?","text":"<p>Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API.</p> <p></p> <p>HashiCorp and the Terraform community have already written thousands of providers to manage many different types of resources and services. You can find all publicly available providers on the Terraform Registry, including Amazon Web Services (AWS), Azure, Google Cloud Platform (GCP), Kubernetes, Helm, GitHub, Splunk, DataDog, and many more.</p> <p></p> <p>The core Terraform workflow consists of three stages:</p> <p>Write: You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer.</p> <p>Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration.</p> <p>Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.</p>"},{"location":"getting-started/configuration/","title":"Getting Started Configuration","text":"<p>If you didn't create a new shell, then do so now.</p> <p>After bootstrapping you need to create a file called <code>config.yaml</code> to hold your specific configuration. Create this by running</p> <pre><code>cd ${ONEPATH}\ncp config.yaml.sample config.yaml\n</code></pre> <p>and open it with your prefered editor.</p> <p>The bare minimum to adapt are:</p> <ul> <li><code>aws.account_id</code></li> <li><code>cloudone_api_key</code></li> </ul> <p>For the rest and especially the default values see below:</p> <pre><code>services:\n- name: cloudone\n## Cloud One region to work with\n## \n## Default value: trend-us-1\nregion: ''\n## Cloud One instance to use\n##\n## Allowed values: cloudone, staging-cloudone, dev-cloudone\n## \n## Default value: cloudone\ninstance: ''\n## Cloud One API Key with Full Access\n## \n## REQUIRED if you want to play with Cloud One\n##\n## Default value: ''\napi_key: ''\n## Cloud One Scanner API Key\n## \n## REQUIRED if you want to play with Artifac Scanning as a Service\n##\n## Default value: ''\nscanner_api_key: ''\n- name: aws\n## The account id of your AWS account\n## \n## Default value: ''\naccount_id: ''\n## The default AWS region to use\n## \n## Default value: \"eu-central-1\"\nregion: ''\n## The default AWS environment name to use\n## \n## Default value: \"playground-one\"\nenvironment: \"playground-one\"\n- name: awsone\n## Restrict access to AWS One\n## \n## Default value: \"0.0.0.0/0\"\naccess_ip: ''\ninstances:\n## Create Linux instance(s)\n## \n## Default value: true\ncreate_linux: true\n## Create Windows instance(s)\n## \n## Default value: true\ncreate_windows: true\ncluster-eks:\n## Create Fargate Profile\n## \n## Default value: true\ncreate_fargate_profile : true\n- name: container_security\n## The id of the policy for use with AWSONE\n## \n## Default value: ''\npolicy_id: ''\n- name: workload-security\n## Cloud One Workload Security Tenant ID\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: ''\nws_tenant_id: ''\n## Cloud One Workload Security Token\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: ''\nws_token: ''\n## Cloud One Workload Security Linux Policy ID\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: 0\nws_policy_id: 0\n...\n</code></pre> <p>Now, continue with the chapter General Life-Cycle.</p>"},{"location":"getting-started/prepare/","title":"Getting Started","text":"<p>Choose the platform documentation</p>"},{"location":"getting-started/prepare/#ubuntu","title":"Ubuntu","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a Ubuntu machine (not Cloud9)</li> </ul> <p>Test if <code>sudo</code> requires a password by running <code>sudo ls /etc</code>. If you don't get a password prompt you're fine, otherwise run.</p> <pre><code>sudo visudo -f /etc/sudoers.d/custom-users\n</code></pre> <p>Add the following line:</p> <pre><code>&lt;YOUR USER NAME&gt; ALL=(ALL) NOPASSWD:ALL </code></pre> <p>Now, run the Playground</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session and continue with Configuration.</p> <p>Note: Ensure that you are authenticated to AWS on your Ubuntu server. If not, run <code>aws configure</code> before proceeding.</p>"},{"location":"getting-started/prepare/#cloud9","title":"Cloud9","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a AWS Cloud9 environment</li> </ul> <p>Follow the steps below to create a Cloud9 suitable for the Playground.</p> <ul> <li>Point your browser to AWS</li> <li>Choose your default AWS region in the top right</li> <li>Go to the Cloud9 service</li> <li>Select <code>[Create Cloud9 environment]</code></li> <li>Name it as you like</li> <li>Choose <code>[t3.medium]</code> for instance type and</li> <li><code>Ubuntu 18.04 LTS</code> as the platform</li> <li>For the rest take all default values and click <code>[Create environment]</code></li> </ul> <p>Update IAM Settings for the Workspace</p> <ul> <li>Click the gear icon (in top right corner), or click to open a new tab and choose <code>[Open Preferences]</code></li> <li>Select AWS SETTINGS</li> <li>Turn OFF <code>[AWS managed temporary credentials]</code></li> <li>Close the Preferences tab</li> </ul> <p>Now, run the Playground</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>If you run the above command on a newly created or rebooted Cloud9 instance and are receiving the following error, just wait a minute or two and rerun the curl command. The reason for this error is, that directly after starting the machine some update processes are running in the background causing the lock to the package manager process.</p> <pre><code>E: Could not get lock /var/lib/dpkg/lock-frontend - open (11: Resource temporarily unavailable)\nE: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\n</code></pre> <p>You will be asked for your AWS credentials. They will never be stored on disk and get removed from memory after creating and assigning an instance role to the Cloud9 instance.</p> <p>If you forgot to disable AWS managed temporary credentials you will asked to do it again.</p> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session and continue with Configuration.</p>"},{"location":"integrations/endpoint_security/","title":"Vision One Endpoint Security Server &amp; Workload Protection","text":"<p>Three different instances are currently provided by the AWS One Playground with different configurations:</p> <p>Instance Web1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>Nginx and Wordpress deployment</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Db1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>MySql databse</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Srv1:</p> <ul> <li>Windows Server 2022 Standalone Server</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>All instances are integrated with Vision One Endpoint Security for Server &amp; Workload Protection and have access to the Attomic Launcher.</p> <p>The instances are created within a public subnet of an automatically created VPC. They all get an EC2 instance role assigned providing them the ability to access installer packages stored within an S3 bucket.</p> <p>All instances including the Windows Server are accessible via ssh and key authentication. RDP for Windows is supported as well.</p>"},{"location":"integrations/endpoint_security/#optional-drop-vision-one-installer-packages","title":"Optional: Drop Vision One Installer Packages","text":"<p>Next, you need to download the installer packages for Vision One Endpoint Security for Windows and Linux operating systems from your Vision One instance. You need to do this manually since these installers are specific to your environment. The downloaded files should be named <code>TMServerAgent_Linux_auto_64_Server_-_Workload_Protection_Manager.tar</code> respectively <code>TMServerAgent_Windows_auto_64_Server_-_Workload_Protection_Manager.zip</code> and are to be placed into the directory <code>$PGPATH/terraform-awsone/0-files</code></p> <p>Optionally, download the Atomic Launcher from here and store them in the  <code>$PGPATH/terraform-awsone/0-files</code> directory as well.</p> <p>Your <code>$PGPATH/terraform-awsone/0-files</code>-directory should look like this:</p> <pre><code>-rw-rw-r-- 1 17912014 May 15 09:10 atomic_launcher_linux_1.0.0.1009.zip\n-rw-rw-r-- 1 96135367 May 15 09:05 atomic_launcher_windows_1.0.0.1013.zip\n-rw-rw-r-- 1        0 May 23 09:30 see_documentation\n-rw-rw-r-- 1 27380224 Jul 11 07:39 TMServerAgent_Linux_auto_64_Server_-_Workload_Protection_Manager.tar\n-rw-rw-r-- 1      130 Jul 17 10:12 TMServerAgent_Linux_deploy.sh\n-rw-r--r-- 1  3303330 Jul  4 11:10 TMServerAgent_Windows_auto_64_Server_-_Workload_Protection_Manager.zip\n-rw-rw-r-- 1     1102 Jul 14 14:06 TMServerAgent_Windows_deploy.ps1\n</code></pre>"},{"location":"integrations/endpoint_security/#optional-server-workload-protection-event-based-tasks","title":"Optional: Server &amp; Workload Protection Event-Based Tasks","text":"<p>Create Event-Based Tasks to automatically assign Linux or Windows server policies to the machines.</p> <p>Agent-initiated Activation Linux</p> <ul> <li>Actions: Assign Policy: Linux Server</li> <li>Conditions: \"Platform\" matches \".*Linux*.\"</li> </ul> <p>Agent-initiated Activation Windows</p> <ul> <li>Actions: Assign Policy: Windows Server</li> <li>Conditions: \"Platform\" matches \".*Windows*.\"</li> </ul>"},{"location":"integrations/endpoint_security/#atomic-launcher","title":"Atomic Launcher","text":"<p>The Atomic Launcher is stored within the downloads folder of each of the instances.</p> <p>The unzip password is <code>virus</code>.</p> <p>You should disable Anti Malware protection und set the IPS module to detect only before using Atomic Launcher :-).</p>"},{"location":"integrations/sentry/","title":"Sentry","text":"<p>To create findings and scan with Sentry run</p> <pre><code>$PGPATH/terraform-awsone/1-scripts/create-findings.sh\n</code></pre> <p>Feel free to have a look on the script above, but in theory it should prepare six findings for Sentry and two Workbenches in Vision One.</p> <p>To trigger Sentry scans for any instance run (example):</p> <pre><code># INSTANCE=&lt;INSTANCE_ID&gt; sentry-trigger-ebs-scan\nINSTANCE=$(terraform output -raw public_instance_ip_web1) sentry-trigger-ebs-scan\n</code></pre> <p>The scan results should show up in your Cloud One Central console.</p>"},{"location":"integrations/xdr_for_containers/","title":"Vision One XDR for Containers","text":"<p>At the time of writing, XDR for Containers is in an early preview stage. Unless you already have an EKS cluster running whose VPC is connected to XDR for Containers you can create one from within the Playground menu. Choose <code>EKS-A  Elastic Kubernetes Cluster (Amazon Linux)</code> in this case. This cluster variant supports Application Load Balancing which is required for XDR for Containers.</p> <p>You need to create a connection with XDR for Containers by going through the workflow in your Vision One environment.</p> <p>Note: This process will get easier with the GA release of XDR for Containers.</p>"},{"location":"playing/eks/","title":"EKS","text":""},{"location":"playing/eks/#kubernetes-autoscaling","title":"Kubernetes Autoscaling","text":"<p>Logs:</p> <pre><code>kubectl logs -f -n kube-system -l app=cluster-autoscaler\n</code></pre>"}]}